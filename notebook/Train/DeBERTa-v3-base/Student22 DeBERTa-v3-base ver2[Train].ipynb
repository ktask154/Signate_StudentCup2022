{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Student22/DeBERTa-v3-base ver2[Train].ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNmNd90h+qMfdTQYc8qxQSn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"e59dbfe99cad48e1a2e1249a9936ac16":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c30a233de27549aab613fd4912ca2fac","IPY_MODEL_22bffffcabe34e95a34404aea8c12a87","IPY_MODEL_3fcc245cf7364795b6b7f35c4b426cd2"],"layout":"IPY_MODEL_883f898cf8d149929a84fc6a4cd4afdc"}},"c30a233de27549aab613fd4912ca2fac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6f6c7a1f02f462bbdc14762f90a76ea","placeholder":"​","style":"IPY_MODEL_a6b2a268a63d46c6b99547b09780349f","value":"Downloading tokenizer_config.json: 100%"}},"22bffffcabe34e95a34404aea8c12a87":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbf5a6f00d4f4b7d9804490d13a99ae3","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c848b28461914cfda49a0040c06d86c2","value":52}},"3fcc245cf7364795b6b7f35c4b426cd2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebc4905ff0534a63b0deca83fed251e8","placeholder":"​","style":"IPY_MODEL_4ecece160cb24cbca41b5d2b670b9a61","value":" 52.0/52.0 [00:00&lt;00:00, 1.39kB/s]"}},"883f898cf8d149929a84fc6a4cd4afdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6f6c7a1f02f462bbdc14762f90a76ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6b2a268a63d46c6b99547b09780349f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbf5a6f00d4f4b7d9804490d13a99ae3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c848b28461914cfda49a0040c06d86c2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ebc4905ff0534a63b0deca83fed251e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ecece160cb24cbca41b5d2b670b9a61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1327b01b9c54faea8e3a99a2beca2db":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_16232642bf964cbd8a5cbd04b2d874f1","IPY_MODEL_8660e6afff424b68a8ff53ae40ea7fd9","IPY_MODEL_1ee2e82ee86e46268b0768f601213534"],"layout":"IPY_MODEL_6d5e7f75b7274e738d900de49b0eb05f"}},"16232642bf964cbd8a5cbd04b2d874f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40ba890472444b139cc7330960a1e6dc","placeholder":"​","style":"IPY_MODEL_ab75cb461caf4645875b5960fb888bc8","value":"Downloading config.json: 100%"}},"8660e6afff424b68a8ff53ae40ea7fd9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3444ffa052d54af0bf73f03863743281","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e5ad3f17a39469e83a4055bbe1ba94f","value":579}},"1ee2e82ee86e46268b0768f601213534":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3f37d4402ec44ca9a5019e416857582","placeholder":"​","style":"IPY_MODEL_4e0e210a94514acdb3a459e22cdda1cd","value":" 579/579 [00:00&lt;00:00, 19.7kB/s]"}},"6d5e7f75b7274e738d900de49b0eb05f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40ba890472444b139cc7330960a1e6dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab75cb461caf4645875b5960fb888bc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3444ffa052d54af0bf73f03863743281":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e5ad3f17a39469e83a4055bbe1ba94f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3f37d4402ec44ca9a5019e416857582":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e0e210a94514acdb3a459e22cdda1cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71858434ae1a47d7abc1177c64bd5847":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d03daa88d706480494301fd82e38a940","IPY_MODEL_37a270207a114010a293e2a6c45bc998","IPY_MODEL_f9eb15df8eb44cbcbca81d05a4698795"],"layout":"IPY_MODEL_1d9665ebd4404687b4b9fec5aeb195d3"}},"d03daa88d706480494301fd82e38a940":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8523aa62e424758aa7c4d46fba26674","placeholder":"​","style":"IPY_MODEL_5b30d3b3db964db19cabdecc5dd77ab8","value":"Downloading spm.model: 100%"}},"37a270207a114010a293e2a6c45bc998":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbee481222af43b39ece9824a273b1f7","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4656aefa540d497285d344b3e5055394","value":2464616}},"f9eb15df8eb44cbcbca81d05a4698795":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2af3a7d0ec964b22818d5f803b5e303c","placeholder":"​","style":"IPY_MODEL_be9b8943a5a040cf86787ee13bbc96fc","value":" 2.35M/2.35M [00:00&lt;00:00, 2.94MB/s]"}},"1d9665ebd4404687b4b9fec5aeb195d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8523aa62e424758aa7c4d46fba26674":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b30d3b3db964db19cabdecc5dd77ab8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbee481222af43b39ece9824a273b1f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4656aefa540d497285d344b3e5055394":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2af3a7d0ec964b22818d5f803b5e303c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be9b8943a5a040cf86787ee13bbc96fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6bf40cad449f4d79ad4a431ad80ca7bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_07b0f88a97a3467e8e02a12f3bb19ae7","IPY_MODEL_8f5dea5104f34374972e0e2e9bfbd5be","IPY_MODEL_d3479711fc554bac92e277e2c6438234"],"layout":"IPY_MODEL_e683ccd0024541c38046bc90b0a05efb"}},"07b0f88a97a3467e8e02a12f3bb19ae7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a9715f3f03b42e38749a01afa914a87","placeholder":"​","style":"IPY_MODEL_18f0ecacf5e34d19a11c2f079701c772","value":"Downloading pytorch_model.bin: 100%"}},"8f5dea5104f34374972e0e2e9bfbd5be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6f64870397a4bb4852488dc817cb799","max":371146213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86dbdfb33f2c49debaa76a69765cbf17","value":371146213}},"d3479711fc554bac92e277e2c6438234":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_967c325d7d1a4a41a0b280bceb687de6","placeholder":"​","style":"IPY_MODEL_e2a55f1fe5be4b8db7e6af537026186b","value":" 354M/354M [00:12&lt;00:00, 44.9MB/s]"}},"e683ccd0024541c38046bc90b0a05efb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a9715f3f03b42e38749a01afa914a87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18f0ecacf5e34d19a11c2f079701c772":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6f64870397a4bb4852488dc817cb799":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86dbdfb33f2c49debaa76a69765cbf17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"967c325d7d1a4a41a0b280bceb687de6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2a55f1fe5be4b8db7e6af537026186b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["#epoch増やす、パラメータ調整"],"metadata":{"id":"oprNYcUEiKeG"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BySnjPX7PXz5","executionInfo":{"status":"ok","timestamp":1659644941748,"user_tz":-540,"elapsed":21082,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"89c583ef-ae87-4099-e5bb-e9ba6da5a435"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75m2xhfBPqp4","executionInfo":{"status":"ok","timestamp":1659644952556,"user_tz":-540,"elapsed":10812,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"ab8d27ea-007b-4769-ffe4-fe86ec0a21b6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 3.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 11.3 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 54.4 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 59.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n"]}]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eba8I100PsyG","executionInfo":{"status":"ok","timestamp":1659644956666,"user_tz":-540,"elapsed":4115,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"f8769a21-d1a0-4d52-b005-f1dca807672c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 3.2 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}]},{"cell_type":"code","source":["import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"o8r0GW8uPvH1","executionInfo":{"status":"ok","timestamp":1659644963399,"user_tz":-540,"elapsed":6738,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["INPUT_DIR = '/content/drive/MyDrive/Competitions/Signate/Student Cup 2022/input/'\n","OUTPUT_DIR = '/content/drive/MyDrive/Competitions/Signate/Student Cup 2022/output/'\n","OUTPUT_SUB_DIR = os.path.join(OUTPUT_DIR,'Submission')\n","OUTPUT_MODEL_DIR = os.path.join(OUTPUT_DIR,'Model/DeBERTa-base[ver2]/')"],"metadata":{"id":"5ZzXtBUuP3Xo","executionInfo":{"status":"ok","timestamp":1659644963400,"user_tz":-540,"elapsed":15,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class CFG:\n","    wandb = False\n","    apex = True\n","    model = 'microsoft/deberta-v3-base'\n","    seed = 42\n","    n_splits = 5\n","    max_len = 1024\n","    dropout = 0.1\n","    target_size=4\n","    n_accumulate=1\n","    print_freq = 50\n","    min_lr=1e-6\n","    scheduler = 'cosine'\n","    batch_size = 8\n","    num_workers = 2\n","    lr = 3e-5\n","    weigth_decay = 0.01\n","    epochs = 10\n","    n_fold = 5\n","    trn_fold = [0, 1, 2, 3, 4]\n","    train = True \n","    num_warmup_steps = 0\n","    num_cycles=0.5\n","    debug = False\n","    debug_ver2 = False\n","    gradient_checkpointing = True\n","    freezing = True"],"metadata":{"id":"eHaPjAWUP9nl","executionInfo":{"status":"ok","timestamp":1659644963400,"user_tz":-540,"elapsed":14,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Loss Func\n","def criterion(outputs, labels):\n","    return nn.CrossEntropyLoss()(outputs, labels)\n","\n","def softmax(z):\n","    assert len(z.shape) == 2\n","    s = np.max(z, axis=1)\n","    s = s[:, np.newaxis] # necessary step to do broadcasting\n","    e_x = np.exp(z - s)\n","    div = np.sum(e_x, axis=1)\n","    div = div[:, np.newaxis] # dito\n","    return e_x / div\n","\"\"\"\n","def get_score(y_true, y_pred):\n","    y_pred = softmax(y_pred)\n","    score = log_loss(y_true, y_pred)\n","    return round(score, 5)\n","\"\"\"\n","def get_score(outputs, labels):\n","    outputs = F.softmax(torch.tensor(outputs)).numpy()\n","    return f1_score(np.argmax(outputs,axis=1),labels ,average='macro')\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)\n","\n","def prepare_input(cfg, text, text_2=None):\n","    inputs = cfg.tokenizer(text, text_2,\n","                           padding=\"max_length\",\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           truncation=True)\n","\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","        \n","    return inputs"],"metadata":{"id":"HtdolflkQF-N","executionInfo":{"status":"ok","timestamp":1659644964361,"user_tz":-540,"elapsed":975,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"I-zmI7wcQIWQ","executionInfo":{"status":"ok","timestamp":1659644964361,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train = pd.read_csv(os.path.join(INPUT_DIR, 'train.csv'))\n","test = pd.read_csv(os.path.join(INPUT_DIR, 'test.csv'))\n","submission_df = pd.read_csv(os.path.join(INPUT_DIR, 'submit_sample.csv'))\n","\n","display(train.head())\n","print(train.shape)\n","display(test.head())\n","print(test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"u0MWWeigQQ-m","executionInfo":{"status":"ok","timestamp":1659644965614,"user_tz":-540,"elapsed":1256,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"cef6a125-65d5-4109-cd68-81ed2f857d35"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["   id                                        description  jobflag\n","0   0  <li>Develop cutting-edge web applications that...        3\n","1   1  <li> Designs and develops high quality, scalab...        3\n","2   2  <li>Functions as a point person for Network St...        4\n","3   3  <li> Work on the technical design, development...        3\n","4   4  <li>Quantify the resources required for a task...        4"],"text/html":["\n","  <div id=\"df-8e312fbb-6c5f-4d71-9911-bf2cb1f7249a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","      <th>jobflag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>&lt;li&gt;Develop cutting-edge web applications that...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>&lt;li&gt; Designs and develops high quality, scalab...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>&lt;li&gt;Functions as a point person for Network St...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>&lt;li&gt; Work on the technical design, development...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>&lt;li&gt;Quantify the resources required for a task...</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e312fbb-6c5f-4d71-9911-bf2cb1f7249a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8e312fbb-6c5f-4d71-9911-bf2cb1f7249a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8e312fbb-6c5f-4d71-9911-bf2cb1f7249a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(1516, 3)\n"]},{"output_type":"display_data","data":{"text/plain":["     id                                        description\n","0  1516  <li>Building decision-making models and propos...\n","1  1517  <li>Educate homeowners on the benefits of sola...\n","2  1518  <li><span>Design, develop, document, and imple...\n","3  1519  <li>Apply advanced technical expertise and ski...\n","4  1520  <li>Project manage and deliver against our roa..."],"text/html":["\n","  <div id=\"df-216c9609-f9f3-4eb8-9d5c-694b35eaa241\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1516</td>\n","      <td>&lt;li&gt;Building decision-making models and propos...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1517</td>\n","      <td>&lt;li&gt;Educate homeowners on the benefits of sola...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1518</td>\n","      <td>&lt;li&gt;&lt;span&gt;Design, develop, document, and imple...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1519</td>\n","      <td>&lt;li&gt;Apply advanced technical expertise and ski...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1520</td>\n","      <td>&lt;li&gt;Project manage and deliver against our roa...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-216c9609-f9f3-4eb8-9d5c-694b35eaa241')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-216c9609-f9f3-4eb8-9d5c-694b35eaa241 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-216c9609-f9f3-4eb8-9d5c-694b35eaa241');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(1517, 2)\n"]}]},{"cell_type":"code","source":["def remove_tag(x):\n","    p = re.compile(r\"<[^>]*?>\")\n","    return p.sub('',x)\n","\n","def cleaning(texts):\n","    clean_texts = []\n","    for text in texts:\n","        # htmlタグを削除\n","        text = remove_tag(text)\n","        #アルファベット以外をスペースに置き換え\n","        #clean_punc = re.sub(r'[^a-zA-Z]', ' ', text)\n","        clean_texts.append(text)\n","    return clean_texts\n","\n","\n","\n","from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n","    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n","\n","\n","def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n","    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n","\n","# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n","codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n","codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n","\n","def resolve_encodings_and_normalize(text: str) -> str:\n","    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n","    text = (\n","        text.encode(\"raw_unicode_escape\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","    )\n","    text = unidecode(text)\n","    return text\n","\n","train['description'] = cleaning(train['description'])\n","test['description'] = cleaning(test['description'])\n","train['inputs'] = train['description'].apply(lambda x : resolve_encodings_and_normalize(x))\n","test['inputs'] = test['description'].apply(lambda x : resolve_encodings_and_normalize(x))\n","train = train.rename(columns = {\"jobflag\": \"label\"})\n","train[\"label\"] = train[\"label\"].apply(lambda x : 0 if x == 4 else x)\n","train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"VzIaDXs2Qc02","executionInfo":{"status":"ok","timestamp":1659644966066,"user_tz":-540,"elapsed":456,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"6c8291fd-3cf0-406e-97ec-fa877d0ec594"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id                                        description  label  \\\n","0        0  Develop cutting-edge web applications that per...      3   \n","1        1   Designs and develops high quality, scalable a...      3   \n","2        2  Functions as a point person for Network Strate...      0   \n","3        3   Work on the technical design, development, re...      3   \n","4        4  Quantify the resources required for a task/pro...      0   \n","...    ...                                                ...    ...   \n","1511  1511  Support detailed reporting, statistical analys...      1   \n","1512  1512  Collaborate with teams to support the ML techn...      2   \n","1513  1513   Work with executives and other business leade...      1   \n","1514  1514  Leading design ideation sessions to ensure we ...      3   \n","1515  1515  Detection of Issues &amp; Impact Assessments e...      1   \n","\n","                                                 inputs  \n","0     Develop cutting-edge web applications that per...  \n","1      Designs and develops high quality, scalable a...  \n","2     Functions as a point person for Network Strate...  \n","3      Work on the technical design, development, re...  \n","4     Quantify the resources required for a task/pro...  \n","...                                                 ...  \n","1511  Support detailed reporting, statistical analys...  \n","1512  Collaborate with teams to support the ML techn...  \n","1513   Work with executives and other business leade...  \n","1514  Leading design ideation sessions to ensure we ...  \n","1515  Detection of Issues &amp; Impact Assessments e...  \n","\n","[1516 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-aa52f3af-5784-4bdb-9653-4df01ea73f95\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","      <th>label</th>\n","      <th>inputs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Develop cutting-edge web applications that per...</td>\n","      <td>3</td>\n","      <td>Develop cutting-edge web applications that per...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Designs and develops high quality, scalable a...</td>\n","      <td>3</td>\n","      <td>Designs and develops high quality, scalable a...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Functions as a point person for Network Strate...</td>\n","      <td>0</td>\n","      <td>Functions as a point person for Network Strate...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Work on the technical design, development, re...</td>\n","      <td>3</td>\n","      <td>Work on the technical design, development, re...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Quantify the resources required for a task/pro...</td>\n","      <td>0</td>\n","      <td>Quantify the resources required for a task/pro...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1511</th>\n","      <td>1511</td>\n","      <td>Support detailed reporting, statistical analys...</td>\n","      <td>1</td>\n","      <td>Support detailed reporting, statistical analys...</td>\n","    </tr>\n","    <tr>\n","      <th>1512</th>\n","      <td>1512</td>\n","      <td>Collaborate with teams to support the ML techn...</td>\n","      <td>2</td>\n","      <td>Collaborate with teams to support the ML techn...</td>\n","    </tr>\n","    <tr>\n","      <th>1513</th>\n","      <td>1513</td>\n","      <td>Work with executives and other business leade...</td>\n","      <td>1</td>\n","      <td>Work with executives and other business leade...</td>\n","    </tr>\n","    <tr>\n","      <th>1514</th>\n","      <td>1514</td>\n","      <td>Leading design ideation sessions to ensure we ...</td>\n","      <td>3</td>\n","      <td>Leading design ideation sessions to ensure we ...</td>\n","    </tr>\n","    <tr>\n","      <th>1515</th>\n","      <td>1515</td>\n","      <td>Detection of Issues &amp;amp; Impact Assessments e...</td>\n","      <td>1</td>\n","      <td>Detection of Issues &amp;amp; Impact Assessments e...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1516 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa52f3af-5784-4bdb-9653-4df01ea73f95')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-aa52f3af-5784-4bdb-9653-4df01ea73f95 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-aa52f3af-5784-4bdb-9653-4df01ea73f95');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CFG.n_splits,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train.label)):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","train[\"kfold\"] = train[\"kfold\"].astype(int)"],"metadata":{"id":"-Oaxhj1tQqyH","executionInfo":{"status":"ok","timestamp":1659644966066,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_MODEL_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer\n","SEP = tokenizer.sep_token"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["e59dbfe99cad48e1a2e1249a9936ac16","c30a233de27549aab613fd4912ca2fac","22bffffcabe34e95a34404aea8c12a87","3fcc245cf7364795b6b7f35c4b426cd2","883f898cf8d149929a84fc6a4cd4afdc","e6f6c7a1f02f462bbdc14762f90a76ea","a6b2a268a63d46c6b99547b09780349f","cbf5a6f00d4f4b7d9804490d13a99ae3","c848b28461914cfda49a0040c06d86c2","ebc4905ff0534a63b0deca83fed251e8","4ecece160cb24cbca41b5d2b670b9a61","a1327b01b9c54faea8e3a99a2beca2db","16232642bf964cbd8a5cbd04b2d874f1","8660e6afff424b68a8ff53ae40ea7fd9","1ee2e82ee86e46268b0768f601213534","6d5e7f75b7274e738d900de49b0eb05f","40ba890472444b139cc7330960a1e6dc","ab75cb461caf4645875b5960fb888bc8","3444ffa052d54af0bf73f03863743281","8e5ad3f17a39469e83a4055bbe1ba94f","f3f37d4402ec44ca9a5019e416857582","4e0e210a94514acdb3a459e22cdda1cd","71858434ae1a47d7abc1177c64bd5847","d03daa88d706480494301fd82e38a940","37a270207a114010a293e2a6c45bc998","f9eb15df8eb44cbcbca81d05a4698795","1d9665ebd4404687b4b9fec5aeb195d3","e8523aa62e424758aa7c4d46fba26674","5b30d3b3db964db19cabdecc5dd77ab8","dbee481222af43b39ece9824a273b1f7","4656aefa540d497285d344b3e5055394","2af3a7d0ec964b22818d5f803b5e303c","be9b8943a5a040cf86787ee13bbc96fc"]},"id":"JozVPxKoRCCj","executionInfo":{"status":"ok","timestamp":1659644970000,"user_tz":-540,"elapsed":3937,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"9db9d114-2595-4c1e-f4b4-5831f4a4787c"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e59dbfe99cad48e1a2e1249a9936ac16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1327b01b9c54faea8e3a99a2beca2db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading spm.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71858434ae1a47d7abc1177c64bd5847"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["class Dataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length):\n","        self.df = df\n","        self.max_len = CFG.max_len\n","        self.text = df['inputs'].values\n","        self.tokenizer = CFG.tokenizer\n","        self.targets = df['label'].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        text = self.text[index]\n","        inputs = tokenizer.encode_plus(\n","            text,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length = self.max_len\n","        )\n","        samples = {\n","            'input_ids': inputs['input_ids'],\n","            'attention_mask': inputs['attention_mask'],\n","            'target': self.targets[index]\n","        }\n","\n","        if 'token_type_ids' in inputs:\n","            samples['token_type_ids'] = inputs['token_type_ids']\n","            \n","        return samples"],"metadata":{"id":"0-62YNlsRGQ8","executionInfo":{"status":"ok","timestamp":1659644970001,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Dynamic Padding (Collate)\n","#collate_fn = DataCollatorWithPadding(tokenizer=CFG.tokenizer)\n","class Collate:\n","    def __init__(self, tokenizer, isTrain=True):\n","        self.tokenizer = tokenizer\n","        self.isTrain = isTrain\n","        # self.args = args\n","\n","    def __call__(self, batch):\n","        output = dict()\n","        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n","        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n","        if self.isTrain:\n","            output[\"target\"] = [sample[\"target\"] for sample in batch]\n","\n","        # calculate max token length of this batch\n","        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n","        else:\n","            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n","\n","        # convert to tensors\n","        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n","        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n","        if self.isTrain:\n","            output[\"target\"] = torch.tensor(output[\"target\"], dtype=torch.long)\n","\n","        return output\n","    \n","collate_fn = Collate(CFG.tokenizer, isTrain=True)"],"metadata":{"id":"_sh69Da6RQFz","executionInfo":{"status":"ok","timestamp":1659644970001,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9) #\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings"],"metadata":{"id":"H_GyjbDnRStd","executionInfo":{"status":"ok","timestamp":1659644970001,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, model_name):\n","        super(CustomModel, self).__init__()\n","        # Header (fast or normal)\n","        self.model = AutoModel.from_pretrained(model_name)\n","        \n","        # Gradient_checkpointing\n","        if CFG.gradient_checkpointing:\n","            (self.model).gradient_checkpointing_enable()\n","        \n","        # Freezing\n","        if CFG.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            CFG.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","        \n","        self.config = AutoConfig.from_pretrained(model_name)\n","        self.drop = nn.Dropout(p=CFG.dropout)\n","        self.pooler = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, CFG.target_size)\n","        \n","    def forward(self, ids, mask):        \n","        out = self.model(input_ids=ids, \n","                         attention_mask=mask,\n","                         output_hidden_states=False)\n","        out = self.pooler(out.last_hidden_state, mask)\n","        out = self.drop(out)\n","        outputs = self.fc(out)\n","        return outputs"],"metadata":{"id":"Tm7w8yAcRVP3","executionInfo":{"status":"ok","timestamp":1659644970002,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def asMinutes(s):\n","    m = math.floor(s/60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","def get_scheduler(cfg, optimizer, num_train_steps):\n","    if cfg.scheduler == 'linear':\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","        )\n","    elif cfg.scheduler == 'cosine':\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","        )\n","    return scheduler\n","\n","def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","    model.train()\n","\n","    dataset_size = 0\n","    running_loss = 0\n","\n","    start = end = time.time()\n","\n","    for step, data in enumerate(dataloader):\n","        ids = data['input_ids'].to(device, dtype=torch.long)\n","        mask = data['attention_mask'].to(device, dtype=torch.long)\n","        targets = data['target'].to(device, dtype=torch.long)\n","\n","        batch_size = ids.size(0)\n","        \n","        outputs = model(ids, mask)\n","        loss = criterion(outputs, targets)\n","\n","        #accumulate\n","        loss = loss / CFG.n_accumulate \n","        loss.backward()\n","        if (step +1) % CFG.n_accumulate == 0:\n","            optimizer.step()\n","\n","            optimizer.zero_grad()\n","            if scheduler is not None:\n","                scheduler.step()\n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","\n","        epoch_loss = running_loss / dataset_size\n","\n","        end = time.time()\n","        \n","        if step % CFG.print_freq == 0 or step == (len(dataloader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  .format(epoch+1, step, len(dataloader), \n","                          remain=timeSince(start, float(step+1)/len(dataloader))))\n","\n","    gc.collect()\n","\n","    return epoch_loss\n","\n","\n","@torch.no_grad()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","\n","    dataset_size = 0\n","    running_loss = 0\n","\n","    start = end = time.time()\n","    pred = []\n","\n","    for step, data in enumerate(dataloader):\n","        ids = data['input_ids'].to(device, dtype=torch.long)\n","        mask = data['attention_mask'].to(device, dtype=torch.long)\n","        targets = data['target'].to(device, dtype=torch.long)\n","\n","        batch_size = ids.size(0)\n","        outputs = model(ids, mask)\n","        loss = criterion(outputs, targets)\n","        pred.append(outputs.to('cpu').numpy())\n","\n","        running_loss += (loss.item()* batch_size)\n","        dataset_size += batch_size\n","\n","        epoch_loss = running_loss / dataset_size\n","\n","        end = time.time()\n","\n","        if step % CFG.print_freq == 0 or step == (len(dataloader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  .format(step, len(dataloader),\n","                          remain=timeSince(start, float(step+1)/len(dataloader))))\n","            \n","    pred = np.concatenate(pred)\n","            \n","    return epoch_loss, pred"],"metadata":{"id":"TEFbXjOCRguX","executionInfo":{"status":"ok","timestamp":1659644970002,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def train_loop(fold):\n","    #wandb.watch(model, log_freq=100)\n","\n","    LOGGER.info(f'-------------fold:{fold} training-------------')\n","\n","    train_data = train[train.kfold != fold].reset_index(drop=True)\n","    valid_data = train[train.kfold == fold].reset_index(drop=True)\n","    valid_labels = valid_data.label.values\n","\n","    trainDataset = Dataset(train_data, CFG.tokenizer, CFG.max_len)\n","    validDataset = Dataset(valid_data, CFG.tokenizer, CFG.max_len)\n","\n","    train_loader = DataLoader(trainDataset,\n","                              batch_size = CFG.batch_size,\n","                              shuffle=True,\n","                              collate_fn = collate_fn,\n","                              num_workers = CFG.num_workers,\n","                              pin_memory = True,\n","                              drop_last=True)\n","    \n","    valid_loader = DataLoader(validDataset,\n","                              batch_size = CFG.batch_size*2,\n","                              shuffle=False,\n","                              collate_fn = collate_fn,\n","                              num_workers = CFG.num_workers,\n","                              pin_memory = True,\n","                              drop_last=False)\n","    \n","    model = CustomModel(CFG.model)\n","    torch.save(model.config, OUTPUT_MODEL_DIR+'config.pth')\n","    model.to(device)\n","    optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weigth_decay)\n","    num_train_steps = int(len(train_data) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # loop\n","    best_score = 0\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","\n","        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, train_loader, device, epoch)\n","        valid_epoch_loss, pred = valid_one_epoch(model, valid_loader, device, epoch)\n","\n","        score = get_score(pred, valid_labels)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {train_epoch_loss:.4f}  avg_val_loss: {valid_epoch_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                       f\"[fold{fold}] avg_train_loss\": train_epoch_loss, \n","                       f\"[fold{fold}] avg_val_loss\": valid_epoch_loss,\n","                       f\"[fold{fold}] score\": score})\n","            \n","        if score > best_score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': pred},\n","                        OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","            \n","    predictions = torch.load(OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_data['Consultant'] = predictions[:, 0]\n","    valid_data['Data scientist'] = predictions[:, 1]\n","    valid_data['Machine learning engineer'] = predictions[:, 2]\n","    valid_data['Software engineer'] = predictions[:, 3]\n","    \n","    \n","    temp = valid_data[['Consultant','Data scientist','Machine learning engineer','Software engineer']].values.tolist()\n","    print(get_score(temp, valid_data['label'].values))\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_data"],"metadata":{"id":"Iftyf0agiWRJ","executionInfo":{"status":"ok","timestamp":1659644970289,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['label'].values\n","        preds = oof_df[['Consultant','Data scientist','Machine learning engineer','Software engineer']].values.tolist()\n","        score = get_score(preds, labels)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')\n","        oof_df.to_csv(OUTPUT_MODEL_DIR+f'oof_df.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["6bf40cad449f4d79ad4a431ad80ca7bb","07b0f88a97a3467e8e02a12f3bb19ae7","8f5dea5104f34374972e0e2e9bfbd5be","d3479711fc554bac92e277e2c6438234","e683ccd0024541c38046bc90b0a05efb","6a9715f3f03b42e38749a01afa914a87","18f0ecacf5e34d19a11c2f079701c772","b6f64870397a4bb4852488dc817cb799","86dbdfb33f2c49debaa76a69765cbf17","967c325d7d1a4a41a0b280bceb687de6","e2a55f1fe5be4b8db7e6af537026186b"]},"id":"0DG0hD6XiZ2S","executionInfo":{"status":"ok","timestamp":1659647920351,"user_tz":-540,"elapsed":2950065,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"fde2030c-cb31-4dc4-80f3-c5fd51b718f0"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["-------------fold:0 training-------------\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/354M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bf40cad449f4d79ad4a431ad80ca7bb"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/151] Elapsed 0m 4s (remain 10m 9s) \n","Epoch: [1][50/151] Elapsed 0m 22s (remain 0m 43s) \n","Epoch: [1][100/151] Elapsed 0m 38s (remain 0m 19s) \n","Epoch: [1][150/151] Elapsed 0m 55s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.9333  avg_val_loss: 0.8344  time: 60s\n","Epoch 1 - Score: 0.5196\n","Epoch 1 - Save Best Score: 0.5196 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [2][0/151] Elapsed 0m 0s (remain 1m 4s) \n","Epoch: [2][50/151] Elapsed 0m 18s (remain 0m 36s) \n","Epoch: [2][100/151] Elapsed 0m 36s (remain 0m 18s) \n","Epoch: [2][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5791  avg_val_loss: 0.6335  time: 57s\n","Epoch 2 - Score: 0.6113\n","Epoch 2 - Save Best Score: 0.6113 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [3][0/151] Elapsed 0m 0s (remain 1m 21s) \n","Epoch: [3][50/151] Elapsed 0m 18s (remain 0m 35s) \n","Epoch: [3][100/151] Elapsed 0m 36s (remain 0m 18s) \n","Epoch: [3][150/151] Elapsed 0m 53s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4245  avg_val_loss: 0.6633  time: 58s\n","Epoch 3 - Score: 0.6799\n","Epoch 3 - Save Best Score: 0.6799 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [4][0/151] Elapsed 0m 0s (remain 1m 10s) \n","Epoch: [4][50/151] Elapsed 0m 19s (remain 0m 37s) \n","Epoch: [4][100/151] Elapsed 0m 37s (remain 0m 18s) \n","Epoch: [4][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2863  avg_val_loss: 0.6578  time: 58s\n","Epoch 4 - Score: 0.7607\n","Epoch 4 - Save Best Score: 0.7607 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [5][0/151] Elapsed 0m 0s (remain 2m 19s) \n","Epoch: [5][50/151] Elapsed 0m 18s (remain 0m 36s) \n","Epoch: [5][100/151] Elapsed 0m 36s (remain 0m 17s) \n","Epoch: [5][150/151] Elapsed 0m 53s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1688  avg_val_loss: 0.7163  time: 58s\n","Epoch 5 - Score: 0.7297\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [6][0/151] Elapsed 0m 0s (remain 2m 13s) \n","Epoch: [6][50/151] Elapsed 0m 17s (remain 0m 34s) \n","Epoch: [6][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [6][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0653  avg_val_loss: 0.8007  time: 57s\n","Epoch 6 - Score: 0.7592\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [7][0/151] Elapsed 0m 0s (remain 1m 25s) \n","Epoch: [7][50/151] Elapsed 0m 17s (remain 0m 35s) \n","Epoch: [7][100/151] Elapsed 0m 33s (remain 0m 16s) \n","Epoch: [7][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0305  avg_val_loss: 0.8364  time: 57s\n","Epoch 7 - Score: 0.7549\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [8][0/151] Elapsed 0m 0s (remain 1m 7s) \n","Epoch: [8][50/151] Elapsed 0m 18s (remain 0m 36s) \n","Epoch: [8][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [8][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0108  avg_val_loss: 0.8457  time: 58s\n","Epoch 8 - Score: 0.7632\n","Epoch 8 - Save Best Score: 0.7632 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [9][0/151] Elapsed 0m 0s (remain 1m 19s) \n","Epoch: [9][50/151] Elapsed 0m 18s (remain 0m 35s) \n","Epoch: [9][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [9][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0082  avg_val_loss: 0.8556  time: 58s\n","Epoch 9 - Score: 0.7509\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [10][0/151] Elapsed 0m 0s (remain 1m 19s) \n","Epoch: [10][50/151] Elapsed 0m 18s (remain 0m 36s) \n","Epoch: [10][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [10][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0070  avg_val_loss: 0.8599  time: 58s\n","Epoch 10 - Score: 0.7509\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","Score: 0.7632\n","-------------fold:1 training-------------\n"]},{"output_type":"stream","name":"stdout","text":["0.7632318732463171\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/151] Elapsed 0m 0s (remain 1m 18s) \n","Epoch: [1][50/151] Elapsed 0m 18s (remain 0m 35s) \n","Epoch: [1][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [1][150/151] Elapsed 0m 53s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.9985  avg_val_loss: 0.6970  time: 57s\n","Epoch 1 - Score: 0.5630\n","Epoch 1 - Save Best Score: 0.5630 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [2][0/151] Elapsed 0m 0s (remain 0m 55s) \n","Epoch: [2][50/151] Elapsed 0m 17s (remain 0m 34s) \n","Epoch: [2][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [2][150/151] Elapsed 0m 54s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 5s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.6154  avg_val_loss: 0.7007  time: 58s\n","Epoch 2 - Score: 0.6753\n","Epoch 2 - Save Best Score: 0.6753 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [3][0/151] Elapsed 0m 0s (remain 1m 22s) \n","Epoch: [3][50/151] Elapsed 0m 16s (remain 0m 32s) \n","Epoch: [3][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [3][150/151] Elapsed 0m 51s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4948  avg_val_loss: 0.6335  time: 56s\n","Epoch 3 - Score: 0.6731\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [4][0/151] Elapsed 0m 0s (remain 0m 47s) \n","Epoch: [4][50/151] Elapsed 0m 17s (remain 0m 33s) \n","Epoch: [4][100/151] Elapsed 0m 34s (remain 0m 17s) \n","Epoch: [4][150/151] Elapsed 0m 53s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3415  avg_val_loss: 0.6557  time: 57s\n","Epoch 4 - Score: 0.7048\n","Epoch 4 - Save Best Score: 0.7048 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [5][0/151] Elapsed 0m 0s (remain 0m 52s) \n","Epoch: [5][50/151] Elapsed 0m 20s (remain 0m 39s) \n","Epoch: [5][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [5][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.2272  avg_val_loss: 0.7381  time: 56s\n","Epoch 5 - Score: 0.6982\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [6][0/151] Elapsed 0m 0s (remain 1m 15s) \n","Epoch: [6][50/151] Elapsed 0m 18s (remain 0m 36s) \n","Epoch: [6][100/151] Elapsed 0m 36s (remain 0m 18s) \n","Epoch: [6][150/151] Elapsed 0m 53s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 5s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.1399  avg_val_loss: 0.8322  time: 58s\n","Epoch 6 - Score: 0.7016\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [7][0/151] Elapsed 0m 0s (remain 1m 21s) \n","Epoch: [7][50/151] Elapsed 0m 17s (remain 0m 34s) \n","Epoch: [7][100/151] Elapsed 0m 37s (remain 0m 18s) \n","Epoch: [7][150/151] Elapsed 0m 54s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 5s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0608  avg_val_loss: 0.8522  time: 58s\n","Epoch 7 - Score: 0.6933\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [8][0/151] Elapsed 0m 0s (remain 0m 58s) \n","Epoch: [8][50/151] Elapsed 0m 18s (remain 0m 35s) \n","Epoch: [8][100/151] Elapsed 0m 36s (remain 0m 18s) \n","Epoch: [8][150/151] Elapsed 0m 54s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 5s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0334  avg_val_loss: 0.9058  time: 58s\n","Epoch 8 - Score: 0.6994\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [9][0/151] Elapsed 0m 0s (remain 0m 58s) \n","Epoch: [9][50/151] Elapsed 0m 17s (remain 0m 34s) \n","Epoch: [9][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [9][150/151] Elapsed 0m 53s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 5s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0191  avg_val_loss: 0.9320  time: 57s\n","Epoch 9 - Score: 0.7293\n","Epoch 9 - Save Best Score: 0.7293 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [10][0/151] Elapsed 0m 0s (remain 0m 57s) \n","Epoch: [10][50/151] Elapsed 0m 17s (remain 0m 33s) \n","Epoch: [10][100/151] Elapsed 0m 33s (remain 0m 16s) \n","Epoch: [10][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 5s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0183  avg_val_loss: 0.9434  time: 56s\n","Epoch 10 - Score: 0.6994\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","Score: 0.7293\n"]},{"output_type":"stream","name":"stdout","text":["0.7293167677468589\n"]},{"output_type":"stream","name":"stderr","text":["-------------fold:2 training-------------\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/151] Elapsed 0m 0s (remain 1m 8s) \n","Epoch: [1][50/151] Elapsed 0m 18s (remain 0m 36s) \n","Epoch: [1][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [1][150/151] Elapsed 0m 51s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.9741  avg_val_loss: 0.6511  time: 56s\n","Epoch 1 - Score: 0.6886\n","Epoch 1 - Save Best Score: 0.6886 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [2][0/151] Elapsed 0m 0s (remain 0m 59s) \n","Epoch: [2][50/151] Elapsed 0m 17s (remain 0m 34s) \n","Epoch: [2][100/151] Elapsed 0m 36s (remain 0m 17s) \n","Epoch: [2][150/151] Elapsed 0m 50s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.6390  avg_val_loss: 0.6070  time: 56s\n","Epoch 2 - Score: 0.6948\n","Epoch 2 - Save Best Score: 0.6948 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [3][0/151] Elapsed 0m 0s (remain 1m 26s) \n","Epoch: [3][50/151] Elapsed 0m 16s (remain 0m 32s) \n","Epoch: [3][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [3][150/151] Elapsed 0m 51s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4504  avg_val_loss: 0.6280  time: 56s\n","Epoch 3 - Score: 0.6262\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [4][0/151] Elapsed 0m 0s (remain 0m 53s) \n","Epoch: [4][50/151] Elapsed 0m 18s (remain 0m 36s) \n","Epoch: [4][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [4][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2987  avg_val_loss: 0.7204  time: 57s\n","Epoch 4 - Score: 0.6977\n","Epoch 4 - Save Best Score: 0.6977 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [5][0/151] Elapsed 0m 0s (remain 1m 3s) \n","Epoch: [5][50/151] Elapsed 0m 18s (remain 0m 35s) \n","Epoch: [5][100/151] Elapsed 0m 34s (remain 0m 17s) \n","Epoch: [5][150/151] Elapsed 0m 51s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1844  avg_val_loss: 0.8088  time: 56s\n","Epoch 5 - Score: 0.6779\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [6][0/151] Elapsed 0m 0s (remain 1m 7s) \n","Epoch: [6][50/151] Elapsed 0m 17s (remain 0m 34s) \n","Epoch: [6][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [6][150/151] Elapsed 0m 51s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.1082  avg_val_loss: 0.9025  time: 56s\n","Epoch 6 - Score: 0.6739\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [7][0/151] Elapsed 0m 0s (remain 1m 42s) \n","Epoch: [7][50/151] Elapsed 0m 16s (remain 0m 31s) \n","Epoch: [7][100/151] Elapsed 0m 34s (remain 0m 17s) \n","Epoch: [7][150/151] Elapsed 0m 50s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0429  avg_val_loss: 1.0117  time: 55s\n","Epoch 7 - Score: 0.6703\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [8][0/151] Elapsed 0m 0s (remain 0m 53s) \n","Epoch: [8][50/151] Elapsed 0m 16s (remain 0m 32s) \n","Epoch: [8][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [8][150/151] Elapsed 0m 51s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0310  avg_val_loss: 0.9817  time: 56s\n","Epoch 8 - Score: 0.6868\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [9][0/151] Elapsed 0m 0s (remain 0m 52s) \n","Epoch: [9][50/151] Elapsed 0m 17s (remain 0m 34s) \n","Epoch: [9][100/151] Elapsed 0m 34s (remain 0m 16s) \n","Epoch: [9][150/151] Elapsed 0m 50s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0206  avg_val_loss: 1.0077  time: 56s\n","Epoch 9 - Score: 0.6716\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [10][0/151] Elapsed 0m 0s (remain 1m 10s) \n","Epoch: [10][50/151] Elapsed 0m 16s (remain 0m 32s) \n","Epoch: [10][100/151] Elapsed 0m 34s (remain 0m 17s) \n","Epoch: [10][150/151] Elapsed 0m 50s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0163  avg_val_loss: 1.0180  time: 55s\n","Epoch 10 - Score: 0.6798\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","0.6976686328965201\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","Score: 0.6977\n","-------------fold:3 training-------------\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/151] Elapsed 0m 0s (remain 1m 20s) \n","Epoch: [1][50/151] Elapsed 0m 18s (remain 0m 35s) \n","Epoch: [1][100/151] Elapsed 0m 36s (remain 0m 17s) \n","Epoch: [1][150/151] Elapsed 0m 53s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.9742  avg_val_loss: 0.7066  time: 57s\n","Epoch 1 - Score: 0.5556\n","Epoch 1 - Save Best Score: 0.5556 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [2][0/151] Elapsed 0m 0s (remain 2m 2s) \n","Epoch: [2][50/151] Elapsed 0m 19s (remain 0m 37s) \n","Epoch: [2][100/151] Elapsed 0m 38s (remain 0m 18s) \n","Epoch: [2][150/151] Elapsed 0m 53s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.6416  avg_val_loss: 0.6694  time: 58s\n","Epoch 2 - Score: 0.6483\n","Epoch 2 - Save Best Score: 0.6483 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [3][0/151] Elapsed 0m 0s (remain 1m 9s) \n","Epoch: [3][50/151] Elapsed 0m 20s (remain 0m 39s) \n","Epoch: [3][100/151] Elapsed 0m 36s (remain 0m 18s) \n","Epoch: [3][150/151] Elapsed 0m 54s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4642  avg_val_loss: 0.6512  time: 58s\n","Epoch 3 - Score: 0.6908\n","Epoch 3 - Save Best Score: 0.6908 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [4][0/151] Elapsed 0m 0s (remain 1m 19s) \n","Epoch: [4][50/151] Elapsed 0m 17s (remain 0m 33s) \n","Epoch: [4][100/151] Elapsed 0m 34s (remain 0m 17s) \n","Epoch: [4][150/151] Elapsed 0m 53s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3485  avg_val_loss: 0.5903  time: 58s\n","Epoch 4 - Score: 0.7065\n","Epoch 4 - Save Best Score: 0.7065 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [5][0/151] Elapsed 0m 1s (remain 2m 54s) \n","Epoch: [5][50/151] Elapsed 0m 19s (remain 0m 38s) \n","Epoch: [5][100/151] Elapsed 0m 36s (remain 0m 18s) \n","Epoch: [5][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.2050  avg_val_loss: 0.7770  time: 56s\n","Epoch 5 - Score: 0.6931\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [6][0/151] Elapsed 0m 0s (remain 0m 57s) \n","Epoch: [6][50/151] Elapsed 0m 17s (remain 0m 34s) \n","Epoch: [6][100/151] Elapsed 0m 36s (remain 0m 17s) \n","Epoch: [6][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.1101  avg_val_loss: 0.8596  time: 56s\n","Epoch 6 - Score: 0.7233\n","Epoch 6 - Save Best Score: 0.7233 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [7][0/151] Elapsed 0m 0s (remain 1m 10s) \n","Epoch: [7][50/151] Elapsed 0m 18s (remain 0m 35s) \n","Epoch: [7][100/151] Elapsed 0m 34s (remain 0m 16s) \n","Epoch: [7][150/151] Elapsed 0m 53s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0778  avg_val_loss: 0.8499  time: 57s\n","Epoch 7 - Score: 0.7271\n","Epoch 7 - Save Best Score: 0.7271 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [8][0/151] Elapsed 0m 0s (remain 1m 13s) \n","Epoch: [8][50/151] Elapsed 0m 19s (remain 0m 38s) \n","Epoch: [8][100/151] Elapsed 0m 36s (remain 0m 18s) \n","Epoch: [8][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 7s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0293  avg_val_loss: 0.8885  time: 56s\n","Epoch 8 - Score: 0.7334\n","Epoch 8 - Save Best Score: 0.7334 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [9][0/151] Elapsed 0m 0s (remain 1m 16s) \n","Epoch: [9][50/151] Elapsed 0m 20s (remain 0m 40s) \n","Epoch: [9][100/151] Elapsed 0m 37s (remain 0m 18s) \n","Epoch: [9][150/151] Elapsed 0m 54s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0194  avg_val_loss: 0.9130  time: 58s\n","Epoch 9 - Score: 0.7282\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [10][0/151] Elapsed 0m 0s (remain 1m 23s) \n","Epoch: [10][50/151] Elapsed 0m 20s (remain 0m 39s) \n","Epoch: [10][100/151] Elapsed 0m 36s (remain 0m 17s) \n","Epoch: [10][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 6s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0149  avg_val_loss: 0.9179  time: 57s\n","Epoch 10 - Score: 0.7233\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","0.73338688449166\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n","Score: 0.7334\n","-------------fold:4 training-------------\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/151] Elapsed 0m 0s (remain 1m 29s) \n","Epoch: [1][50/151] Elapsed 0m 18s (remain 0m 36s) \n","Epoch: [1][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [1][150/151] Elapsed 0m 51s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 1.0259  avg_val_loss: 0.7582  time: 55s\n","Epoch 1 - Score: 0.5456\n","Epoch 1 - Save Best Score: 0.5456 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [2][0/151] Elapsed 0m 0s (remain 1m 16s) \n","Epoch: [2][50/151] Elapsed 0m 18s (remain 0m 35s) \n","Epoch: [2][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [2][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.6883  avg_val_loss: 0.6893  time: 56s\n","Epoch 2 - Score: 0.6253\n","Epoch 2 - Save Best Score: 0.6253 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [3][0/151] Elapsed 0m 0s (remain 0m 48s) \n","Epoch: [3][50/151] Elapsed 0m 18s (remain 0m 35s) \n","Epoch: [3][100/151] Elapsed 0m 34s (remain 0m 17s) \n","Epoch: [3][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.5520  avg_val_loss: 0.6974  time: 57s\n","Epoch 3 - Score: 0.6598\n","Epoch 3 - Save Best Score: 0.6598 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [4][0/151] Elapsed 0m 0s (remain 1m 1s) \n","Epoch: [4][50/151] Elapsed 0m 18s (remain 0m 35s) \n","Epoch: [4][100/151] Elapsed 0m 34s (remain 0m 17s) \n","Epoch: [4][150/151] Elapsed 0m 50s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.4001  avg_val_loss: 0.6016  time: 55s\n","Epoch 4 - Score: 0.7305\n","Epoch 4 - Save Best Score: 0.7305 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [5][0/151] Elapsed 0m 0s (remain 1m 10s) \n","Epoch: [5][50/151] Elapsed 0m 18s (remain 0m 36s) \n","Epoch: [5][100/151] Elapsed 0m 36s (remain 0m 17s) \n","Epoch: [5][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.2805  avg_val_loss: 0.6555  time: 56s\n","Epoch 5 - Score: 0.7053\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [6][0/151] Elapsed 0m 0s (remain 0m 52s) \n","Epoch: [6][50/151] Elapsed 0m 16s (remain 0m 32s) \n","Epoch: [6][100/151] Elapsed 0m 34s (remain 0m 16s) \n","Epoch: [6][150/151] Elapsed 0m 51s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.1842  avg_val_loss: 0.7138  time: 56s\n","Epoch 6 - Score: 0.7296\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [7][0/151] Elapsed 0m 0s (remain 0m 58s) \n","Epoch: [7][50/151] Elapsed 0m 17s (remain 0m 34s) \n","Epoch: [7][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [7][150/151] Elapsed 0m 51s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.1045  avg_val_loss: 0.8909  time: 56s\n","Epoch 7 - Score: 0.6954\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n","Epoch: [8][0/151] Elapsed 0m 0s (remain 0m 52s) \n","Epoch: [8][50/151] Elapsed 0m 17s (remain 0m 34s) \n","Epoch: [8][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [8][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0673  avg_val_loss: 0.8810  time: 57s\n","Epoch 8 - Score: 0.7381\n","Epoch 8 - Save Best Score: 0.7381 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [9][0/151] Elapsed 0m 0s (remain 1m 6s) \n","Epoch: [9][50/151] Elapsed 0m 18s (remain 0m 36s) \n","Epoch: [9][100/151] Elapsed 0m 35s (remain 0m 17s) \n","Epoch: [9][150/151] Elapsed 0m 52s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0563  avg_val_loss: 0.9134  time: 56s\n","Epoch 9 - Score: 0.7387\n","Epoch 9 - Save Best Score: 0.7387 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 4s (remain 0m 0s) \n","Epoch: [10][0/151] Elapsed 0m 0s (remain 1m 37s) \n","Epoch: [10][50/151] Elapsed 0m 17s (remain 0m 33s) \n","Epoch: [10][100/151] Elapsed 0m 34s (remain 0m 17s) \n","Epoch: [10][150/151] Elapsed 0m 51s (remain 0m 0s) \n","EVAL: [0/19] Elapsed 0m 0s (remain 0m 8s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0464  avg_val_loss: 0.9164  time: 56s\n","Epoch 10 - Score: 0.7364\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [18/19] Elapsed 0m 3s (remain 0m 0s) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 4 result ==========\n","Score: 0.7387\n","========== CV ==========\n"]},{"output_type":"stream","name":"stdout","text":["0.7386594806051077\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.7327\n"]}]},{"cell_type":"code","source":["A = pd.read_csv(OUTPUT_MODEL_DIR+'oof_df.csv')\n","A.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"p7aGlmzxq_Zy","executionInfo":{"status":"ok","timestamp":1659647920352,"user_tz":-540,"elapsed":19,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"4ff5d6f3-4a43-4c69-b0d7-c73d03fcae0a"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id                                        description  label  \\\n","0   1   Designs and develops high quality, scalable a...      3   \n","1   9  Maintain and improve existing predictive model...      1   \n","2  10   Optimize deep learning frameworks like Tensor...      2   \n","3  26  Explore and evaluate new ML algorithms to opti...      1   \n","4  32   Optimizing our ML model and methods for deter...      2   \n","\n","                                              inputs  kfold  Consultant  \\\n","0   Designs and develops high quality, scalable a...      0   -1.282729   \n","1  Maintain and improve existing predictive model...      0   -0.521084   \n","2   Optimize deep learning frameworks like Tensor...      0   -2.937326   \n","3  Explore and evaluate new ML algorithms to opti...      0   -3.754522   \n","4   Optimizing our ML model and methods for deter...      0   -3.863037   \n","\n","   Data scientist  Machine learning engineer  Software engineer  \n","0       -2.773179                  -2.872591           5.333655  \n","1        5.992557                  -2.142767          -3.166550  \n","2       -0.239947                   5.709708          -0.982370  \n","3        3.016727                   3.990207          -2.201664  \n","4        3.374876                   3.804641          -1.566969  "],"text/html":["\n","  <div id=\"df-39402f3d-2f5c-43b0-88da-e45cc4e59658\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","      <th>label</th>\n","      <th>inputs</th>\n","      <th>kfold</th>\n","      <th>Consultant</th>\n","      <th>Data scientist</th>\n","      <th>Machine learning engineer</th>\n","      <th>Software engineer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Designs and develops high quality, scalable a...</td>\n","      <td>3</td>\n","      <td>Designs and develops high quality, scalable a...</td>\n","      <td>0</td>\n","      <td>-1.282729</td>\n","      <td>-2.773179</td>\n","      <td>-2.872591</td>\n","      <td>5.333655</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9</td>\n","      <td>Maintain and improve existing predictive model...</td>\n","      <td>1</td>\n","      <td>Maintain and improve existing predictive model...</td>\n","      <td>0</td>\n","      <td>-0.521084</td>\n","      <td>5.992557</td>\n","      <td>-2.142767</td>\n","      <td>-3.166550</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10</td>\n","      <td>Optimize deep learning frameworks like Tensor...</td>\n","      <td>2</td>\n","      <td>Optimize deep learning frameworks like Tensor...</td>\n","      <td>0</td>\n","      <td>-2.937326</td>\n","      <td>-0.239947</td>\n","      <td>5.709708</td>\n","      <td>-0.982370</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>26</td>\n","      <td>Explore and evaluate new ML algorithms to opti...</td>\n","      <td>1</td>\n","      <td>Explore and evaluate new ML algorithms to opti...</td>\n","      <td>0</td>\n","      <td>-3.754522</td>\n","      <td>3.016727</td>\n","      <td>3.990207</td>\n","      <td>-2.201664</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>32</td>\n","      <td>Optimizing our ML model and methods for deter...</td>\n","      <td>2</td>\n","      <td>Optimizing our ML model and methods for deter...</td>\n","      <td>0</td>\n","      <td>-3.863037</td>\n","      <td>3.374876</td>\n","      <td>3.804641</td>\n","      <td>-1.566969</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39402f3d-2f5c-43b0-88da-e45cc4e59658')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-39402f3d-2f5c-43b0-88da-e45cc4e59658 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-39402f3d-2f5c-43b0-88da-e45cc4e59658');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":[""],"metadata":{"id":"eCPvJIzF_W9x","executionInfo":{"status":"ok","timestamp":1659647920352,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":20,"outputs":[]}]}