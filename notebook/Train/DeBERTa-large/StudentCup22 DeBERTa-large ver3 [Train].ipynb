{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StudentCup22/DeBERTa-large ver3 [Train].ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNz1hTGSdQoFJmaPxryuUuE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"c732ab0c651e4fab861203e4b6abe737":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_89bed5ff26cc4620bbcd18a9710f9a0e","IPY_MODEL_d83ad40fa214487e8b388990c80f493d","IPY_MODEL_c72e46f5b0ef4e4aba711318f6c544b2"],"layout":"IPY_MODEL_b2f5aef251764e529acfa6c2d722a517","tabbable":null,"tooltip":null}},"89bed5ff26cc4620bbcd18a9710f9a0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_aac3240c1e0e4e65bec2798d02b98318","placeholder":"​","style":"IPY_MODEL_dede6135364e4c93b1d7811498048365","tabbable":null,"tooltip":null,"value":"Downloading tokenizer_config.json: 100%"}},"d83ad40fa214487e8b388990c80f493d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_d46ce6a61c3a4aeaa777f3681cfce691","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03e9c13fad334ad4a3bcf9a4819ece79","tabbable":null,"tooltip":null,"value":52}},"c72e46f5b0ef4e4aba711318f6c544b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_b59bbf8899c34dbcb5614a93479f43d2","placeholder":"​","style":"IPY_MODEL_c0e154f984bb45f68aa47704fda81fdf","tabbable":null,"tooltip":null,"value":" 52.0/52.0 [00:00&lt;00:00, 1.67kB/s]"}},"b2f5aef251764e529acfa6c2d722a517":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aac3240c1e0e4e65bec2798d02b98318":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dede6135364e4c93b1d7811498048365":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"d46ce6a61c3a4aeaa777f3681cfce691":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03e9c13fad334ad4a3bcf9a4819ece79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b59bbf8899c34dbcb5614a93479f43d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0e154f984bb45f68aa47704fda81fdf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"3dc4623582be43e8abc7ce83c0beb062":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_04d9d7b8f6be4993a29c3a13dc34518a","IPY_MODEL_d0ea860c5368456584169bb4d662bb85","IPY_MODEL_1dec0dddd30c4db4991dcb54d7e6daa0"],"layout":"IPY_MODEL_39afae6296e5485cb90fbf8fc130593d","tabbable":null,"tooltip":null}},"04d9d7b8f6be4993a29c3a13dc34518a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_0637c8b96c27412c99e541caa7a20b70","placeholder":"​","style":"IPY_MODEL_1e06f5c1cebf41e5ae2b865dac9a5c05","tabbable":null,"tooltip":null,"value":"Downloading config.json: 100%"}},"d0ea860c5368456584169bb4d662bb85":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_3178bb878fb34582a4579c4163a67a00","max":475,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5216a0652d454d3fa1f31a87103f0f98","tabbable":null,"tooltip":null,"value":475}},"1dec0dddd30c4db4991dcb54d7e6daa0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_9d9157b1dca84898a0c1ccd44aec392d","placeholder":"​","style":"IPY_MODEL_4af03a4e7cdd4b46b4f5a37fd2060f81","tabbable":null,"tooltip":null,"value":" 475/475 [00:00&lt;00:00, 12.9kB/s]"}},"39afae6296e5485cb90fbf8fc130593d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0637c8b96c27412c99e541caa7a20b70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e06f5c1cebf41e5ae2b865dac9a5c05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"3178bb878fb34582a4579c4163a67a00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5216a0652d454d3fa1f31a87103f0f98":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d9157b1dca84898a0c1ccd44aec392d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4af03a4e7cdd4b46b4f5a37fd2060f81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"fdc9878e1b61421f816698509a98d1a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d240d449ec0946f395a5fd5d95372243","IPY_MODEL_69bfaef6f4d64555aa512bd724da8e79","IPY_MODEL_dce72829133c4f8ba7ed295971950581"],"layout":"IPY_MODEL_abb2e15bd1aa4ca293a8bfa9851bd222","tabbable":null,"tooltip":null}},"d240d449ec0946f395a5fd5d95372243":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_cf1a636331e741cbbf0670ca7fcd1df0","placeholder":"​","style":"IPY_MODEL_0240c5460c3640328bb6e164827bf3da","tabbable":null,"tooltip":null,"value":"Downloading vocab.json: 100%"}},"69bfaef6f4d64555aa512bd724da8e79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_2da4e1021957455f96abc8b684751441","max":898825,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9ffac7dab1d645f19a31715af20651a1","tabbable":null,"tooltip":null,"value":898825}},"dce72829133c4f8ba7ed295971950581":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c75d01147a0e4e20a13259b2ea59880c","placeholder":"​","style":"IPY_MODEL_bba0b46eea2545fd91f2b213bc029522","tabbable":null,"tooltip":null,"value":" 878k/878k [00:00&lt;00:00, 6.97MB/s]"}},"abb2e15bd1aa4ca293a8bfa9851bd222":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf1a636331e741cbbf0670ca7fcd1df0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0240c5460c3640328bb6e164827bf3da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"2da4e1021957455f96abc8b684751441":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ffac7dab1d645f19a31715af20651a1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c75d01147a0e4e20a13259b2ea59880c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bba0b46eea2545fd91f2b213bc029522":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"b7a6937c562f44989970f91858831ba5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8aae111cd8704bcb9c89de5afacf3457","IPY_MODEL_404fd685497449ed94e943025aaad982","IPY_MODEL_0e452e0511f74ef7946b27a9223b5cad"],"layout":"IPY_MODEL_7ed0ef5624f64090b4b5f50650e86435","tabbable":null,"tooltip":null}},"8aae111cd8704bcb9c89de5afacf3457":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_446916e7c082489594ac23242be99f58","placeholder":"​","style":"IPY_MODEL_36ee6e9935614bb7ba0d32d56306ed3f","tabbable":null,"tooltip":null,"value":"Downloading merges.txt: 100%"}},"404fd685497449ed94e943025aaad982":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_892e1be7589e466688984a493a5a80b1","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_533037e830224992912dda6e70b3e919","tabbable":null,"tooltip":null,"value":456318}},"0e452e0511f74ef7946b27a9223b5cad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_5c8403081d774b73bdcced7e0e0ce652","placeholder":"​","style":"IPY_MODEL_0ac493de74324a478b8cbcd30146653d","tabbable":null,"tooltip":null,"value":" 446k/446k [00:00&lt;00:00, 4.50MB/s]"}},"7ed0ef5624f64090b4b5f50650e86435":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"446916e7c082489594ac23242be99f58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36ee6e9935614bb7ba0d32d56306ed3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"892e1be7589e466688984a493a5a80b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"533037e830224992912dda6e70b3e919":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c8403081d774b73bdcced7e0e0ce652":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ac493de74324a478b8cbcd30146653d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"21fe79b4897641888e1ed567c5e93db1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7f271382f684c98985d538976dd1abb","IPY_MODEL_24ecec73ed87401b8c0f7afabde3a82d","IPY_MODEL_78cd957f6e3a47ee93a73b61b6250164"],"layout":"IPY_MODEL_bc1396ec1c2a4890a37299c932721768","tabbable":null,"tooltip":null}},"e7f271382f684c98985d538976dd1abb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_94c7853391a1423f8f33ecb7330f4f5c","placeholder":"​","style":"IPY_MODEL_487a8564aa994260ad38df3ec22c4e25","tabbable":null,"tooltip":null,"value":"Downloading pytorch_model.bin: 100%"}},"24ecec73ed87401b8c0f7afabde3a82d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_e2318a6410d64d37856fefead7feac13","max":1627284589,"min":0,"orientation":"horizontal","style":"IPY_MODEL_acb89636efe7427d926ad927aa59e515","tabbable":null,"tooltip":null,"value":1627284589}},"78cd957f6e3a47ee93a73b61b6250164":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e1b9e12cfed0430fb096cec1a0fca0c0","placeholder":"​","style":"IPY_MODEL_9f02d8bbc73d43d09df4f148cf0c27f9","tabbable":null,"tooltip":null,"value":" 1.52G/1.52G [00:29&lt;00:00, 66.0MB/s]"}},"bc1396ec1c2a4890a37299c932721768":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94c7853391a1423f8f33ecb7330f4f5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"487a8564aa994260ad38df3ec22c4e25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"e2318a6410d64d37856fefead7feac13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acb89636efe7427d926ad927aa59e515":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1b9e12cfed0430fb096cec1a0fca0c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f02d8bbc73d43d09df4f148cf0c27f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BySnjPX7PXz5","executionInfo":{"status":"ok","timestamp":1661138422697,"user_tz":-540,"elapsed":17835,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"4cd8006b-95be-453e-d9d5-3bcbdafd0a35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75m2xhfBPqp4","executionInfo":{"status":"ok","timestamp":1661138431187,"user_tz":-540,"elapsed":8493,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"e2d4a798-c856-4436-dbd7-4f8ad8735697"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 6.9 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 13.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.8.1 tokenizers-0.12.1 transformers-4.21.1\n"]}]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eba8I100PsyG","executionInfo":{"status":"ok","timestamp":1661138434690,"user_tz":-540,"elapsed":3507,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"64769be4-eb3d-4c74-cd88-c427786217db"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 5.3 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"code","source":["import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"o8r0GW8uPvH1","executionInfo":{"status":"ok","timestamp":1661138440098,"user_tz":-540,"elapsed":5415,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["INPUT_DIR = '/content/drive/MyDrive/Competitions/Signate/Student Cup 2022/input/'\n","OUTPUT_DIR = '/content/drive/MyDrive/Competitions/Signate/Student Cup 2022/output/'\n","OUTPUT_SUB_DIR = os.path.join(OUTPUT_DIR,'Submission')\n","OUTPUT_MODEL_DIR = os.path.join(OUTPUT_DIR,'Model/DeBERTa-large[ver3]/')"],"metadata":{"id":"5ZzXtBUuP3Xo","executionInfo":{"status":"ok","timestamp":1661138440099,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class CFG:\n","    wandb = False\n","    apex = True\n","    model = 'microsoft/deberta-large'\n","    seed = 42\n","    n_splits = 5\n","    max_len = 1024\n","    dropout = 0.2\n","    target_size=4\n","    n_accumulate=1\n","    print_freq = 50\n","    min_lr=1e-6\n","    scheduler = 'cosine'\n","    batch_size = 16\n","    num_workers = 2\n","    lr = 3e-5\n","    weigth_decay = 0.01\n","    epochs = 10\n","    n_fold = 5\n","    trn_fold = [0, 1, 2, 3, 4]\n","    train = True \n","    num_warmup_steps = 0\n","    num_cycles=0.5\n","    debug = False\n","    debug_ver2 = False\n","    gradient_checkpointing = True\n","    freezing = True"],"metadata":{"id":"eHaPjAWUP9nl","executionInfo":{"status":"ok","timestamp":1661138440099,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Loss Func\n","def criterion(outputs, labels):\n","    return nn.CrossEntropyLoss()(outputs, labels)\n","\n","def softmax(z):\n","    assert len(z.shape) == 2\n","    s = np.max(z, axis=1)\n","    s = s[:, np.newaxis] # necessary step to do broadcasting\n","    e_x = np.exp(z - s)\n","    div = np.sum(e_x, axis=1)\n","    div = div[:, np.newaxis] # dito\n","    return e_x / div\n","\"\"\"\n","def get_score(y_true, y_pred):\n","    y_pred = softmax(y_pred)\n","    score = log_loss(y_true, y_pred)\n","    return round(score, 5)\n","\"\"\"\n","def get_score(outputs, labels):\n","    outputs = F.softmax(torch.tensor(outputs)).numpy()\n","    return f1_score(np.argmax(outputs,axis=1),labels ,average='macro')\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)\n","\n","def prepare_input(cfg, text, text_2=None):\n","    inputs = cfg.tokenizer(text, text_2,\n","                           padding=\"max_length\",\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           truncation=True)\n","\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","        \n","    return inputs"],"metadata":{"id":"HtdolflkQF-N","executionInfo":{"status":"ok","timestamp":1661138440920,"user_tz":-540,"elapsed":824,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"I-zmI7wcQIWQ","executionInfo":{"status":"ok","timestamp":1661138440921,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train = pd.read_csv(os.path.join(INPUT_DIR, 'train.csv'))\n","test = pd.read_csv(os.path.join(INPUT_DIR, 'test.csv'))\n","submission_df = pd.read_csv(os.path.join(INPUT_DIR, 'submit_sample.csv'))\n","\n","display(train.head())\n","print(train.shape)\n","display(test.head())\n","print(test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"u0MWWeigQQ-m","executionInfo":{"status":"ok","timestamp":1661138441556,"user_tz":-540,"elapsed":638,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"88d76cc4-1338-481e-fafb-7e4d10fb0fa7"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["   id                                        description  jobflag\n","0   0  <li>Develop cutting-edge web applications that...        3\n","1   1  <li> Designs and develops high quality, scalab...        3\n","2   2  <li>Functions as a point person for Network St...        4\n","3   3  <li> Work on the technical design, development...        3\n","4   4  <li>Quantify the resources required for a task...        4"],"text/html":["\n","  <div id=\"df-9db93014-2565-41c1-bdba-c3cba7517dac\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","      <th>jobflag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>&lt;li&gt;Develop cutting-edge web applications that...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>&lt;li&gt; Designs and develops high quality, scalab...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>&lt;li&gt;Functions as a point person for Network St...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>&lt;li&gt; Work on the technical design, development...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>&lt;li&gt;Quantify the resources required for a task...</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9db93014-2565-41c1-bdba-c3cba7517dac')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9db93014-2565-41c1-bdba-c3cba7517dac button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9db93014-2565-41c1-bdba-c3cba7517dac');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(1516, 3)\n"]},{"output_type":"display_data","data":{"text/plain":["     id                                        description\n","0  1516  <li>Building decision-making models and propos...\n","1  1517  <li>Educate homeowners on the benefits of sola...\n","2  1518  <li><span>Design, develop, document, and imple...\n","3  1519  <li>Apply advanced technical expertise and ski...\n","4  1520  <li>Project manage and deliver against our roa..."],"text/html":["\n","  <div id=\"df-1661b9af-a3a9-4362-ba79-163c9f2e2fa0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1516</td>\n","      <td>&lt;li&gt;Building decision-making models and propos...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1517</td>\n","      <td>&lt;li&gt;Educate homeowners on the benefits of sola...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1518</td>\n","      <td>&lt;li&gt;&lt;span&gt;Design, develop, document, and imple...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1519</td>\n","      <td>&lt;li&gt;Apply advanced technical expertise and ski...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1520</td>\n","      <td>&lt;li&gt;Project manage and deliver against our roa...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1661b9af-a3a9-4362-ba79-163c9f2e2fa0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1661b9af-a3a9-4362-ba79-163c9f2e2fa0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1661b9af-a3a9-4362-ba79-163c9f2e2fa0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(1517, 2)\n"]}]},{"cell_type":"code","source":["def remove_tag(x):\n","    p = re.compile(r\"<[^>]*?>\")\n","    return p.sub('',x)\n","\n","def cleaning(texts):\n","    clean_texts = []\n","    for text in texts:\n","        # htmlタグを削除\n","        text = remove_tag(text)\n","        #アルファベット以外をスペースに置き換え\n","        #clean_punc = re.sub(r'[^a-zA-Z]', ' ', text)\n","        clean_texts.append(text)\n","    return clean_texts\n","\n","\n","\n","from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n","    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n","\n","\n","def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n","    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n","\n","# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n","codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n","codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n","\n","def resolve_encodings_and_normalize(text: str) -> str:\n","    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n","    text = (\n","        text.encode(\"raw_unicode_escape\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","    )\n","    text = unidecode(text)\n","    return text\n","\n","train['description'] = cleaning(train['description'])\n","test['description'] = cleaning(test['description'])\n","train['inputs'] = train['description'].apply(lambda x : resolve_encodings_and_normalize(x))\n","test['inputs'] = test['description'].apply(lambda x : resolve_encodings_and_normalize(x))\n","train.drop_duplicates(subset=['inputs'],keep='first',inplace=True)\n","train = train.reset_index(drop=True)\n","train = train.rename(columns = {\"jobflag\": \"label\"})\n","train[\"label\"] = train[\"label\"] -1\n","train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"VzIaDXs2Qc02","executionInfo":{"status":"ok","timestamp":1661138442174,"user_tz":-540,"elapsed":624,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"d7140aff-17fe-4c42-9ca2-4388c2b55d83"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id                                        description  label  \\\n","0        0  Develop cutting-edge web applications that per...      2   \n","1        1   Designs and develops high quality, scalable a...      2   \n","2        2  Functions as a point person for Network Strate...      3   \n","3        3   Work on the technical design, development, re...      2   \n","4        4  Quantify the resources required for a task/pro...      3   \n","...    ...                                                ...    ...   \n","1499  1511  Support detailed reporting, statistical analys...      0   \n","1500  1512  Collaborate with teams to support the ML techn...      1   \n","1501  1513   Work with executives and other business leade...      0   \n","1502  1514  Leading design ideation sessions to ensure we ...      2   \n","1503  1515  Detection of Issues &amp; Impact Assessments e...      0   \n","\n","                                                 inputs  \n","0     Develop cutting-edge web applications that per...  \n","1      Designs and develops high quality, scalable a...  \n","2     Functions as a point person for Network Strate...  \n","3      Work on the technical design, development, re...  \n","4     Quantify the resources required for a task/pro...  \n","...                                                 ...  \n","1499  Support detailed reporting, statistical analys...  \n","1500  Collaborate with teams to support the ML techn...  \n","1501   Work with executives and other business leade...  \n","1502  Leading design ideation sessions to ensure we ...  \n","1503  Detection of Issues &amp; Impact Assessments e...  \n","\n","[1504 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-b462eeef-3abe-49a3-a591-3117bd3b55d2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","      <th>label</th>\n","      <th>inputs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Develop cutting-edge web applications that per...</td>\n","      <td>2</td>\n","      <td>Develop cutting-edge web applications that per...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Designs and develops high quality, scalable a...</td>\n","      <td>2</td>\n","      <td>Designs and develops high quality, scalable a...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Functions as a point person for Network Strate...</td>\n","      <td>3</td>\n","      <td>Functions as a point person for Network Strate...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Work on the technical design, development, re...</td>\n","      <td>2</td>\n","      <td>Work on the technical design, development, re...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Quantify the resources required for a task/pro...</td>\n","      <td>3</td>\n","      <td>Quantify the resources required for a task/pro...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1499</th>\n","      <td>1511</td>\n","      <td>Support detailed reporting, statistical analys...</td>\n","      <td>0</td>\n","      <td>Support detailed reporting, statistical analys...</td>\n","    </tr>\n","    <tr>\n","      <th>1500</th>\n","      <td>1512</td>\n","      <td>Collaborate with teams to support the ML techn...</td>\n","      <td>1</td>\n","      <td>Collaborate with teams to support the ML techn...</td>\n","    </tr>\n","    <tr>\n","      <th>1501</th>\n","      <td>1513</td>\n","      <td>Work with executives and other business leade...</td>\n","      <td>0</td>\n","      <td>Work with executives and other business leade...</td>\n","    </tr>\n","    <tr>\n","      <th>1502</th>\n","      <td>1514</td>\n","      <td>Leading design ideation sessions to ensure we ...</td>\n","      <td>2</td>\n","      <td>Leading design ideation sessions to ensure we ...</td>\n","    </tr>\n","    <tr>\n","      <th>1503</th>\n","      <td>1515</td>\n","      <td>Detection of Issues &amp;amp; Impact Assessments e...</td>\n","      <td>0</td>\n","      <td>Detection of Issues &amp;amp; Impact Assessments e...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1504 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b462eeef-3abe-49a3-a591-3117bd3b55d2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b462eeef-3abe-49a3-a591-3117bd3b55d2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b462eeef-3abe-49a3-a591-3117bd3b55d2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CFG.n_splits,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train.label)):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","train[\"kfold\"] = train[\"kfold\"].astype(int)"],"metadata":{"id":"-Oaxhj1tQqyH","executionInfo":{"status":"ok","timestamp":1661138442175,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_MODEL_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer\n","SEP = tokenizer.sep_token"],"metadata":{"id":"JozVPxKoRCCj","executionInfo":{"status":"ok","timestamp":1661138444176,"user_tz":-540,"elapsed":2004,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["c732ab0c651e4fab861203e4b6abe737","89bed5ff26cc4620bbcd18a9710f9a0e","d83ad40fa214487e8b388990c80f493d","c72e46f5b0ef4e4aba711318f6c544b2","b2f5aef251764e529acfa6c2d722a517","aac3240c1e0e4e65bec2798d02b98318","dede6135364e4c93b1d7811498048365","d46ce6a61c3a4aeaa777f3681cfce691","03e9c13fad334ad4a3bcf9a4819ece79","b59bbf8899c34dbcb5614a93479f43d2","c0e154f984bb45f68aa47704fda81fdf","3dc4623582be43e8abc7ce83c0beb062","04d9d7b8f6be4993a29c3a13dc34518a","d0ea860c5368456584169bb4d662bb85","1dec0dddd30c4db4991dcb54d7e6daa0","39afae6296e5485cb90fbf8fc130593d","0637c8b96c27412c99e541caa7a20b70","1e06f5c1cebf41e5ae2b865dac9a5c05","3178bb878fb34582a4579c4163a67a00","5216a0652d454d3fa1f31a87103f0f98","9d9157b1dca84898a0c1ccd44aec392d","4af03a4e7cdd4b46b4f5a37fd2060f81","fdc9878e1b61421f816698509a98d1a1","d240d449ec0946f395a5fd5d95372243","69bfaef6f4d64555aa512bd724da8e79","dce72829133c4f8ba7ed295971950581","abb2e15bd1aa4ca293a8bfa9851bd222","cf1a636331e741cbbf0670ca7fcd1df0","0240c5460c3640328bb6e164827bf3da","2da4e1021957455f96abc8b684751441","9ffac7dab1d645f19a31715af20651a1","c75d01147a0e4e20a13259b2ea59880c","bba0b46eea2545fd91f2b213bc029522","b7a6937c562f44989970f91858831ba5","8aae111cd8704bcb9c89de5afacf3457","404fd685497449ed94e943025aaad982","0e452e0511f74ef7946b27a9223b5cad","7ed0ef5624f64090b4b5f50650e86435","446916e7c082489594ac23242be99f58","36ee6e9935614bb7ba0d32d56306ed3f","892e1be7589e466688984a493a5a80b1","533037e830224992912dda6e70b3e919","5c8403081d774b73bdcced7e0e0ce652","0ac493de74324a478b8cbcd30146653d"]},"outputId":"687897b4-d5ad-4d02-c8a6-b361dc128458"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c732ab0c651e4fab861203e4b6abe737"},"application/json":{"n":0,"total":52,"elapsed":0.023038864135742188,"ncols":null,"nrows":null,"prefix":"Downloading tokenizer_config.json","ascii":false,"unit":"B","unit_scale":true,"rate":null,"bar_format":null,"postfix":null,"unit_divisor":1024,"initial":0,"colour":null}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/475 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dc4623582be43e8abc7ce83c0beb062"},"application/json":{"n":0,"total":475,"elapsed":0.026465415954589844,"ncols":null,"nrows":null,"prefix":"Downloading config.json","ascii":false,"unit":"B","unit_scale":true,"rate":null,"bar_format":null,"postfix":null,"unit_divisor":1024,"initial":0,"colour":null}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdc9878e1b61421f816698509a98d1a1"},"application/json":{"n":0,"total":898825,"elapsed":0.018637418746948242,"ncols":null,"nrows":null,"prefix":"Downloading vocab.json","ascii":false,"unit":"B","unit_scale":true,"rate":null,"bar_format":null,"postfix":null,"unit_divisor":1024,"initial":0,"colour":null}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7a6937c562f44989970f91858831ba5"},"application/json":{"n":0,"total":456318,"elapsed":0.018208980560302734,"ncols":null,"nrows":null,"prefix":"Downloading merges.txt","ascii":false,"unit":"B","unit_scale":true,"rate":null,"bar_format":null,"postfix":null,"unit_divisor":1024,"initial":0,"colour":null}},"metadata":{}}]},{"cell_type":"code","source":["class Dataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length):\n","        self.df = df\n","        self.max_len = CFG.max_len\n","        self.text = df['inputs'].values\n","        self.tokenizer = CFG.tokenizer\n","        self.targets = df['label'].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        text = self.text[index]\n","        inputs = tokenizer.encode_plus(\n","            text,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length = self.max_len\n","        )\n","        samples = {\n","            'input_ids': inputs['input_ids'],\n","            'attention_mask': inputs['attention_mask'],\n","            'target': self.targets[index]\n","        }\n","\n","        if 'token_type_ids' in inputs:\n","            samples['token_type_ids'] = inputs['token_type_ids']\n","            \n","        return samples"],"metadata":{"id":"0-62YNlsRGQ8","executionInfo":{"status":"ok","timestamp":1661138444176,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Dynamic Padding (Collate)\n","#collate_fn = DataCollatorWithPadding(tokenizer=CFG.tokenizer)\n","class Collate:\n","    def __init__(self, tokenizer, isTrain=True):\n","        self.tokenizer = tokenizer\n","        self.isTrain = isTrain\n","        # self.args = args\n","\n","    def __call__(self, batch):\n","        output = dict()\n","        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n","        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n","        if self.isTrain:\n","            output[\"target\"] = [sample[\"target\"] for sample in batch]\n","\n","        # calculate max token length of this batch\n","        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n","        else:\n","            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n","\n","        # convert to tensors\n","        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n","        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n","        if self.isTrain:\n","            output[\"target\"] = torch.tensor(output[\"target\"], dtype=torch.long)\n","\n","        return output\n","    \n","collate_fn = Collate(CFG.tokenizer, isTrain=True)"],"metadata":{"id":"_sh69Da6RQFz","executionInfo":{"status":"ok","timestamp":1661138444176,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9) #\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings"],"metadata":{"id":"H_GyjbDnRStd","executionInfo":{"status":"ok","timestamp":1661138444620,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, model_name):\n","        super(CustomModel, self).__init__()\n","        # Header (fast or normal)\n","        self.model = AutoModel.from_pretrained(model_name)\n","        \n","        # Gradient_checkpointing\n","        if CFG.gradient_checkpointing:\n","            (self.model).gradient_checkpointing_enable()\n","        \n","        # Freezing\n","        if CFG.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            CFG.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","        \n","        self.config = AutoConfig.from_pretrained(model_name)\n","        self.drop = nn.Dropout(p=CFG.dropout)\n","        #self.pooler = MeanPooling()\n","        self.dropout1 = nn.Dropout(0.1)\n","        self.dropout2 = nn.Dropout(0.2)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.dropout4 = nn.Dropout(0.4)\n","        self.dropout5 = nn.Dropout(0.5)\n","        self.output = nn.Sequential( nn.Linear(self.config.hidden_size, CFG.target_size) )\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def forward(self, ids, mask):        \n","        output = self.model(input_ids=ids, \n","                         attention_mask=mask,\n","                         output_hidden_states=False)\n","        output = output[0][:, 0, :]\n","        logits1 = self.output(self.dropout1(output))\n","        logits2 = self.output(self.dropout2(output))\n","        logits3 = self.output(self.dropout3(output))\n","        logits4 = self.output(self.dropout4(output))\n","        logits5 = self.output(self.dropout5(output))\n","        outputs = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n","        return outputs"],"metadata":{"id":"Tm7w8yAcRVP3","executionInfo":{"status":"ok","timestamp":1661138444621,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def asMinutes(s):\n","    m = math.floor(s/60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","def get_scheduler(cfg, optimizer, num_train_steps):\n","    if cfg.scheduler == 'linear':\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","        )\n","    elif cfg.scheduler == 'cosine':\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","        )\n","    return scheduler\n","\n","def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n","    model.train()\n","\n","    dataset_size = 0\n","    running_loss = 0\n","\n","    start = end = time.time()\n","\n","    for step, data in enumerate(dataloader):\n","        ids = data['input_ids'].to(device, dtype=torch.long)\n","        mask = data['attention_mask'].to(device, dtype=torch.long)\n","        targets = data['target'].to(device, dtype=torch.long)\n","\n","        batch_size = ids.size(0)\n","        \n","        outputs = model(ids, mask)\n","        loss = criterion(outputs, targets)\n","\n","        #accumulate\n","        loss = loss / CFG.n_accumulate \n","        loss.backward()\n","        if (step +1) % CFG.n_accumulate == 0:\n","            optimizer.step()\n","\n","            optimizer.zero_grad()\n","            if scheduler is not None:\n","                scheduler.step()\n","        running_loss += (loss.item() * batch_size)\n","        dataset_size += batch_size\n","\n","        epoch_loss = running_loss / dataset_size\n","\n","        end = time.time()\n","        \n","        if step % CFG.print_freq == 0 or step == (len(dataloader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  .format(epoch+1, step, len(dataloader), \n","                          remain=timeSince(start, float(step+1)/len(dataloader))))\n","\n","    gc.collect()\n","\n","    return epoch_loss\n","\n","\n","@torch.no_grad()\n","def valid_one_epoch(model, dataloader, device, epoch):\n","    model.eval()\n","\n","    dataset_size = 0\n","    running_loss = 0\n","\n","    start = end = time.time()\n","    pred = []\n","\n","    for step, data in enumerate(dataloader):\n","        ids = data['input_ids'].to(device, dtype=torch.long)\n","        mask = data['attention_mask'].to(device, dtype=torch.long)\n","        targets = data['target'].to(device, dtype=torch.long)\n","\n","        batch_size = ids.size(0)\n","        outputs = model(ids, mask)\n","        loss = criterion(outputs, targets)\n","        pred.append(outputs.to('cpu').numpy())\n","\n","        running_loss += (loss.item()* batch_size)\n","        dataset_size += batch_size\n","\n","        epoch_loss = running_loss / dataset_size\n","\n","        end = time.time()\n","\n","        if step % CFG.print_freq == 0 or step == (len(dataloader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  .format(step, len(dataloader),\n","                          remain=timeSince(start, float(step+1)/len(dataloader))))\n","            \n","    pred = np.concatenate(pred)\n","            \n","    return epoch_loss, pred"],"metadata":{"id":"TEFbXjOCRguX","executionInfo":{"status":"ok","timestamp":1661138444621,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def train_loop(fold):\n","    #wandb.watch(model, log_freq=100)\n","\n","    LOGGER.info(f'-------------fold:{fold} training-------------')\n","\n","    train_data = train[train.kfold != fold].reset_index(drop=True)\n","    valid_data = train[train.kfold == fold].reset_index(drop=True)\n","    valid_labels = valid_data.label.values\n","\n","    trainDataset = Dataset(train_data, CFG.tokenizer, CFG.max_len)\n","    validDataset = Dataset(valid_data, CFG.tokenizer, CFG.max_len)\n","\n","    train_loader = DataLoader(trainDataset,\n","                              batch_size = CFG.batch_size,\n","                              shuffle=True,\n","                              collate_fn = collate_fn,\n","                              num_workers = CFG.num_workers,\n","                              pin_memory = True,\n","                              drop_last=True)\n","    \n","    valid_loader = DataLoader(validDataset,\n","                              batch_size = CFG.batch_size*2,\n","                              shuffle=False,\n","                              collate_fn = collate_fn,\n","                              num_workers = CFG.num_workers,\n","                              pin_memory = True,\n","                              drop_last=False)\n","    \n","    model = CustomModel(CFG.model)\n","    torch.save(model.config, OUTPUT_MODEL_DIR+'config.pth')\n","    model.to(device)\n","    optimizer = AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weigth_decay)\n","    num_train_steps = int(len(train_data) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # loop\n","    best_score = 0\n","\n","    for epoch in range(CFG.epochs):\n","        start_time = time.time()\n","\n","        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, train_loader, device, epoch)\n","        valid_epoch_loss, pred = valid_one_epoch(model, valid_loader, device, epoch)\n","\n","        score = get_score(pred, valid_labels)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {train_epoch_loss:.4f}  avg_val_loss: {valid_epoch_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                       f\"[fold{fold}] avg_train_loss\": train_epoch_loss, \n","                       f\"[fold{fold}] avg_val_loss\": valid_epoch_loss,\n","                       f\"[fold{fold}] score\": score})\n","            \n","        if score > best_score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': pred},\n","                        OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","            \n","    predictions = torch.load(OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_data['Data scientist'] = predictions[:, 0]\n","    valid_data['Machine learning engineer'] = predictions[:, 1]\n","    valid_data['Software engineer'] = predictions[:, 2]\n","    valid_data['Consultant'] = predictions[:, 3]\n","    \n","    \n","    temp = valid_data[['Data scientist','Machine learning engineer','Software engineer','Consultant']].values.tolist()\n","    print(get_score(temp, valid_data['label'].values))\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_data"],"metadata":{"id":"Iftyf0agiWRJ","executionInfo":{"status":"ok","timestamp":1661138444621,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['label'].values\n","        preds = oof_df[['Data scientist','Machine learning engineer','Software engineer','Consultant']].values.tolist()\n","        score = get_score(preds, labels)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')\n","        oof_df.to_csv(OUTPUT_MODEL_DIR+f'oof_df.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["21fe79b4897641888e1ed567c5e93db1","e7f271382f684c98985d538976dd1abb","24ecec73ed87401b8c0f7afabde3a82d","78cd957f6e3a47ee93a73b61b6250164","bc1396ec1c2a4890a37299c932721768","94c7853391a1423f8f33ecb7330f4f5c","487a8564aa994260ad38df3ec22c4e25","e2318a6410d64d37856fefead7feac13","acb89636efe7427d926ad927aa59e515","e1b9e12cfed0430fb096cec1a0fca0c0","9f02d8bbc73d43d09df4f148cf0c27f9"]},"id":"0DG0hD6XiZ2S","executionInfo":{"status":"error","timestamp":1661150437848,"user_tz":-540,"elapsed":11993231,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"83b8eb58-7064-4a45-a300-144873c7cd9a"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["-------------fold:0 training-------------\n","INFO:__main__:-------------fold:0 training-------------\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21fe79b4897641888e1ed567c5e93db1"},"application/json":{"n":0,"total":1627284589,"elapsed":0.03737831115722656,"ncols":null,"nrows":null,"prefix":"Downloading pytorch_model.bin","ascii":false,"unit":"B","unit_scale":true,"rate":null,"bar_format":null,"postfix":null,"unit_divisor":1024,"initial":0,"colour":null}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/75] Elapsed 0m 7s (remain 8m 57s) \n","Epoch: [1][50/75] Elapsed 3m 46s (remain 1m 46s) \n","Epoch: [1][74/75] Elapsed 5m 48s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 3s (remain 0m 29s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.9592  avg_val_loss: 0.6611  time: 379s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.9592  avg_val_loss: 0.6611  time: 379s\n","Epoch 1 - Score: 0.5669\n","INFO:__main__:Epoch 1 - Score: 0.5669\n","Epoch 1 - Save Best Score: 0.5669 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5669 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 30s (remain 0m 0s) \n","Epoch: [2][0/75] Elapsed 0m 3s (remain 4m 14s) \n","Epoch: [2][50/75] Elapsed 3m 54s (remain 1m 50s) \n","Epoch: [2][74/75] Elapsed 5m 45s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 3s (remain 0m 29s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.6021  avg_val_loss: 0.5999  time: 376s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.6021  avg_val_loss: 0.5999  time: 376s\n","Epoch 2 - Score: 0.7109\n","INFO:__main__:Epoch 2 - Score: 0.7109\n","Epoch 2 - Save Best Score: 0.7109 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7109 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 30s (remain 0m 0s) \n","Epoch: [3][0/75] Elapsed 0m 3s (remain 4m 14s) \n","Epoch: [3][50/75] Elapsed 4m 7s (remain 1m 56s) \n","Epoch: [3][74/75] Elapsed 5m 57s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 3s (remain 0m 29s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3940  avg_val_loss: 0.6996  time: 388s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3940  avg_val_loss: 0.6996  time: 388s\n","Epoch 3 - Score: 0.7393\n","INFO:__main__:Epoch 3 - Score: 0.7393\n","Epoch 3 - Save Best Score: 0.7393 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7393 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 30s (remain 0m 0s) \n","Epoch: [4][0/75] Elapsed 0m 7s (remain 9m 19s) \n","Epoch: [4][50/75] Elapsed 3m 53s (remain 1m 49s) \n","Epoch: [4][74/75] Elapsed 5m 39s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 3s (remain 0m 29s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1801  avg_val_loss: 0.8315  time: 370s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1801  avg_val_loss: 0.8315  time: 370s\n","Epoch 4 - Score: 0.6946\n","INFO:__main__:Epoch 4 - Score: 0.6946\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 30s (remain 0m 0s) \n","Epoch: [5][0/75] Elapsed 0m 7s (remain 9m 19s) \n","Epoch: [5][50/75] Elapsed 4m 1s (remain 1m 53s) \n","Epoch: [5][74/75] Elapsed 5m 52s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 3s (remain 0m 29s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0808  avg_val_loss: 0.9803  time: 383s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0808  avg_val_loss: 0.9803  time: 383s\n","Epoch 5 - Score: 0.7057\n","INFO:__main__:Epoch 5 - Score: 0.7057\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 30s (remain 0m 0s) \n","Epoch: [6][0/75] Elapsed 0m 2s (remain 3m 20s) \n","Epoch: [6][50/75] Elapsed 4m 2s (remain 1m 54s) \n","Epoch: [6][74/75] Elapsed 5m 51s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 3s (remain 0m 30s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0435  avg_val_loss: 0.9514  time: 382s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0435  avg_val_loss: 0.9514  time: 382s\n","Epoch 6 - Score: 0.7325\n","INFO:__main__:Epoch 6 - Score: 0.7325\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 30s (remain 0m 0s) \n","Epoch: [7][0/75] Elapsed 0m 2s (remain 3m 7s) \n","Epoch: [7][50/75] Elapsed 4m 0s (remain 1m 53s) \n","Epoch: [7][74/75] Elapsed 5m 36s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 3s (remain 0m 29s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0070  avg_val_loss: 1.0592  time: 366s\n","INFO:__main__:Epoch 7 - avg_train_loss: 0.0070  avg_val_loss: 1.0592  time: 366s\n","Epoch 7 - Score: 0.7558\n","INFO:__main__:Epoch 7 - Score: 0.7558\n","Epoch 7 - Save Best Score: 0.7558 Model\n","INFO:__main__:Epoch 7 - Save Best Score: 0.7558 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 30s (remain 0m 0s) \n","Epoch: [8][0/75] Elapsed 0m 4s (remain 5m 6s) \n","Epoch: [8][50/75] Elapsed 3m 58s (remain 1m 52s) \n","Epoch: [8][74/75] Elapsed 5m 50s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 3s (remain 0m 29s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0034  avg_val_loss: 1.0893  time: 381s\n","INFO:__main__:Epoch 8 - avg_train_loss: 0.0034  avg_val_loss: 1.0893  time: 381s\n","Epoch 8 - Score: 0.7385\n","INFO:__main__:Epoch 8 - Score: 0.7385\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 30s (remain 0m 0s) \n","Epoch: [9][0/75] Elapsed 0m 6s (remain 8m 5s) \n","Epoch: [9][50/75] Elapsed 3m 49s (remain 1m 47s) \n","Epoch: [9][74/75] Elapsed 5m 57s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 3s (remain 0m 28s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0023  avg_val_loss: 1.0966  time: 387s\n","INFO:__main__:Epoch 9 - avg_train_loss: 0.0023  avg_val_loss: 1.0966  time: 387s\n","Epoch 9 - Score: 0.7385\n","INFO:__main__:Epoch 9 - Score: 0.7385\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 29s (remain 0m 0s) \n","Epoch: [10][0/75] Elapsed 0m 5s (remain 6m 31s) \n","Epoch: [10][50/75] Elapsed 4m 13s (remain 1m 59s) \n","Epoch: [10][74/75] Elapsed 5m 50s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 3s (remain 0m 29s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0023  avg_val_loss: 1.0955  time: 380s\n","INFO:__main__:Epoch 10 - avg_train_loss: 0.0023  avg_val_loss: 1.0955  time: 380s\n","Epoch 10 - Score: 0.7360\n","INFO:__main__:Epoch 10 - Score: 0.7360\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 30s (remain 0m 0s) \n","0.7558494527348809\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.7558\n","INFO:__main__:Score: 0.7558\n","-------------fold:1 training-------------\n","INFO:__main__:-------------fold:1 training-------------\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/75] Elapsed 0m 3s (remain 4m 31s) \n","Epoch: [1][50/75] Elapsed 4m 10s (remain 1m 57s) \n","Epoch: [1][74/75] Elapsed 6m 8s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 4s (remain 0m 42s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.9803  avg_val_loss: 1.0936  time: 395s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.9803  avg_val_loss: 1.0936  time: 395s\n","Epoch 1 - Score: 0.5789\n","INFO:__main__:Epoch 1 - Score: 0.5789\n","Epoch 1 - Save Best Score: 0.5789 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5789 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 26s (remain 0m 0s) \n","Epoch: [2][0/75] Elapsed 0m 2s (remain 3m 1s) \n","Epoch: [2][50/75] Elapsed 3m 57s (remain 1m 51s) \n","Epoch: [2][74/75] Elapsed 5m 59s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 4s (remain 0m 42s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5408  avg_val_loss: 0.6502  time: 386s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5408  avg_val_loss: 0.6502  time: 386s\n","Epoch 2 - Score: 0.6489\n","INFO:__main__:Epoch 2 - Score: 0.6489\n","Epoch 2 - Save Best Score: 0.6489 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.6489 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 26s (remain 0m 0s) \n","Epoch: [3][0/75] Elapsed 0m 5s (remain 7m 2s) \n","Epoch: [3][50/75] Elapsed 3m 53s (remain 1m 50s) \n","Epoch: [3][74/75] Elapsed 5m 51s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 4s (remain 0m 42s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2875  avg_val_loss: 0.6477  time: 379s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2875  avg_val_loss: 0.6477  time: 379s\n","Epoch 3 - Score: 0.6989\n","INFO:__main__:Epoch 3 - Score: 0.6989\n","Epoch 3 - Save Best Score: 0.6989 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.6989 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 26s (remain 0m 0s) \n","Epoch: [4][0/75] Elapsed 0m 4s (remain 6m 5s) \n","Epoch: [4][50/75] Elapsed 3m 46s (remain 1m 46s) \n","Epoch: [4][74/75] Elapsed 6m 2s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 4s (remain 0m 42s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1720  avg_val_loss: 0.7172  time: 389s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1720  avg_val_loss: 0.7172  time: 389s\n","Epoch 4 - Score: 0.7243\n","INFO:__main__:Epoch 4 - Score: 0.7243\n","Epoch 4 - Save Best Score: 0.7243 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7243 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 26s (remain 0m 0s) \n","Epoch: [5][0/75] Elapsed 0m 5s (remain 6m 31s) \n","Epoch: [5][50/75] Elapsed 4m 10s (remain 1m 58s) \n","Epoch: [5][74/75] Elapsed 6m 1s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 4s (remain 0m 42s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0566  avg_val_loss: 0.8998  time: 388s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0566  avg_val_loss: 0.8998  time: 388s\n","Epoch 5 - Score: 0.7125\n","INFO:__main__:Epoch 5 - Score: 0.7125\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 26s (remain 0m 0s) \n","Epoch: [6][0/75] Elapsed 0m 3s (remain 4m 5s) \n","Epoch: [6][50/75] Elapsed 3m 48s (remain 1m 47s) \n","Epoch: [6][74/75] Elapsed 5m 47s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 4s (remain 0m 42s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0108  avg_val_loss: 0.9588  time: 375s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0108  avg_val_loss: 0.9588  time: 375s\n","Epoch 6 - Score: 0.7410\n","INFO:__main__:Epoch 6 - Score: 0.7410\n","Epoch 6 - Save Best Score: 0.7410 Model\n","INFO:__main__:Epoch 6 - Save Best Score: 0.7410 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 26s (remain 0m 0s) \n","Epoch: [7][0/75] Elapsed 0m 2s (remain 3m 5s) \n","Epoch: [7][50/75] Elapsed 3m 59s (remain 1m 52s) \n","Epoch: [7][74/75] Elapsed 5m 49s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 4s (remain 0m 42s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0192  avg_val_loss: 0.9981  time: 376s\n","INFO:__main__:Epoch 7 - avg_train_loss: 0.0192  avg_val_loss: 0.9981  time: 376s\n","Epoch 7 - Score: 0.7155\n","INFO:__main__:Epoch 7 - Score: 0.7155\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 26s (remain 0m 0s) \n","Epoch: [8][0/75] Elapsed 0m 3s (remain 4m 49s) \n","Epoch: [8][50/75] Elapsed 4m 9s (remain 1m 57s) \n","Epoch: [8][74/75] Elapsed 5m 52s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 4s (remain 0m 42s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0068  avg_val_loss: 1.0144  time: 380s\n","INFO:__main__:Epoch 8 - avg_train_loss: 0.0068  avg_val_loss: 1.0144  time: 380s\n","Epoch 8 - Score: 0.7217\n","INFO:__main__:Epoch 8 - Score: 0.7217\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 26s (remain 0m 0s) \n","Epoch: [9][0/75] Elapsed 0m 5s (remain 7m 7s) \n","Epoch: [9][50/75] Elapsed 4m 17s (remain 2m 1s) \n","Epoch: [9][74/75] Elapsed 6m 4s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 4s (remain 0m 42s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0039  avg_val_loss: 1.0195  time: 391s\n","INFO:__main__:Epoch 9 - avg_train_loss: 0.0039  avg_val_loss: 1.0195  time: 391s\n","Epoch 9 - Score: 0.7215\n","INFO:__main__:Epoch 9 - Score: 0.7215\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 26s (remain 0m 0s) \n","Epoch: [10][0/75] Elapsed 0m 2s (remain 3m 37s) \n","Epoch: [10][50/75] Elapsed 4m 5s (remain 1m 55s) \n","Epoch: [10][74/75] Elapsed 5m 57s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 4s (remain 0m 42s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0032  avg_val_loss: 1.0205  time: 384s\n","INFO:__main__:Epoch 10 - avg_train_loss: 0.0032  avg_val_loss: 1.0205  time: 384s\n","Epoch 10 - Score: 0.7215\n","INFO:__main__:Epoch 10 - Score: 0.7215\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 26s (remain 0m 0s) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.7410\n","INFO:__main__:Score: 0.7410\n","-------------fold:2 training-------------\n","INFO:__main__:-------------fold:2 training-------------\n"]},{"output_type":"stream","name":"stdout","text":["0.7409758232826322\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/75] Elapsed 0m 2s (remain 3m 2s) \n","Epoch: [1][50/75] Elapsed 3m 55s (remain 1m 50s) \n","Epoch: [1][74/75] Elapsed 5m 43s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 2s (remain 0m 22s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.9811  avg_val_loss: 0.6581  time: 367s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.9811  avg_val_loss: 0.6581  time: 367s\n","Epoch 1 - Score: 0.6305\n","INFO:__main__:Epoch 1 - Score: 0.6305\n","Epoch 1 - Save Best Score: 0.6305 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6305 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 23s (remain 0m 0s) \n","Epoch: [2][0/75] Elapsed 0m 2s (remain 2m 42s) \n","Epoch: [2][50/75] Elapsed 3m 38s (remain 1m 42s) \n","Epoch: [2][74/75] Elapsed 5m 47s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 2s (remain 0m 22s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5909  avg_val_loss: 0.7291  time: 371s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5909  avg_val_loss: 0.7291  time: 371s\n","Epoch 2 - Score: 0.5658\n","INFO:__main__:Epoch 2 - Score: 0.5658\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 23s (remain 0m 0s) \n","Epoch: [3][0/75] Elapsed 0m 2s (remain 3m 16s) \n","Epoch: [3][50/75] Elapsed 3m 56s (remain 1m 51s) \n","Epoch: [3][74/75] Elapsed 5m 54s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 2s (remain 0m 22s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4139  avg_val_loss: 0.6849  time: 378s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.4139  avg_val_loss: 0.6849  time: 378s\n","Epoch 3 - Score: 0.7289\n","INFO:__main__:Epoch 3 - Score: 0.7289\n","Epoch 3 - Save Best Score: 0.7289 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7289 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 23s (remain 0m 0s) \n","Epoch: [4][0/75] Elapsed 0m 4s (remain 4m 58s) \n","Epoch: [4][50/75] Elapsed 4m 11s (remain 1m 58s) \n","Epoch: [4][74/75] Elapsed 6m 9s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 2s (remain 0m 22s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2279  avg_val_loss: 0.7824  time: 393s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2279  avg_val_loss: 0.7824  time: 393s\n","Epoch 4 - Score: 0.7301\n","INFO:__main__:Epoch 4 - Score: 0.7301\n","Epoch 4 - Save Best Score: 0.7301 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7301 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 23s (remain 0m 0s) \n","Epoch: [5][0/75] Elapsed 0m 5s (remain 6m 29s) \n","Epoch: [5][50/75] Elapsed 4m 8s (remain 1m 57s) \n","Epoch: [5][74/75] Elapsed 5m 56s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 2s (remain 0m 22s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0858  avg_val_loss: 0.9044  time: 380s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0858  avg_val_loss: 0.9044  time: 380s\n","Epoch 5 - Score: 0.7232\n","INFO:__main__:Epoch 5 - Score: 0.7232\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 23s (remain 0m 0s) \n","Epoch: [6][0/75] Elapsed 0m 3s (remain 4m 13s) \n","Epoch: [6][50/75] Elapsed 4m 5s (remain 1m 55s) \n","Epoch: [6][74/75] Elapsed 6m 0s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 2s (remain 0m 22s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6 - avg_train_loss: 0.0389  avg_val_loss: 0.9918  time: 384s\n","INFO:__main__:Epoch 6 - avg_train_loss: 0.0389  avg_val_loss: 0.9918  time: 384s\n","Epoch 6 - Score: 0.7411\n","INFO:__main__:Epoch 6 - Score: 0.7411\n","Epoch 6 - Save Best Score: 0.7411 Model\n","INFO:__main__:Epoch 6 - Save Best Score: 0.7411 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 23s (remain 0m 0s) \n","Epoch: [7][0/75] Elapsed 0m 10s (remain 12m 37s) \n","Epoch: [7][50/75] Elapsed 4m 16s (remain 2m 0s) \n","Epoch: [7][74/75] Elapsed 6m 6s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 2s (remain 0m 22s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7 - avg_train_loss: 0.0170  avg_val_loss: 1.1382  time: 390s\n","INFO:__main__:Epoch 7 - avg_train_loss: 0.0170  avg_val_loss: 1.1382  time: 390s\n","Epoch 7 - Score: 0.6948\n","INFO:__main__:Epoch 7 - Score: 0.6948\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 23s (remain 0m 0s) \n","Epoch: [8][0/75] Elapsed 0m 7s (remain 8m 54s) \n","Epoch: [8][50/75] Elapsed 4m 6s (remain 1m 56s) \n","Epoch: [8][74/75] Elapsed 6m 0s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 2s (remain 0m 22s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8 - avg_train_loss: 0.0054  avg_val_loss: 1.1033  time: 384s\n","INFO:__main__:Epoch 8 - avg_train_loss: 0.0054  avg_val_loss: 1.1033  time: 384s\n","Epoch 8 - Score: 0.7420\n","INFO:__main__:Epoch 8 - Score: 0.7420\n","Epoch 8 - Save Best Score: 0.7420 Model\n","INFO:__main__:Epoch 8 - Save Best Score: 0.7420 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 23s (remain 0m 0s) \n","Epoch: [9][0/75] Elapsed 0m 3s (remain 4m 13s) \n","Epoch: [9][50/75] Elapsed 4m 36s (remain 2m 9s) \n","Epoch: [9][74/75] Elapsed 6m 15s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 2s (remain 0m 22s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9 - avg_train_loss: 0.0042  avg_val_loss: 1.1188  time: 399s\n","INFO:__main__:Epoch 9 - avg_train_loss: 0.0042  avg_val_loss: 1.1188  time: 399s\n","Epoch 9 - Score: 0.7420\n","INFO:__main__:Epoch 9 - Score: 0.7420\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 23s (remain 0m 0s) \n","Epoch: [10][0/75] Elapsed 0m 5s (remain 7m 1s) \n","Epoch: [10][50/75] Elapsed 4m 29s (remain 2m 6s) \n","Epoch: [10][74/75] Elapsed 6m 21s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 2s (remain 0m 22s) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10 - avg_train_loss: 0.0034  avg_val_loss: 1.1206  time: 405s\n","INFO:__main__:Epoch 10 - avg_train_loss: 0.0034  avg_val_loss: 1.1206  time: 405s\n","Epoch 10 - Score: 0.7420\n","INFO:__main__:Epoch 10 - Score: 0.7420\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [9/10] Elapsed 0m 23s (remain 0m 0s) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.7420\n","INFO:__main__:Score: 0.7420\n","-------------fold:3 training-------------\n","INFO:__main__:-------------fold:3 training-------------\n"]},{"output_type":"stream","name":"stdout","text":["0.7420202660606812\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/75] Elapsed 0m 5s (remain 6m 34s) \n","Epoch: [1][50/75] Elapsed 4m 8s (remain 1m 56s) \n","Epoch: [1][74/75] Elapsed 5m 52s (remain 0m 0s) \n","EVAL: [0/10] Elapsed 0m 2s (remain 0m 18s) \n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-553280c22e61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_fold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0m_oof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0moof_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moof_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_oof_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"========== fold: {fold} result ==========\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-4f7766b011e5>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtrain_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mvalid_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-16bb79c228ae>\u001b[0m in \u001b[0;36mvalid_one_epoch\u001b[0;34m(model, dataloader, device, epoch)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-60b953386b4e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, mask)\u001b[0m\n\u001b[1;32m     45\u001b[0m         output = self.model(input_ids=ids, \n\u001b[1;32m     46\u001b[0m                          \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                          output_hidden_states=False)\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mlogits1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m         )\n\u001b[1;32m    964\u001b[0m         \u001b[0mencoded_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    454\u001b[0m                     \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m                 )\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m         )\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         )\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0mrel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mrel_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisentangled_att_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrel_att\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/deberta/modeling_deberta.py\u001b[0m in \u001b[0;36mdisentangled_att_bias\u001b[0;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mp2c_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_query_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             p2c_att = torch.gather(\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0mp2c_att\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp2c_dynamic_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2c_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             ).transpose(-1, -2)\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 906.00 MiB (GPU 0; 14.76 GiB total capacity; 11.56 GiB already allocated; 645.75 MiB free; 13.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["A = pd.read_csv(OUTPUT_MODEL_DIR+'oof_df.csv')\n","A.head()"],"metadata":{"id":"p7aGlmzxq_Zy","executionInfo":{"status":"aborted","timestamp":1661150437849,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"eCPvJIzF_W9x"},"execution_count":null,"outputs":[]}]}