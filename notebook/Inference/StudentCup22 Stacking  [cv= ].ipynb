{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StudentCup22/Stacking  [cv= ].ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPhW+ElWAIPYra8qPPNEO8D"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TgVUIAM51oHK","executionInfo":{"status":"ok","timestamp":1661349793000,"user_tz":-540,"elapsed":2815,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"ba03710f-a50e-408b-e821-39027c27ff34"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P8sgSe3J1skr","executionInfo":{"status":"ok","timestamp":1661349799964,"user_tz":-540,"elapsed":6973,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"3cbb8865-a5cf-4983-b43f-089c86392919"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"]}]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EZTz7Twh1uXy","executionInfo":{"status":"ok","timestamp":1661349805612,"user_tz":-540,"elapsed":5657,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"7ef6b552-786e-447d-bd4a-552134e27737"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n"]}]},{"cell_type":"code","source":["!pip install catboost"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-l4cT8XP7LXG","executionInfo":{"status":"ok","timestamp":1661349810282,"user_tz":-540,"elapsed":4682,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"56c2ba51-4b84-4970-9a2a-ae84d3645af2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.0.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n"]}]},{"cell_type":"code","source":["import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","from sklearn.linear_model import LogisticRegression\n","import lightgbm as lgb\n","import catboost as ctb\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"tb8E3Tfd1wZ4","executionInfo":{"status":"ok","timestamp":1661349827191,"user_tz":-540,"elapsed":16918,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["INPUT_DIR = '/content/drive/MyDrive/Competitions/Signate/Student Cup 2022/input/'\n","OUTPUT_DIR = '/content/drive/MyDrive/Competitions/Signate/Student Cup 2022/output/'\n","OUTPUT_SUB_DIR = os.path.join(OUTPUT_DIR,'Submission')\n","OUTPUT_MODEL_DIR1 = os.path.join(OUTPUT_DIR,'Model/DeBERTa-large/')  #0.7455 → 0.7717\n","OUTPUT_MODEL_DIR2 = os.path.join(OUTPUT_DIR,'Model/DeBERTa-base[ver2]/')  #0.7327　→ 0.7565\n","OUTPUT_MODEL_DIR3 = os.path.join(OUTPUT_DIR,'Model/RoBERTa-large/')  #0.7385　→ 0.7519\n","OUTPUT_MODEL_DIR4 = os.path.join(OUTPUT_DIR,'Model/DeBERTa-v3-large/')  #0.7301　→ 0.7506\n","OUTPUT_MODEL_DIR5 = os.path.join(OUTPUT_DIR,'Model/DeBERTa-v3-large[ver2]meanpooling/') #0.7525　→ 0.7571"],"metadata":{"id":"PXSlDy4S1zHb","executionInfo":{"status":"ok","timestamp":1661349827193,"user_tz":-540,"elapsed":60,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class CFG1:\n","    num_workers=2\n","    path=OUTPUT_MODEL_DIR1\n","    config_path=OUTPUT_MODEL_DIR1+'config.pth'\n","    model=\"microsoft/deberta-large\"\n","    batch_size=32\n","    dropout=0.2\n","    target_size=4\n","    max_len=1024\n","    seed=42\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4]\n","    gradient_checkpointing=True\n","    freezing=True"],"metadata":{"id":"i2eCp8XY146k","executionInfo":{"status":"ok","timestamp":1661349827194,"user_tz":-540,"elapsed":59,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class CFG2:\n","    num_workers=2\n","    path=OUTPUT_MODEL_DIR2\n","    config_path=OUTPUT_MODEL_DIR2+'config.pth'\n","    model=\"microsoft/deberta-v3-base\"\n","    batch_size=16\n","    dropout=0.1\n","    target_size=4\n","    max_len=1024\n","    seed=42\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4]\n","    gradient_checkpointing=True\n","    freezing=True"],"metadata":{"id":"XuSC9704VOE2","executionInfo":{"status":"ok","timestamp":1661349827195,"user_tz":-540,"elapsed":59,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class CFG3:\n","    num_workers=2\n","    path=OUTPUT_MODEL_DIR3\n","    config_path=OUTPUT_MODEL_DIR3+'config.pth'\n","    model=\"roberta-large\"\n","    batch_size=32\n","    dropout=0.2\n","    target_size=4\n","    max_len=128\n","    seed=42\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4]\n","    gradient_checkpointing=True\n","    freezing=True"],"metadata":{"id":"Pwo7jYStVSt_","executionInfo":{"status":"ok","timestamp":1661349827196,"user_tz":-540,"elapsed":59,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class CFG4:\n","    num_workers=2\n","    path=OUTPUT_MODEL_DIR4\n","    config_path=OUTPUT_MODEL_DIR4+'config.pth'\n","    model=\"microsoft/deberta-v3-large\"\n","    batch_size=32\n","    dropout=0.2\n","    target_size=4\n","    max_len=1024\n","    seed=42\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4]\n","    gradient_checkpointing=True\n","    freezing=True"],"metadata":{"id":"0u7ASRTQnVGn","executionInfo":{"status":"ok","timestamp":1661349827198,"user_tz":-540,"elapsed":60,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class CFG5:\n","    num_workers=2\n","    path=OUTPUT_MODEL_DIR5\n","    config_path=OUTPUT_MODEL_DIR5+'config.pth'\n","    model=\"microsoft/deberta-v3-large\"\n","    batch_size=32\n","    dropout=0.2\n","    target_size=4\n","    max_len=1024\n","    seed=42\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4]\n","    gradient_checkpointing=True\n","    freezing=True"],"metadata":{"id":"Awe2j0vqrZ04","executionInfo":{"status":"ok","timestamp":1661349827199,"user_tz":-540,"elapsed":60,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Loss Func\n","def criterion(outputs, labels):\n","    return nn.CrossEntropyLoss()(outputs, labels)\n","\n","def softmax(z):\n","    assert len(z.shape) == 2\n","    s = np.max(z, axis=1)\n","    s = s[:, np.newaxis] # necessary step to do broadcasting\n","    e_x = np.exp(z - s)\n","    div = np.sum(e_x, axis=1)\n","    div = div[:, np.newaxis] # dito\n","    return e_x / div\n","\"\"\"\n","def get_score(y_true, y_pred):\n","    y_pred = softmax(y_pred)\n","    score = log_loss(y_true, y_pred)\n","    return round(score, 5)\n","\"\"\"\n","def get_score(outputs, labels):\n","    outputs = F.softmax(torch.tensor(outputs)).numpy()\n","    return f1_score(np.argmax(outputs,axis=1),labels ,average='macro')\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG1.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"],"metadata":{"id":"yFs0881Q3aKi","executionInfo":{"status":"ok","timestamp":1661349827200,"user_tz":-540,"elapsed":60,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["oof_df = pd.DataFrame()\n","oof_df1 = pd.read_pickle(OUTPUT_MODEL_DIR1+'oof_df.pkl')\n","oof_df2 = pd.read_pickle(OUTPUT_MODEL_DIR2+'oof_df.pkl')\n","oof_df3 = pd.read_pickle(OUTPUT_MODEL_DIR3+'oof_df.pkl')\n","oof_df4 = pd.read_pickle(OUTPUT_MODEL_DIR4+'oof_df.pkl')\n","oof_df5 = pd.read_pickle(OUTPUT_MODEL_DIR5+'oof_df.pkl')\n","labels = oof_df1['label'].values\n","labels2 = oof_df2['label'].values\n","preds1 = oof_df1[['Data scientist','Machine learning engineer','Software engineer','Consultant']]\n","preds3 = oof_df3[['Data scientist','Machine learning engineer','Software engineer','Consultant']]\n","preds2 = oof_df2[['Consultant','Data scientist','Machine learning engineer','Software engineer']]\n","preds4 = oof_df4[['Data scientist','Machine learning engineer','Software engineer','Consultant']]\n","preds5 = oof_df5[['Data scientist','Machine learning engineer','Software engineer','Consultant']]\n","oof_df[\"Data scientist\"] = (preds1[\"Data scientist\"] + preds2[\"Data scientist\"] + preds3[\"Data scientist\"] + preds4[\"Data scientist\"] + preds5[\"Data scientist\"]) / 5\n","oof_df[\"Machine learning engineer\"] = (preds1[\"Machine learning engineer\"] + preds2[\"Machine learning engineer\"] + preds3[\"Machine learning engineer\"] + preds4[\"Machine learning engineer\"] + preds5[\"Machine learning engineer\"]) / 5\n","oof_df[\"Software engineer\"] = (preds1[\"Software engineer\"] + preds2[\"Software engineer\"] + preds3[\"Software engineer\"] + preds4[\"Software engineer\"] + preds5[\"Software engineer\"]) / 5\n","oof_df[\"Consultant\"] = (preds1[\"Consultant\"] + preds2[\"Consultant\"] + preds3[\"Consultant\"] + preds4[\"Consultant\"] + preds5[\"Consultant\"]) / 5\n","preds = oof_df[['Data scientist','Machine learning engineer','Software engineer','Consultant']].values.tolist()\n","score1 = get_score(preds1.values, labels)\n","score2 = get_score(preds2.values, labels2)\n","score3 = get_score(preds3.values, labels)\n","score4 = get_score(preds4.values, labels)\n","score5 = get_score(preds5.values, labels)\n","mean_score = (score1+score2+score3+score4+score5)/5\n","score = get_score(preds, labels)\n","LOGGER.info(f'Deberta-large CV Score: {score1:<.4f}')\n","LOGGER.info(f'Deberta-v3-baseCV Score: {score2:<.4f}')\n","LOGGER.info(f'Roberta-large CV Score: {score3:<.4f}')\n","LOGGER.info(f'Deberta-v3-large(attension) CV Score: {score4:<.4f}')\n","LOGGER.info(f'Roberta-v3-large(meanpool) CV Score: {score5:<.4f}')\n","LOGGER.info(f'CV Mean Score: {mean_score:<.4f}')\n","LOGGER.info(f'CV Score: {score:<.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YvsuWJc93pkF","executionInfo":{"status":"ok","timestamp":1661349828185,"user_tz":-540,"elapsed":1044,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"39b99086-6a18-4fbd-827d-51f8adfbc762"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Deberta-large CV Score: 0.7455\n","INFO:__main__:Deberta-large CV Score: 0.7455\n","Deberta-v3-baseCV Score: 0.7327\n","INFO:__main__:Deberta-v3-baseCV Score: 0.7327\n","Roberta-large CV Score: 0.7385\n","INFO:__main__:Roberta-large CV Score: 0.7385\n","Deberta-v3-large(attension) CV Score: 0.7301\n","INFO:__main__:Deberta-v3-large(attension) CV Score: 0.7301\n","Roberta-v3-large(meanpool) CV Score: 0.7525\n","INFO:__main__:Roberta-v3-large(meanpool) CV Score: 0.7525\n","CV Mean Score: 0.7399\n","INFO:__main__:CV Mean Score: 0.7399\n","CV Score: 0.7533\n","INFO:__main__:CV Score: 0.7533\n"]}]},{"cell_type":"code","source":["oof_df1['std 1'] = oof_df1[['Data scientist','Machine learning engineer','Software engineer','Consultant']].std(axis=1)\n","oof_df1['mean 1'] = oof_df1[['Data scientist','Machine learning engineer','Software engineer','Consultant']].mean(axis=1)\n","oof_df2['std 2'] = oof_df2[['Data scientist','Machine learning engineer','Software engineer','Consultant']].std(axis=1)\n","oof_df2['mean 2'] = oof_df2[['Data scientist','Machine learning engineer','Software engineer','Consultant']].mean(axis=1)\n","oof_df3['std 3'] = oof_df3[['Data scientist','Machine learning engineer','Software engineer','Consultant']].std(axis=1)\n","oof_df3['mean 3'] = oof_df2[['Data scientist','Machine learning engineer','Software engineer','Consultant']].mean(axis=1)\n","oof_df4['std 4'] = oof_df4[['Data scientist','Machine learning engineer','Software engineer','Consultant']].std(axis=1)\n","oof_df4['mean 4'] = oof_df4[['Data scientist','Machine learning engineer','Software engineer','Consultant']].mean(axis=1)\n","oof_df5['std 5'] = oof_df5[['Data scientist','Machine learning engineer','Software engineer','Consultant']].std(axis=1)\n","oof_df5['mean 5'] = oof_df5[['Data scientist','Machine learning engineer','Software engineer','Consultant']].mean(axis=1)\n","\n","oof_df1 = oof_df1.rename(columns={'Data scientist': 'Data scientist 1','Machine learning engineer':'Machine learning engineer 1',\n","                                  'Software engineer':'Software engineer 1','Consultant':'Consultant 1'})\n","oof_df2 = oof_df2.rename(columns={'Data scientist': 'Data scientist 2','Machine learning engineer':'Machine learning engineer 2',\n","                                  'Software engineer':'Software engineer 2','Consultant':'Consultant 2'})\n","oof_df3 = oof_df3.rename(columns={'Data scientist': 'Data scientist 3','Machine learning engineer':'Machine learning engineer 3',\n","                                  'Software engineer':'Software engineer 3','Consultant':'Consultant 3'})\n","oof_df4 = oof_df4.rename(columns={'Data scientist': 'Data scientist 4','Machine learning engineer':'Machine learning engineer 4',\n","                                  'Software engineer':'Software engineer 4','Consultant':'Consultant 4'})\n","oof_df5 = oof_df5.rename(columns={'Data scientist': 'Data scientist 5','Machine learning engineer':'Machine learning engineer 5',\n","                                  'Software engineer':'Software engineer 5','Consultant':'Consultant 5'})"],"metadata":{"id":"VkZlZrbfxAUA","executionInfo":{"status":"ok","timestamp":1661349828187,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["stacking_train = oof_df1[['id','label','kfold','Data scientist 1','Machine learning engineer 1','Software engineer 1','Consultant 1','std 1','mean 1']].merge(oof_df2[['id','kfold','Data scientist 2','Machine learning engineer 2','Software engineer 2','Consultant 2','std 2','mean 2']],how='left',on=['id','kfold']).merge(oof_df3[['id','label','kfold','Data scientist 3','Machine learning engineer 3','Software engineer 3','Consultant 3','std 3','mean 3']],how='left',on=['id','label','kfold']).merge(oof_df4[['id','label','kfold','Data scientist 4','Machine learning engineer 4','Software engineer 4','Consultant 4','std 4','mean 4']],how='left',on=['id','label','kfold']).merge(oof_df5[['id','label','kfold','Data scientist 5','Machine learning engineer 5','Software engineer 5','Consultant 5','std 5','mean 5']],how='left',on=['id','label','kfold'])\n","display(stacking_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":540},"id":"Ewtx4RHyzqzG","executionInfo":{"status":"ok","timestamp":1661349828662,"user_tz":-540,"elapsed":482,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"4a3b4960-27c6-4b44-cc9e-12d2981fde61"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["        id  label  kfold  Data scientist 1  Machine learning engineer 1  \\\n","0        1      2      0         -2.965860                    -1.017218   \n","1        9      0      0          6.925399                    -3.056653   \n","2       10      1      0          0.208691                     7.635777   \n","3       26      0      0          3.692573                     6.822127   \n","4       32      1      0          2.262520                     5.702750   \n","...    ...    ...    ...               ...                          ...   \n","1511  1499      3      4          2.378140                    -4.249498   \n","1512  1500      3      4          2.794290                    -3.991971   \n","1513  1509      2      4         -4.527265                    -0.770007   \n","1514  1511      0      4          7.434820                    -3.601152   \n","1515  1515      0      4          6.152353                    -4.150577   \n","\n","      Software engineer 1  Consultant 1     std 1    mean 1  Data scientist 2  \\\n","0                7.890793     -3.641326  5.333454  0.066597         -2.773179   \n","1               -5.294641      1.608724  5.413475  0.045707          5.992557   \n","2               -1.905769     -5.799308  5.645285  0.034848         -0.239947   \n","3               -3.615892     -5.866379  5.983285  0.258107          3.016727   \n","4               -2.445959     -5.642027  5.015037 -0.030679          3.374876   \n","...                   ...           ...       ...       ...               ...   \n","1511            -4.891499      6.624092  5.523113 -0.034691         -1.000058   \n","1512            -4.152143      5.879009  5.015872  0.132296          4.696843   \n","1513             6.463882     -2.509835  4.786057 -0.335806         -2.623826   \n","1514            -5.101388      0.958970  5.632193 -0.077188          5.443227   \n","1515            -4.163008      1.999228  5.046442 -0.040501          5.715172   \n","\n","      ...  Software engineer 4  Consultant 4     std 4    mean 4  \\\n","0     ...             5.362940     -0.850250  3.976717 -0.242818   \n","1     ...            -3.066729      0.438705  3.431118  0.148691   \n","2     ...            -0.121819     -3.344715  3.060674 -0.063436   \n","3     ...            -0.643374     -3.675896  3.094977 -0.043446   \n","4     ...            -1.026131     -4.107147  3.478127 -0.105858   \n","...   ...                  ...           ...       ...       ...   \n","1511  ...            -2.068501      7.273594  4.925186  0.080474   \n","1512  ...            -1.963520      5.614141  4.224563  0.006614   \n","1513  ...             7.332036     -0.497775  4.730177  0.407091   \n","1514  ...            -3.402658     -0.489366  4.459239  0.036450   \n","1515  ...            -2.759102      1.002336  3.784342  0.024441   \n","\n","      Data scientist 5  Machine learning engineer 5  Software engineer 5  \\\n","0            -2.555282                    -2.009481             4.370277   \n","1             4.466621                    -1.450690            -2.954009   \n","2            -1.460583                     5.359279            -0.740972   \n","3             4.484289                     1.420338            -1.549800   \n","4            -0.069221                     2.483360             0.301805   \n","...                ...                          ...                  ...   \n","1511          0.229901                    -4.581410            -2.374878   \n","1512          2.911459                    -3.948030            -2.946266   \n","1513         -3.080327                    -2.951421             7.119303   \n","1514          5.797778                    -1.438778            -3.207971   \n","1515          4.929774                    -2.367268            -3.120381   \n","\n","      Consultant 5     std 5    mean 5  \n","0        -1.767629  3.257240 -0.490529  \n","1        -0.027843  3.203220  0.008520  \n","2        -5.097662  4.337801 -0.484984  \n","3        -3.985067  3.668545  0.092440  \n","4        -4.304681  2.837970 -0.397184  \n","...            ...       ...       ...  \n","1511      7.053916  5.046885  0.081882  \n","1512      4.470585  4.190094  0.121937  \n","1513     -0.792462  4.812830  0.073773  \n","1514     -0.745921  3.936613  0.101277  \n","1515      1.242312  3.699983  0.171109  \n","\n","[1516 rows x 33 columns]"],"text/html":["\n","  <div id=\"df-7d5da6a1-dc65-4913-b5b7-0c1f42216eb3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>kfold</th>\n","      <th>Data scientist 1</th>\n","      <th>Machine learning engineer 1</th>\n","      <th>Software engineer 1</th>\n","      <th>Consultant 1</th>\n","      <th>std 1</th>\n","      <th>mean 1</th>\n","      <th>Data scientist 2</th>\n","      <th>...</th>\n","      <th>Software engineer 4</th>\n","      <th>Consultant 4</th>\n","      <th>std 4</th>\n","      <th>mean 4</th>\n","      <th>Data scientist 5</th>\n","      <th>Machine learning engineer 5</th>\n","      <th>Software engineer 5</th>\n","      <th>Consultant 5</th>\n","      <th>std 5</th>\n","      <th>mean 5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>-2.965860</td>\n","      <td>-1.017218</td>\n","      <td>7.890793</td>\n","      <td>-3.641326</td>\n","      <td>5.333454</td>\n","      <td>0.066597</td>\n","      <td>-2.773179</td>\n","      <td>...</td>\n","      <td>5.362940</td>\n","      <td>-0.850250</td>\n","      <td>3.976717</td>\n","      <td>-0.242818</td>\n","      <td>-2.555282</td>\n","      <td>-2.009481</td>\n","      <td>4.370277</td>\n","      <td>-1.767629</td>\n","      <td>3.257240</td>\n","      <td>-0.490529</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>6.925399</td>\n","      <td>-3.056653</td>\n","      <td>-5.294641</td>\n","      <td>1.608724</td>\n","      <td>5.413475</td>\n","      <td>0.045707</td>\n","      <td>5.992557</td>\n","      <td>...</td>\n","      <td>-3.066729</td>\n","      <td>0.438705</td>\n","      <td>3.431118</td>\n","      <td>0.148691</td>\n","      <td>4.466621</td>\n","      <td>-1.450690</td>\n","      <td>-2.954009</td>\n","      <td>-0.027843</td>\n","      <td>3.203220</td>\n","      <td>0.008520</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.208691</td>\n","      <td>7.635777</td>\n","      <td>-1.905769</td>\n","      <td>-5.799308</td>\n","      <td>5.645285</td>\n","      <td>0.034848</td>\n","      <td>-0.239947</td>\n","      <td>...</td>\n","      <td>-0.121819</td>\n","      <td>-3.344715</td>\n","      <td>3.060674</td>\n","      <td>-0.063436</td>\n","      <td>-1.460583</td>\n","      <td>5.359279</td>\n","      <td>-0.740972</td>\n","      <td>-5.097662</td>\n","      <td>4.337801</td>\n","      <td>-0.484984</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>26</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3.692573</td>\n","      <td>6.822127</td>\n","      <td>-3.615892</td>\n","      <td>-5.866379</td>\n","      <td>5.983285</td>\n","      <td>0.258107</td>\n","      <td>3.016727</td>\n","      <td>...</td>\n","      <td>-0.643374</td>\n","      <td>-3.675896</td>\n","      <td>3.094977</td>\n","      <td>-0.043446</td>\n","      <td>4.484289</td>\n","      <td>1.420338</td>\n","      <td>-1.549800</td>\n","      <td>-3.985067</td>\n","      <td>3.668545</td>\n","      <td>0.092440</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>32</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2.262520</td>\n","      <td>5.702750</td>\n","      <td>-2.445959</td>\n","      <td>-5.642027</td>\n","      <td>5.015037</td>\n","      <td>-0.030679</td>\n","      <td>3.374876</td>\n","      <td>...</td>\n","      <td>-1.026131</td>\n","      <td>-4.107147</td>\n","      <td>3.478127</td>\n","      <td>-0.105858</td>\n","      <td>-0.069221</td>\n","      <td>2.483360</td>\n","      <td>0.301805</td>\n","      <td>-4.304681</td>\n","      <td>2.837970</td>\n","      <td>-0.397184</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1511</th>\n","      <td>1499</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>2.378140</td>\n","      <td>-4.249498</td>\n","      <td>-4.891499</td>\n","      <td>6.624092</td>\n","      <td>5.523113</td>\n","      <td>-0.034691</td>\n","      <td>-1.000058</td>\n","      <td>...</td>\n","      <td>-2.068501</td>\n","      <td>7.273594</td>\n","      <td>4.925186</td>\n","      <td>0.080474</td>\n","      <td>0.229901</td>\n","      <td>-4.581410</td>\n","      <td>-2.374878</td>\n","      <td>7.053916</td>\n","      <td>5.046885</td>\n","      <td>0.081882</td>\n","    </tr>\n","    <tr>\n","      <th>1512</th>\n","      <td>1500</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>2.794290</td>\n","      <td>-3.991971</td>\n","      <td>-4.152143</td>\n","      <td>5.879009</td>\n","      <td>5.015872</td>\n","      <td>0.132296</td>\n","      <td>4.696843</td>\n","      <td>...</td>\n","      <td>-1.963520</td>\n","      <td>5.614141</td>\n","      <td>4.224563</td>\n","      <td>0.006614</td>\n","      <td>2.911459</td>\n","      <td>-3.948030</td>\n","      <td>-2.946266</td>\n","      <td>4.470585</td>\n","      <td>4.190094</td>\n","      <td>0.121937</td>\n","    </tr>\n","    <tr>\n","      <th>1513</th>\n","      <td>1509</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>-4.527265</td>\n","      <td>-0.770007</td>\n","      <td>6.463882</td>\n","      <td>-2.509835</td>\n","      <td>4.786057</td>\n","      <td>-0.335806</td>\n","      <td>-2.623826</td>\n","      <td>...</td>\n","      <td>7.332036</td>\n","      <td>-0.497775</td>\n","      <td>4.730177</td>\n","      <td>0.407091</td>\n","      <td>-3.080327</td>\n","      <td>-2.951421</td>\n","      <td>7.119303</td>\n","      <td>-0.792462</td>\n","      <td>4.812830</td>\n","      <td>0.073773</td>\n","    </tr>\n","    <tr>\n","      <th>1514</th>\n","      <td>1511</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>7.434820</td>\n","      <td>-3.601152</td>\n","      <td>-5.101388</td>\n","      <td>0.958970</td>\n","      <td>5.632193</td>\n","      <td>-0.077188</td>\n","      <td>5.443227</td>\n","      <td>...</td>\n","      <td>-3.402658</td>\n","      <td>-0.489366</td>\n","      <td>4.459239</td>\n","      <td>0.036450</td>\n","      <td>5.797778</td>\n","      <td>-1.438778</td>\n","      <td>-3.207971</td>\n","      <td>-0.745921</td>\n","      <td>3.936613</td>\n","      <td>0.101277</td>\n","    </tr>\n","    <tr>\n","      <th>1515</th>\n","      <td>1515</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>6.152353</td>\n","      <td>-4.150577</td>\n","      <td>-4.163008</td>\n","      <td>1.999228</td>\n","      <td>5.046442</td>\n","      <td>-0.040501</td>\n","      <td>5.715172</td>\n","      <td>...</td>\n","      <td>-2.759102</td>\n","      <td>1.002336</td>\n","      <td>3.784342</td>\n","      <td>0.024441</td>\n","      <td>4.929774</td>\n","      <td>-2.367268</td>\n","      <td>-3.120381</td>\n","      <td>1.242312</td>\n","      <td>3.699983</td>\n","      <td>0.171109</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1516 rows × 33 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d5da6a1-dc65-4913-b5b7-0c1f42216eb3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7d5da6a1-dc65-4913-b5b7-0c1f42216eb3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7d5da6a1-dc65-4913-b5b7-0c1f42216eb3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"AxyGCuaM3-Ba","executionInfo":{"status":"ok","timestamp":1661349828664,"user_tz":-540,"elapsed":11,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["test = pd.read_csv(os.path.join(INPUT_DIR, 'test.csv'))\n","submission_df = pd.read_csv(os.path.join(INPUT_DIR, 'submit_sample.csv'),header=None)\n","\n","def remove_tag(x):\n","    p = re.compile(r\"<[^>]*?>\")\n","    return p.sub('',x)\n","\n","def cleaning(texts):\n","    clean_texts = []\n","    for text in texts:\n","        # htmlタグを削除\n","        text = remove_tag(text)\n","        #アルファベット以外をスペースに置き換え\n","        #clean_punc = re.sub(r'[^a-zA-Z]', ' ', text)\n","        clean_texts.append(text)\n","    return clean_texts\n","\n","\n","\n","from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n","    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n","\n","\n","def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n","    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n","\n","# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n","codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n","codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n","\n","def resolve_encodings_and_normalize(text: str) -> str:\n","    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n","    text = (\n","        text.encode(\"raw_unicode_escape\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n","        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n","    )\n","    text = unidecode(text)\n","    return text\n","\n","\n","test['description'] = cleaning(test['description'])\n","test['inputs'] = test['description'].apply(lambda x : resolve_encodings_and_normalize(x))\n","display(test.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"7Fr4A20S4G3n","executionInfo":{"status":"ok","timestamp":1661349829020,"user_tz":-540,"elapsed":366,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"6dac407f-bf32-4b1b-ac34-c5373423f111"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["     id                                        description  \\\n","0  1516  Building decision-making models and proposing ...   \n","1  1517  Educate homeowners on the benefits of solar en...   \n","2  1518  Design, develop, document, and implement web a...   \n","3  1519  Apply advanced technical expertise and skills ...   \n","4  1520  Project manage and deliver against our roadmap...   \n","\n","                                              inputs  \n","0  Building decision-making models and proposing ...  \n","1  Educate homeowners on the benefits of solar en...  \n","2  Design, develop, document, and implement web a...  \n","3  Apply advanced technical expertise and skills ...  \n","4  Project manage and deliver against our roadmap...  "],"text/html":["\n","  <div id=\"df-43f255cf-850e-4c51-a347-06db7fa662b1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>description</th>\n","      <th>inputs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1516</td>\n","      <td>Building decision-making models and proposing ...</td>\n","      <td>Building decision-making models and proposing ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1517</td>\n","      <td>Educate homeowners on the benefits of solar en...</td>\n","      <td>Educate homeowners on the benefits of solar en...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1518</td>\n","      <td>Design, develop, document, and implement web a...</td>\n","      <td>Design, develop, document, and implement web a...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1519</td>\n","      <td>Apply advanced technical expertise and skills ...</td>\n","      <td>Apply advanced technical expertise and skills ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1520</td>\n","      <td>Project manage and deliver against our roadmap...</td>\n","      <td>Project manage and deliver against our roadmap...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43f255cf-850e-4c51-a347-06db7fa662b1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-43f255cf-850e-4c51-a347-06db7fa662b1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-43f255cf-850e-4c51-a347-06db7fa662b1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["tokenizer1 = AutoTokenizer.from_pretrained(CFG1.model)\n","CFG1.tokenizer = tokenizer1\n","tokenizer2 = AutoTokenizer.from_pretrained(CFG2.model)\n","CFG2.tokenizer = tokenizer2\n","tokenizer3 = AutoTokenizer.from_pretrained(CFG3.model)\n","CFG3.tokenizer = tokenizer3\n","tokenizer4 = AutoTokenizer.from_pretrained(CFG4.model)\n","CFG4.tokenizer = tokenizer4"],"metadata":{"id":"Xuk_cv5q4oTB","executionInfo":{"status":"ok","timestamp":1661349838982,"user_tz":-540,"elapsed":9969,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"14d8b2b2-e3ae-404f-96e4-16bcdd8a1ddb"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["class Dataset1(Dataset):\n","    def __init__(self, df, tokenizer, max_length):\n","        self.df = df\n","        self.max_len = CFG1.max_len\n","        self.text = df['inputs'].values\n","        self.tokenizer = CFG1.tokenizer\n","        #self.targets = df['label'].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        text = self.text[index]\n","        inputs = tokenizer1.encode_plus(\n","            text,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length = self.max_len\n","        )\n","        samples = {\n","            'input_ids': inputs['input_ids'],\n","            'attention_mask': inputs['attention_mask'],\n","            #'target': self.targets[index]\n","        }\n","\n","        if 'token_type_ids' in inputs:\n","            samples['token_type_ids'] = inputs['token_type_ids']\n","            \n","        return samples"],"metadata":{"id":"KzauU3kS43FA","executionInfo":{"status":"ok","timestamp":1661349838984,"user_tz":-540,"elapsed":50,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class Dataset2(Dataset):\n","    def __init__(self, df, tokenizer, max_length):\n","        self.df = df\n","        self.max_len = CFG2.max_len\n","        self.text = df['inputs'].values\n","        self.tokenizer = CFG2.tokenizer\n","        #self.targets = df['label'].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        text = self.text[index]\n","        inputs = tokenizer2.encode_plus(\n","            text,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length = self.max_len\n","        )\n","        samples = {\n","            'input_ids': inputs['input_ids'],\n","            'attention_mask': inputs['attention_mask'],\n","            #'target': self.targets[index]\n","        }\n","\n","        if 'token_type_ids' in inputs:\n","            samples['token_type_ids'] = inputs['token_type_ids']\n","            \n","        return samples"],"metadata":{"id":"zKnlyvZ4foWE","executionInfo":{"status":"ok","timestamp":1661349838985,"user_tz":-540,"elapsed":49,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["class Dataset3(Dataset):\n","    def __init__(self, df, tokenizer, max_length):\n","        self.df = df\n","        self.max_len = CFG3.max_len\n","        self.text = df['inputs'].values\n","        self.tokenizer = CFG3.tokenizer\n","        #self.targets = df['label'].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        text = self.text[index]\n","        inputs = tokenizer3.encode_plus(\n","            text,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length = self.max_len\n","        )\n","        samples = {\n","            'input_ids': inputs['input_ids'],\n","            'attention_mask': inputs['attention_mask'],\n","            #'target': self.targets[index]\n","        }\n","\n","        if 'token_type_ids' in inputs:\n","            samples['token_type_ids'] = inputs['token_type_ids']\n","            \n","        return samples"],"metadata":{"id":"n1zPEEDDfpGi","executionInfo":{"status":"ok","timestamp":1661349838989,"user_tz":-540,"elapsed":53,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["class Dataset4(Dataset):\n","    def __init__(self, df, tokenizer, max_length):\n","        self.df = df\n","        self.max_len = CFG4.max_len\n","        self.text = df['inputs'].values\n","        self.tokenizer = CFG4.tokenizer\n","        #self.targets = df['label'].values\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        text = self.text[index]\n","        inputs = tokenizer4.encode_plus(\n","            text,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length = self.max_len\n","        )\n","        samples = {\n","            'input_ids': inputs['input_ids'],\n","            'attention_mask': inputs['attention_mask'],\n","            #'target': self.targets[index]\n","        }\n","\n","        if 'token_type_ids' in inputs:\n","            samples['token_type_ids'] = inputs['token_type_ids']\n","            \n","        return samples"],"metadata":{"id":"5teYMxIgppqL","executionInfo":{"status":"ok","timestamp":1661349839553,"user_tz":-540,"elapsed":615,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["class Collate:\n","    def __init__(self, tokenizer, isTrain=True):\n","        self.tokenizer = tokenizer\n","        self.isTrain = isTrain\n","        # self.args = args\n","\n","    def __call__(self, batch):\n","        output = dict()\n","        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n","        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n","        if self.isTrain:\n","            output[\"target\"] = [sample[\"target\"] for sample in batch]\n","\n","        # calculate max token length of this batch\n","        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n","        else:\n","            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n","\n","        # convert to tensors\n","        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n","        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n","        if self.isTrain:\n","            output[\"target\"] = torch.tensor(output[\"target\"], dtype=torch.long)\n","\n","        return output\n","    \n","collate_fn1 = Collate(CFG1.tokenizer, isTrain=False)\n","collate_fn2 = Collate(CFG2.tokenizer, isTrain=False)\n","collate_fn3 = Collate(CFG3.tokenizer, isTrain=False)\n","collate_fn4 = Collate(CFG4.tokenizer, isTrain=False)\n","collate_fn5 = Collate(CFG4.tokenizer, isTrain=False)"],"metadata":{"id":"eqFQBAw348qx","executionInfo":{"status":"ok","timestamp":1661349839554,"user_tz":-540,"elapsed":19,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9) #\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings"],"metadata":{"id":"hx7dTi5l5BOD","executionInfo":{"status":"ok","timestamp":1661349839555,"user_tz":-540,"elapsed":19,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["class CustomModel1(nn.Module):\n","    def __init__(self, model_name):\n","        super(CustomModel1, self).__init__()\n","        # Header (fast or normal)\n","        self.model = AutoModel.from_pretrained(model_name)\n","        \n","        # Gradient_checkpointing\n","        if CFG1.gradient_checkpointing:\n","            (self.model).gradient_checkpointing_enable()\n","        \n","        # Freezing\n","        if CFG1.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            CFG1.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","        \n","        self.config = AutoConfig.from_pretrained(model_name)\n","        self.drop = nn.Dropout(p=CFG1.dropout)\n","        #self.pooler = MeanPooling()\n","        self.dropout1 = nn.Dropout(0.1)\n","        self.dropout2 = nn.Dropout(0.2)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.dropout4 = nn.Dropout(0.4)\n","        self.dropout5 = nn.Dropout(0.5)\n","        self.output = nn.Sequential( nn.Linear(self.config.hidden_size, CFG1.target_size) )\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def forward(self, ids, mask):        \n","        output = self.model(input_ids=ids, \n","                         attention_mask=mask,\n","                         output_hidden_states=False)\n","        output = output[0][:, 0, :]\n","        logits1 = self.output(self.dropout1(output))\n","        logits2 = self.output(self.dropout2(output))\n","        logits3 = self.output(self.dropout3(output))\n","        logits4 = self.output(self.dropout4(output))\n","        logits5 = self.output(self.dropout5(output))\n","        outputs = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n","        return outputs"],"metadata":{"id":"mxfnzZKu5Fxi","executionInfo":{"status":"ok","timestamp":1661349839557,"user_tz":-540,"elapsed":20,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["class CustomModel2(nn.Module):\n","    def __init__(self, model_name):\n","        super(CustomModel2, self).__init__()\n","        # Header (fast or normal)\n","        self.model = AutoModel.from_pretrained(model_name)\n","        \n","        # Gradient_checkpointing\n","        if CFG2.gradient_checkpointing:\n","            (self.model).gradient_checkpointing_enable()\n","        \n","        # Freezing\n","        if CFG2.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            CFG2.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","        \n","        self.config = AutoConfig.from_pretrained(model_name)\n","        self.drop = nn.Dropout(p=CFG2.dropout)\n","        self.pooler = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, CFG2.target_size)\n","        \n","    def forward(self, ids, mask):        \n","        out = self.model(input_ids=ids, \n","                         attention_mask=mask,\n","                         output_hidden_states=False)\n","        out = self.pooler(out.last_hidden_state, mask)\n","        out = self.drop(out)\n","        outputs = self.fc(out)\n","        return outputs"],"metadata":{"id":"hVgNkROpXSLc","executionInfo":{"status":"ok","timestamp":1661349839558,"user_tz":-540,"elapsed":20,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["class CustomModel3(nn.Module):\n","    def __init__(self, model_name):\n","        super(CustomModel3, self).__init__()\n","        # Header (fast or normal)\n","        self.model = AutoModel.from_pretrained(model_name)\n","        \n","        # Gradient_checkpointing\n","        if CFG3.gradient_checkpointing:\n","            (self.model).gradient_checkpointing_enable()\n","        \n","        # Freezing\n","        if CFG3.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            CFG3.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","        \n","        self.config = AutoConfig.from_pretrained(model_name)\n","        self.fc = nn.Linear(self.config.hidden_size, CFG3.target_size)\n","        \n","    def forward(self, ids, mask):        \n","        out = self.model(input_ids=ids, \n","                         attention_mask=mask,\n","                         output_hidden_states=False)\n","        outputs = out[0][:, 0, :]\n","        outputs = self.fc(outputs)\n","        return outputs"],"metadata":{"id":"Mrjb0qqmXUos","executionInfo":{"status":"ok","timestamp":1661349839559,"user_tz":-540,"elapsed":20,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["class CustomModel4(nn.Module):\n","    def __init__(self, model_name):\n","        super(CustomModel4, self).__init__()\n","        # Header (fast or normal)\n","        self.model = AutoModel.from_pretrained(model_name)\n","        \n","        # Gradient_checkpointing\n","        if CFG4.gradient_checkpointing:\n","            (self.model).gradient_checkpointing_enable()\n","        \n","        # Freezing\n","        if CFG4.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            CFG4.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","        \n","        self.config = AutoConfig.from_pretrained(model_name)\n","        self.drop = nn.Dropout(p=CFG4.dropout)\n","        #self.pooler = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, CFG4.target_size)\n","        self._init_weights(self.fc)\n","        self.attention = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 512),\n","            nn.Tanh(),\n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","        self._init_weights(self.attention)\n","        self.output = nn.Sequential( nn.Linear(self.config.hidden_size, CFG4.target_size) )\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def feature(self, ids, mask):\n","        output = self.model(input_ids=ids, \n","                         attention_mask=mask,\n","                         output_hidden_states=False)\n","        last_hidden_states = output[0]\n","        #feature = torch.mean(last_hidden_states, 1)\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        return feature\n","\n","\n","    def forward(self, ids, mask):\n","        feature = self.feature(ids, mask)\n","        output = self.fc(self.drop(feature))        \n","        return output"],"metadata":{"id":"U8q99aXfqCDn","executionInfo":{"status":"ok","timestamp":1661349839560,"user_tz":-540,"elapsed":20,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["class CustomModel5(nn.Module):\n","    def __init__(self, model_name):\n","        super(CustomModel5, self).__init__()\n","        # Header (fast or normal)\n","        self.model = AutoModel.from_pretrained(model_name)\n","        \n","        # Gradient_checkpointing\n","        if CFG4.gradient_checkpointing:\n","            (self.model).gradient_checkpointing_enable()\n","        \n","        # Freezing\n","        if CFG4.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            CFG4.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","        \n","        self.config = AutoConfig.from_pretrained(model_name)\n","        #self.drop = nn.Dropout(p=CFG4.dropout)\n","        self.fc = nn.Linear(self.config.hidden_size, CFG4.target_size)\n","        self._init_weights(self.fc)\n","        self.pooler = MeanPooling()\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n","        \n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","\n","    def forward(self, ids, mask):\n","        out = self.model(input_ids=ids, \n","                         attention_mask=mask,\n","                         output_hidden_states=False)\n","        out = self.pooler(out.last_hidden_state, mask)\n","        out = self.layer_norm1(out)\n","        outputs = self.fc(out)        \n","        return outputs"],"metadata":{"id":"zpcNzElSqnmz","executionInfo":{"status":"ok","timestamp":1661349839561,"user_tz":-540,"elapsed":20,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["def inference_one_epoch(model, dataloader, device):\n","    model.eval()\n","    pred = []\n","    model.to(device)\n","    for step, data in enumerate(dataloader):\n","        ids = data['input_ids'].to(device, dtype=torch.long)\n","        mask = data['attention_mask'].to(device, dtype=torch.long)\n","        with torch.no_grad():\n","            outputs = model(ids, mask)\n","        pred.append(outputs.to('cpu').numpy())\n","    pred = np.concatenate(pred)\n","    return pred"],"metadata":{"id":"YwHoBsxo5J7B","executionInfo":{"status":"ok","timestamp":1661349839562,"user_tz":-540,"elapsed":20,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["testdataset = Dataset1(test, CFG1.tokenizer, CFG1.max_len)\n","\n","test_loader = DataLoader(testdataset, \n","                         batch_size=CFG1.batch_size,\n","                         shuffle=False,\n","                         collate_fn = collate_fn1,\n","                         num_workers = CFG1.num_workers,\n","                         pin_memory = True,\n","                         drop_last = False,\n","                         )\n","\n","predictions1 = []\n","\n","for fold in CFG1.trn_fold:\n","    model = CustomModel1(CFG1.model)\n","    config_path=CFG1.config_path\n","    state = torch.load(CFG1.path+f\"{CFG1.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location = torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","\n","    prediction = inference_one_epoch(model, test_loader, device)\n","    #prediction = F.softmax(torch.tensor(prediction)).numpy().astype(float)\n","    predictions1.append(prediction)\n","    del model, state, prediction\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","del testdataset,test_loader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LZbuFFs5QVa","executionInfo":{"status":"ok","timestamp":1661350425832,"user_tz":-540,"elapsed":586289,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"9063633b-2c30-46b6-dd3d-b8f8cb2b45ca"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["sub1 = submission_df.copy()\n","sub1.columns = [\"id\",\"label\"]\n","\n","\n","#method1\n","sub1_predictions = np.mean(predictions1, axis=0)\n","sub1['Data scientist 1'] = sub1_predictions[:, 0]\n","sub1['Machine learning engineer 1'] = sub1_predictions[:, 1]\n","sub1['Software engineer 1'] = sub1_predictions[:, 2]\n","sub1['Consultant 1'] = sub1_predictions[:, 3]\n","sub1[\"std 1\"] = sub1[['Data scientist 1','Machine learning engineer 1','Software engineer 1','Consultant 1']].std(axis=1)\n","sub1[\"mean 1\"] = sub1[['Data scientist 1','Machine learning engineer 1','Software engineer 1','Consultant 1']].mean(axis=1)\n","\n","display(sub1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"0G9R9Fen5cZa","executionInfo":{"status":"ok","timestamp":1661350425839,"user_tz":-540,"elapsed":23,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"1d139dee-c1f9-4e09-dbb4-8ec2c378b723"},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":["        id  label  Data scientist 1  Machine learning engineer 1  \\\n","0     1516      1          6.685815                    -0.781564   \n","1     1517      1         -0.630478                    -3.923366   \n","2     1518      1         -3.591125                    -2.077838   \n","3     1519      1         -1.075718                    -4.926772   \n","4     1520      1          1.750711                    -0.921016   \n","...    ...    ...               ...                          ...   \n","1512  3028      1         -1.058913                    -1.431018   \n","1513  3029      1          7.246647                    -2.578345   \n","1514  3030      1         -3.504260                    -1.852924   \n","1515  3031      1          4.794982                    -4.459991   \n","1516  3032      1          1.645523                    -2.826577   \n","\n","      Software engineer 1  Consultant 1     std 1    mean 1  \n","0               -4.555237     -1.050914  4.730869  0.074525  \n","1               -2.001289      6.555913  4.574402  0.000195  \n","2                6.774759     -1.719068  4.689425 -0.153318  \n","3               -2.082120      8.101068  5.638934  0.004115  \n","4                1.564643     -2.328322  1.981697  0.016504  \n","...                   ...           ...       ...       ...  \n","1512             3.122421     -1.188190  2.179696 -0.138925  \n","1513            -4.135920     -0.358376  5.046070  0.043501  \n","1514             6.179841     -1.525572  4.324636 -0.175729  \n","1515            -3.940049      3.310294  4.807761 -0.073691  \n","1516             0.076269      0.811613  1.944251 -0.073293  \n","\n","[1517 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-d37e2173-d53e-4f3b-9907-fbcedd09d950\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>Data scientist 1</th>\n","      <th>Machine learning engineer 1</th>\n","      <th>Software engineer 1</th>\n","      <th>Consultant 1</th>\n","      <th>std 1</th>\n","      <th>mean 1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1516</td>\n","      <td>1</td>\n","      <td>6.685815</td>\n","      <td>-0.781564</td>\n","      <td>-4.555237</td>\n","      <td>-1.050914</td>\n","      <td>4.730869</td>\n","      <td>0.074525</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1517</td>\n","      <td>1</td>\n","      <td>-0.630478</td>\n","      <td>-3.923366</td>\n","      <td>-2.001289</td>\n","      <td>6.555913</td>\n","      <td>4.574402</td>\n","      <td>0.000195</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1518</td>\n","      <td>1</td>\n","      <td>-3.591125</td>\n","      <td>-2.077838</td>\n","      <td>6.774759</td>\n","      <td>-1.719068</td>\n","      <td>4.689425</td>\n","      <td>-0.153318</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1519</td>\n","      <td>1</td>\n","      <td>-1.075718</td>\n","      <td>-4.926772</td>\n","      <td>-2.082120</td>\n","      <td>8.101068</td>\n","      <td>5.638934</td>\n","      <td>0.004115</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1520</td>\n","      <td>1</td>\n","      <td>1.750711</td>\n","      <td>-0.921016</td>\n","      <td>1.564643</td>\n","      <td>-2.328322</td>\n","      <td>1.981697</td>\n","      <td>0.016504</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1512</th>\n","      <td>3028</td>\n","      <td>1</td>\n","      <td>-1.058913</td>\n","      <td>-1.431018</td>\n","      <td>3.122421</td>\n","      <td>-1.188190</td>\n","      <td>2.179696</td>\n","      <td>-0.138925</td>\n","    </tr>\n","    <tr>\n","      <th>1513</th>\n","      <td>3029</td>\n","      <td>1</td>\n","      <td>7.246647</td>\n","      <td>-2.578345</td>\n","      <td>-4.135920</td>\n","      <td>-0.358376</td>\n","      <td>5.046070</td>\n","      <td>0.043501</td>\n","    </tr>\n","    <tr>\n","      <th>1514</th>\n","      <td>3030</td>\n","      <td>1</td>\n","      <td>-3.504260</td>\n","      <td>-1.852924</td>\n","      <td>6.179841</td>\n","      <td>-1.525572</td>\n","      <td>4.324636</td>\n","      <td>-0.175729</td>\n","    </tr>\n","    <tr>\n","      <th>1515</th>\n","      <td>3031</td>\n","      <td>1</td>\n","      <td>4.794982</td>\n","      <td>-4.459991</td>\n","      <td>-3.940049</td>\n","      <td>3.310294</td>\n","      <td>4.807761</td>\n","      <td>-0.073691</td>\n","    </tr>\n","    <tr>\n","      <th>1516</th>\n","      <td>3032</td>\n","      <td>1</td>\n","      <td>1.645523</td>\n","      <td>-2.826577</td>\n","      <td>0.076269</td>\n","      <td>0.811613</td>\n","      <td>1.944251</td>\n","      <td>-0.073293</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1517 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d37e2173-d53e-4f3b-9907-fbcedd09d950')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d37e2173-d53e-4f3b-9907-fbcedd09d950 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d37e2173-d53e-4f3b-9907-fbcedd09d950');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["testdataset = Dataset3(test, CFG3.tokenizer, CFG3.max_len)\n","\n","test_loader = DataLoader(testdataset, \n","                         batch_size=CFG3.batch_size,\n","                         shuffle=False,\n","                         collate_fn = collate_fn3,\n","                         num_workers = CFG3.num_workers,\n","                         pin_memory = True,\n","                         drop_last = False,\n","                         )\n","\n","predictions3 = []\n","\n","for fold in CFG3.trn_fold:\n","    model = CustomModel3(CFG3.model)\n","    config_path=CFG3.config_path\n","    state = torch.load(CFG3.path+f\"{CFG3.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location = torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","\n","    prediction = inference_one_epoch(model, test_loader, device)\n","    #prediction = F.softmax(torch.tensor(prediction)).numpy().astype(float)\n","    predictions3.append(prediction)\n","    del model, state, prediction\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","del testdataset,test_loader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7iLOg4pvCp3n","executionInfo":{"status":"ok","timestamp":1661350647729,"user_tz":-540,"elapsed":221905,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"409fa6be-1957-43ce-c34b-4d90efde4ed8"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["sub3 = submission_df.copy()\n","sub3.columns = [\"id\",\"label\"]\n","\n","\n","#method1\n","sub3_predictions = np.mean(predictions3, axis=0)\n","sub3['Data scientist 3'] = sub3_predictions[:, 0]\n","sub3['Machine learning engineer 3'] = sub3_predictions[:, 1]\n","sub3['Software engineer 3'] = sub3_predictions[:, 2]\n","sub3['Consultant 3'] = sub3_predictions[:, 3]\n","sub3[\"std 3\"] = sub3[['Data scientist 3','Machine learning engineer 3','Software engineer 3','Consultant 3']].std(axis=1)\n","sub3[\"mean 3\"] = sub3[['Data scientist 3','Machine learning engineer 3','Software engineer 3','Consultant 3']].mean(axis=1)\n","\n","display(sub3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"miOV8Xo9FbPC","executionInfo":{"status":"ok","timestamp":1661350647735,"user_tz":-540,"elapsed":60,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"e55de0c4-587b-43de-991d-a4f3377fa047"},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":["        id  label  Data scientist 3  Machine learning engineer 3  \\\n","0     1516      1          6.044259                    -1.794004   \n","1     1517      1         -1.944885                    -3.088769   \n","2     1518      1         -3.012674                    -1.977117   \n","3     1519      1         -0.599138                    -3.951811   \n","4     1520      1         -0.544280                    -1.243665   \n","...    ...    ...               ...                          ...   \n","1512  3028      1         -2.184433                    -2.806317   \n","1513  3029      1          6.613635                    -2.103014   \n","1514  3030      1         -2.555261                    -1.915734   \n","1515  3031      1          3.723150                    -4.764701   \n","1516  3032      1          4.600901                    -2.792027   \n","\n","      Software engineer 3  Consultant 3     std 3    mean 3  \n","0               -3.752031     -1.068430  4.277441 -0.142552  \n","1               -0.404268      5.969779  4.043680  0.132964  \n","2                6.045528     -1.233587  4.125023 -0.044462  \n","3               -1.738244      6.822005  4.671404  0.133203  \n","4                4.054093     -2.812925  2.950504 -0.136694  \n","...                   ...           ...       ...       ...  \n","1512             4.975789     -0.311162  3.534396 -0.081531  \n","1513            -3.325536     -1.455415  4.521135 -0.067582  \n","1514             5.903517     -1.648849  3.989900 -0.054082  \n","1515            -2.551706      3.618307  4.326947  0.006263  \n","1516            -0.920225     -1.352093  3.244738 -0.115861  \n","\n","[1517 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-8c388039-1aef-49eb-88bc-75a35b8f6cb5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>Data scientist 3</th>\n","      <th>Machine learning engineer 3</th>\n","      <th>Software engineer 3</th>\n","      <th>Consultant 3</th>\n","      <th>std 3</th>\n","      <th>mean 3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1516</td>\n","      <td>1</td>\n","      <td>6.044259</td>\n","      <td>-1.794004</td>\n","      <td>-3.752031</td>\n","      <td>-1.068430</td>\n","      <td>4.277441</td>\n","      <td>-0.142552</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1517</td>\n","      <td>1</td>\n","      <td>-1.944885</td>\n","      <td>-3.088769</td>\n","      <td>-0.404268</td>\n","      <td>5.969779</td>\n","      <td>4.043680</td>\n","      <td>0.132964</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1518</td>\n","      <td>1</td>\n","      <td>-3.012674</td>\n","      <td>-1.977117</td>\n","      <td>6.045528</td>\n","      <td>-1.233587</td>\n","      <td>4.125023</td>\n","      <td>-0.044462</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1519</td>\n","      <td>1</td>\n","      <td>-0.599138</td>\n","      <td>-3.951811</td>\n","      <td>-1.738244</td>\n","      <td>6.822005</td>\n","      <td>4.671404</td>\n","      <td>0.133203</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1520</td>\n","      <td>1</td>\n","      <td>-0.544280</td>\n","      <td>-1.243665</td>\n","      <td>4.054093</td>\n","      <td>-2.812925</td>\n","      <td>2.950504</td>\n","      <td>-0.136694</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1512</th>\n","      <td>3028</td>\n","      <td>1</td>\n","      <td>-2.184433</td>\n","      <td>-2.806317</td>\n","      <td>4.975789</td>\n","      <td>-0.311162</td>\n","      <td>3.534396</td>\n","      <td>-0.081531</td>\n","    </tr>\n","    <tr>\n","      <th>1513</th>\n","      <td>3029</td>\n","      <td>1</td>\n","      <td>6.613635</td>\n","      <td>-2.103014</td>\n","      <td>-3.325536</td>\n","      <td>-1.455415</td>\n","      <td>4.521135</td>\n","      <td>-0.067582</td>\n","    </tr>\n","    <tr>\n","      <th>1514</th>\n","      <td>3030</td>\n","      <td>1</td>\n","      <td>-2.555261</td>\n","      <td>-1.915734</td>\n","      <td>5.903517</td>\n","      <td>-1.648849</td>\n","      <td>3.989900</td>\n","      <td>-0.054082</td>\n","    </tr>\n","    <tr>\n","      <th>1515</th>\n","      <td>3031</td>\n","      <td>1</td>\n","      <td>3.723150</td>\n","      <td>-4.764701</td>\n","      <td>-2.551706</td>\n","      <td>3.618307</td>\n","      <td>4.326947</td>\n","      <td>0.006263</td>\n","    </tr>\n","    <tr>\n","      <th>1516</th>\n","      <td>3032</td>\n","      <td>1</td>\n","      <td>4.600901</td>\n","      <td>-2.792027</td>\n","      <td>-0.920225</td>\n","      <td>-1.352093</td>\n","      <td>3.244738</td>\n","      <td>-0.115861</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1517 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c388039-1aef-49eb-88bc-75a35b8f6cb5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8c388039-1aef-49eb-88bc-75a35b8f6cb5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8c388039-1aef-49eb-88bc-75a35b8f6cb5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["testdataset = Dataset2(test, CFG2.tokenizer, CFG2.max_len)\n","\n","test_loader = DataLoader(testdataset, \n","                         batch_size=CFG2.batch_size,\n","                         shuffle=False,\n","                         collate_fn = collate_fn2,\n","                         num_workers = CFG2.num_workers,\n","                         pin_memory = True,\n","                         drop_last = False,\n","                         )\n","\n","predictions2 = []\n","\n","for fold in CFG2.trn_fold:\n","    model = CustomModel2(CFG2.model)\n","    config_path=CFG2.config_path\n","    state = torch.load(CFG2.path+f\"{CFG2.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location = torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","\n","    prediction = inference_one_epoch(model, test_loader, device)\n","    #prediction = F.softmax(torch.tensor(prediction)).numpy().astype(float)\n","    predictions2.append(prediction)\n","    del model, state, prediction\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","del testdataset,test_loader"],"metadata":{"id":"xlVxqgeqFfTR","executionInfo":{"status":"ok","timestamp":1661350808795,"user_tz":-540,"elapsed":161112,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"894e9ab4-5c5c-4e12-ad9d-8a643e0aa638"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["sub2 = submission_df.copy()\n","sub2.columns = [\"id\",\"label\"]\n","\n","\n","#method1\n","sub2_predictions = np.mean(predictions2, axis=0)\n","sub2['Consultant 2'] = sub2_predictions[:, 0]\n","sub2['Machine learning engineer 2'] = sub2_predictions[:, 2]\n","sub2['Software engineer 2'] = sub2_predictions[:, 3]\n","sub2['Data scientist 2'] = sub2_predictions[:, 1]\n","sub2[\"std 2\"] = sub2[['Data scientist 2','Machine learning engineer 2','Software engineer 2','Consultant 2']].std(axis=1)\n","sub2[\"mean 2\"] = sub2[['Data scientist 2','Machine learning engineer 2','Software engineer 2','Consultant 2']].mean(axis=1)\n","\n","display(sub2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"qPOek3b_avK8","executionInfo":{"status":"ok","timestamp":1661350808802,"user_tz":-540,"elapsed":27,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"8cd4c0fc-0825-4511-8e7c-2498d7e8a617"},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":["        id  label  Consultant 2  Machine learning engineer 2  \\\n","0     1516      1     -1.095628                    -1.072270   \n","1     1517      1      5.418258                    -2.323590   \n","2     1518      1     -0.704817                    -2.258667   \n","3     1519      1      6.253388                    -2.861278   \n","4     1520      1     -1.468158                    -1.135850   \n","...    ...    ...           ...                          ...   \n","1512  3028      1     -0.319308                    -1.310320   \n","1513  3029      1     -0.890843                    -1.386537   \n","1514  3030      1     -1.245309                    -1.574746   \n","1515  3031      1      4.159598                    -3.362355   \n","1516  3032      1     -0.870242                    -1.763637   \n","\n","      Software engineer 2  Data scientist 2     std 2    mean 2  \n","0               -3.321170          5.762257  3.939766  0.068297  \n","1               -1.500041         -1.254337  3.584742  0.085073  \n","2                5.560447         -2.873216  3.862348 -0.069063  \n","3               -2.194961         -1.014173  4.208317  0.045744  \n","4                3.335479         -0.809194  2.252728 -0.019431  \n","...                   ...               ...       ...       ...  \n","1512             2.546636         -0.914356  1.745499  0.000663  \n","1513            -3.261573          5.881723  3.996634  0.085693  \n","1514             5.309282         -2.950127  3.690946 -0.115225  \n","1515            -2.505882          1.947549  3.590070  0.059728  \n","1516             3.216965         -0.580502  2.202543  0.000646  \n","\n","[1517 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-18170dbf-f84f-41a3-b992-cb590df70fd3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>Consultant 2</th>\n","      <th>Machine learning engineer 2</th>\n","      <th>Software engineer 2</th>\n","      <th>Data scientist 2</th>\n","      <th>std 2</th>\n","      <th>mean 2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1516</td>\n","      <td>1</td>\n","      <td>-1.095628</td>\n","      <td>-1.072270</td>\n","      <td>-3.321170</td>\n","      <td>5.762257</td>\n","      <td>3.939766</td>\n","      <td>0.068297</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1517</td>\n","      <td>1</td>\n","      <td>5.418258</td>\n","      <td>-2.323590</td>\n","      <td>-1.500041</td>\n","      <td>-1.254337</td>\n","      <td>3.584742</td>\n","      <td>0.085073</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1518</td>\n","      <td>1</td>\n","      <td>-0.704817</td>\n","      <td>-2.258667</td>\n","      <td>5.560447</td>\n","      <td>-2.873216</td>\n","      <td>3.862348</td>\n","      <td>-0.069063</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1519</td>\n","      <td>1</td>\n","      <td>6.253388</td>\n","      <td>-2.861278</td>\n","      <td>-2.194961</td>\n","      <td>-1.014173</td>\n","      <td>4.208317</td>\n","      <td>0.045744</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1520</td>\n","      <td>1</td>\n","      <td>-1.468158</td>\n","      <td>-1.135850</td>\n","      <td>3.335479</td>\n","      <td>-0.809194</td>\n","      <td>2.252728</td>\n","      <td>-0.019431</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1512</th>\n","      <td>3028</td>\n","      <td>1</td>\n","      <td>-0.319308</td>\n","      <td>-1.310320</td>\n","      <td>2.546636</td>\n","      <td>-0.914356</td>\n","      <td>1.745499</td>\n","      <td>0.000663</td>\n","    </tr>\n","    <tr>\n","      <th>1513</th>\n","      <td>3029</td>\n","      <td>1</td>\n","      <td>-0.890843</td>\n","      <td>-1.386537</td>\n","      <td>-3.261573</td>\n","      <td>5.881723</td>\n","      <td>3.996634</td>\n","      <td>0.085693</td>\n","    </tr>\n","    <tr>\n","      <th>1514</th>\n","      <td>3030</td>\n","      <td>1</td>\n","      <td>-1.245309</td>\n","      <td>-1.574746</td>\n","      <td>5.309282</td>\n","      <td>-2.950127</td>\n","      <td>3.690946</td>\n","      <td>-0.115225</td>\n","    </tr>\n","    <tr>\n","      <th>1515</th>\n","      <td>3031</td>\n","      <td>1</td>\n","      <td>4.159598</td>\n","      <td>-3.362355</td>\n","      <td>-2.505882</td>\n","      <td>1.947549</td>\n","      <td>3.590070</td>\n","      <td>0.059728</td>\n","    </tr>\n","    <tr>\n","      <th>1516</th>\n","      <td>3032</td>\n","      <td>1</td>\n","      <td>-0.870242</td>\n","      <td>-1.763637</td>\n","      <td>3.216965</td>\n","      <td>-0.580502</td>\n","      <td>2.202543</td>\n","      <td>0.000646</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1517 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18170dbf-f84f-41a3-b992-cb590df70fd3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-18170dbf-f84f-41a3-b992-cb590df70fd3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-18170dbf-f84f-41a3-b992-cb590df70fd3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["testdataset = Dataset4(test, CFG4.tokenizer, CFG4.max_len)\n","\n","test_loader = DataLoader(testdataset, \n","                         batch_size=CFG4.batch_size,\n","                         shuffle=False,\n","                         collate_fn = collate_fn1,\n","                         num_workers = CFG4.num_workers,\n","                         pin_memory = True,\n","                         drop_last = False,\n","                         )\n","\n","predictions4 = []\n","\n","for fold in CFG4.trn_fold:\n","    model = CustomModel4(CFG4.model)\n","    config_path=CFG4.config_path\n","    state = torch.load(CFG4.path+f\"{CFG4.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location = torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","\n","    prediction = inference_one_epoch(model, test_loader, device)\n","    #prediction = F.softmax(torch.tensor(prediction)).numpy().astype(float)\n","    predictions4.append(prediction)\n","    del model, state, prediction\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","del testdataset,test_loader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9eNmSeB_sWdJ","executionInfo":{"status":"ok","timestamp":1661351348149,"user_tz":-540,"elapsed":539366,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"954d1edd-4844-4053-a23e-0439b03f88bf"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["sub4 = submission_df.copy()\n","sub4.columns = [\"id\",\"label\"]\n","\n","\n","#method1\n","sub4_predictions = np.mean(predictions4, axis=0)\n","sub4['Data scientist 4'] = sub4_predictions[:, 0]\n","sub4['Machine learning engineer 4'] = sub4_predictions[:, 1]\n","sub4['Software engineer 4'] = sub4_predictions[:, 2]\n","sub4['Consultant 4'] = sub4_predictions[:, 3]\n","sub4[\"std 4\"] = sub4[['Data scientist 4','Machine learning engineer 4','Software engineer 4','Consultant 4']].std(axis=1)\n","sub4[\"mean 4\"] = sub4[['Data scientist 4','Machine learning engineer 4','Software engineer 4','Consultant 4']].mean(axis=1)\n","\n","display(sub4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"OBHwPeIksmbB","executionInfo":{"status":"ok","timestamp":1661351348152,"user_tz":-540,"elapsed":34,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"9ef1cbef-e8c0-4ce6-ff98-fc7f717f7169"},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":["        id  label  Data scientist 4  Machine learning engineer 4  \\\n","0     1516      1          6.131341                    -2.006162   \n","1     1517      1         -1.435503                    -3.094449   \n","2     1518      1         -2.967395                    -2.247585   \n","3     1519      1         -1.469517                    -3.398634   \n","4     1520      1         -2.238134                    -1.169403   \n","...    ...    ...               ...                          ...   \n","1512  3028      1         -1.567770                    -1.393590   \n","1513  3029      1          6.894443                    -1.280073   \n","1514  3030      1         -3.276514                    -1.704441   \n","1515  3031      1          1.157998                    -3.581794   \n","1516  3032      1         -0.419609                    -1.325653   \n","\n","      Software engineer 4  Consultant 4     std 4    mean 4  \n","0               -3.930109     -0.041512  4.361177  0.038390  \n","1               -1.120204      6.155100  4.111474  0.126236  \n","2                5.858779     -1.070024  4.053061 -0.106556  \n","3               -1.704444      7.262183  4.804017  0.172397  \n","4                5.061175     -1.871674  3.439162 -0.054509  \n","...                   ...           ...       ...       ...  \n","1512             3.450119     -0.677963  2.363190 -0.047301  \n","1513            -3.893260     -1.689687  4.732307  0.007856  \n","1514             6.133006     -1.369423  4.207847 -0.054343  \n","1515            -2.105423      5.109935  3.857034  0.145179  \n","1516             2.878745     -1.036000  1.940062  0.024371  \n","\n","[1517 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-a74ec465-50ed-4de5-baef-64a848100e29\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>Data scientist 4</th>\n","      <th>Machine learning engineer 4</th>\n","      <th>Software engineer 4</th>\n","      <th>Consultant 4</th>\n","      <th>std 4</th>\n","      <th>mean 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1516</td>\n","      <td>1</td>\n","      <td>6.131341</td>\n","      <td>-2.006162</td>\n","      <td>-3.930109</td>\n","      <td>-0.041512</td>\n","      <td>4.361177</td>\n","      <td>0.038390</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1517</td>\n","      <td>1</td>\n","      <td>-1.435503</td>\n","      <td>-3.094449</td>\n","      <td>-1.120204</td>\n","      <td>6.155100</td>\n","      <td>4.111474</td>\n","      <td>0.126236</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1518</td>\n","      <td>1</td>\n","      <td>-2.967395</td>\n","      <td>-2.247585</td>\n","      <td>5.858779</td>\n","      <td>-1.070024</td>\n","      <td>4.053061</td>\n","      <td>-0.106556</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1519</td>\n","      <td>1</td>\n","      <td>-1.469517</td>\n","      <td>-3.398634</td>\n","      <td>-1.704444</td>\n","      <td>7.262183</td>\n","      <td>4.804017</td>\n","      <td>0.172397</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1520</td>\n","      <td>1</td>\n","      <td>-2.238134</td>\n","      <td>-1.169403</td>\n","      <td>5.061175</td>\n","      <td>-1.871674</td>\n","      <td>3.439162</td>\n","      <td>-0.054509</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1512</th>\n","      <td>3028</td>\n","      <td>1</td>\n","      <td>-1.567770</td>\n","      <td>-1.393590</td>\n","      <td>3.450119</td>\n","      <td>-0.677963</td>\n","      <td>2.363190</td>\n","      <td>-0.047301</td>\n","    </tr>\n","    <tr>\n","      <th>1513</th>\n","      <td>3029</td>\n","      <td>1</td>\n","      <td>6.894443</td>\n","      <td>-1.280073</td>\n","      <td>-3.893260</td>\n","      <td>-1.689687</td>\n","      <td>4.732307</td>\n","      <td>0.007856</td>\n","    </tr>\n","    <tr>\n","      <th>1514</th>\n","      <td>3030</td>\n","      <td>1</td>\n","      <td>-3.276514</td>\n","      <td>-1.704441</td>\n","      <td>6.133006</td>\n","      <td>-1.369423</td>\n","      <td>4.207847</td>\n","      <td>-0.054343</td>\n","    </tr>\n","    <tr>\n","      <th>1515</th>\n","      <td>3031</td>\n","      <td>1</td>\n","      <td>1.157998</td>\n","      <td>-3.581794</td>\n","      <td>-2.105423</td>\n","      <td>5.109935</td>\n","      <td>3.857034</td>\n","      <td>0.145179</td>\n","    </tr>\n","    <tr>\n","      <th>1516</th>\n","      <td>3032</td>\n","      <td>1</td>\n","      <td>-0.419609</td>\n","      <td>-1.325653</td>\n","      <td>2.878745</td>\n","      <td>-1.036000</td>\n","      <td>1.940062</td>\n","      <td>0.024371</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1517 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a74ec465-50ed-4de5-baef-64a848100e29')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a74ec465-50ed-4de5-baef-64a848100e29 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a74ec465-50ed-4de5-baef-64a848100e29');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["testdataset = Dataset4(test, CFG4.tokenizer, CFG4.max_len)\n","\n","test_loader = DataLoader(testdataset, \n","                         batch_size=CFG4.batch_size,\n","                         shuffle=False,\n","                         collate_fn = collate_fn1,\n","                         num_workers = CFG4.num_workers,\n","                         pin_memory = True,\n","                         drop_last = False,\n","                         )\n","\n","predictions5 = []\n","\n","for fold in CFG5.trn_fold:\n","    model = CustomModel5(CFG5.model)\n","    config_path=CFG5.config_path\n","    state = torch.load(CFG5.path+f\"{CFG5.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                       map_location = torch.device('cpu'))\n","    model.load_state_dict(state['model'])\n","\n","    prediction = inference_one_epoch(model, test_loader, device)\n","    #prediction = F.softmax(torch.tensor(prediction)).numpy().astype(float)\n","    predictions5.append(prediction)\n","    del model, state, prediction\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","del testdataset,test_loader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l_QiD33HtCaD","executionInfo":{"status":"ok","timestamp":1661351851062,"user_tz":-540,"elapsed":502940,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"90f52bc3-949a-4c89-b703-0b75d310e87f"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["sub5 = submission_df.copy()\n","sub5.columns = [\"id\",\"label\"]\n","\n","\n","#method1\n","sub5_predictions = np.mean(predictions5, axis=0)\n","sub5['Data scientist 5'] = sub5_predictions[:, 0]\n","sub5['Machine learning engineer 5'] = sub5_predictions[:, 1]\n","sub5['Software engineer 5'] = sub5_predictions[:, 2]\n","sub5['Consultant 5'] = sub5_predictions[:, 3]\n","sub5[\"std 5\"] = sub5[['Data scientist 5','Machine learning engineer 5','Software engineer 5','Consultant 5']].std(axis=1)\n","sub5[\"mean 5\"] = sub5[['Data scientist 5','Machine learning engineer 5','Software engineer 5','Consultant 5']].mean(axis=1)\n","\n","display(sub5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"LMjK9B6ttT-w","executionInfo":{"status":"ok","timestamp":1661351851066,"user_tz":-540,"elapsed":41,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"73fb925d-7c5b-4c72-f875-602e2fd86d22"},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":["        id  label  Data scientist 5  Machine learning engineer 5  \\\n","0     1516      1          6.211955                    -1.987111   \n","1     1517      1         -1.507465                    -3.639722   \n","2     1518      1         -2.610141                    -2.877807   \n","3     1519      1         -0.695383                    -4.301244   \n","4     1520      1          0.221690                    -1.864811   \n","...    ...    ...               ...                          ...   \n","1512  3028      1         -1.434959                    -2.221851   \n","1513  3029      1          7.104337                    -1.588706   \n","1514  3030      1         -2.780249                    -2.071175   \n","1515  3031      1          2.977597                    -2.965709   \n","1516  3032      1          0.380797                    -2.859520   \n","\n","      Software engineer 5  Consultant 5     std 5    mean 5  \n","0               -4.183251      0.073621  4.473577  0.028804  \n","1               -1.153705      6.226192  4.305622 -0.018675  \n","2                6.343557     -1.112021  4.341869 -0.064103  \n","3               -2.004891      7.349094  5.065663  0.086894  \n","4                2.857144     -1.610435  2.179003 -0.099103  \n","...                   ...           ...       ...       ...  \n","1512             3.937849     -0.632115  2.761107 -0.087769  \n","1513            -4.403844     -0.971667  4.943975  0.035030  \n","1514             5.696069     -1.301909  3.920351 -0.114316  \n","1515            -2.729434      3.217475  3.435161  0.124982  \n","1516             1.626632      0.941396  1.987630  0.022326  \n","\n","[1517 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-3c2dad74-8366-44bc-b653-491b16480647\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>Data scientist 5</th>\n","      <th>Machine learning engineer 5</th>\n","      <th>Software engineer 5</th>\n","      <th>Consultant 5</th>\n","      <th>std 5</th>\n","      <th>mean 5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1516</td>\n","      <td>1</td>\n","      <td>6.211955</td>\n","      <td>-1.987111</td>\n","      <td>-4.183251</td>\n","      <td>0.073621</td>\n","      <td>4.473577</td>\n","      <td>0.028804</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1517</td>\n","      <td>1</td>\n","      <td>-1.507465</td>\n","      <td>-3.639722</td>\n","      <td>-1.153705</td>\n","      <td>6.226192</td>\n","      <td>4.305622</td>\n","      <td>-0.018675</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1518</td>\n","      <td>1</td>\n","      <td>-2.610141</td>\n","      <td>-2.877807</td>\n","      <td>6.343557</td>\n","      <td>-1.112021</td>\n","      <td>4.341869</td>\n","      <td>-0.064103</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1519</td>\n","      <td>1</td>\n","      <td>-0.695383</td>\n","      <td>-4.301244</td>\n","      <td>-2.004891</td>\n","      <td>7.349094</td>\n","      <td>5.065663</td>\n","      <td>0.086894</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1520</td>\n","      <td>1</td>\n","      <td>0.221690</td>\n","      <td>-1.864811</td>\n","      <td>2.857144</td>\n","      <td>-1.610435</td>\n","      <td>2.179003</td>\n","      <td>-0.099103</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1512</th>\n","      <td>3028</td>\n","      <td>1</td>\n","      <td>-1.434959</td>\n","      <td>-2.221851</td>\n","      <td>3.937849</td>\n","      <td>-0.632115</td>\n","      <td>2.761107</td>\n","      <td>-0.087769</td>\n","    </tr>\n","    <tr>\n","      <th>1513</th>\n","      <td>3029</td>\n","      <td>1</td>\n","      <td>7.104337</td>\n","      <td>-1.588706</td>\n","      <td>-4.403844</td>\n","      <td>-0.971667</td>\n","      <td>4.943975</td>\n","      <td>0.035030</td>\n","    </tr>\n","    <tr>\n","      <th>1514</th>\n","      <td>3030</td>\n","      <td>1</td>\n","      <td>-2.780249</td>\n","      <td>-2.071175</td>\n","      <td>5.696069</td>\n","      <td>-1.301909</td>\n","      <td>3.920351</td>\n","      <td>-0.114316</td>\n","    </tr>\n","    <tr>\n","      <th>1515</th>\n","      <td>3031</td>\n","      <td>1</td>\n","      <td>2.977597</td>\n","      <td>-2.965709</td>\n","      <td>-2.729434</td>\n","      <td>3.217475</td>\n","      <td>3.435161</td>\n","      <td>0.124982</td>\n","    </tr>\n","    <tr>\n","      <th>1516</th>\n","      <td>3032</td>\n","      <td>1</td>\n","      <td>0.380797</td>\n","      <td>-2.859520</td>\n","      <td>1.626632</td>\n","      <td>0.941396</td>\n","      <td>1.987630</td>\n","      <td>0.022326</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1517 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c2dad74-8366-44bc-b653-491b16480647')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3c2dad74-8366-44bc-b653-491b16480647 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3c2dad74-8366-44bc-b653-491b16480647');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["stacking_test = sub1.merge(sub2[['id','Data scientist 2','Machine learning engineer 2','Software engineer 2','Consultant 2','std 2','mean 2']],how=\"left\",on=[\"id\"]).merge(sub3,how=\"left\",on=[\"id\",\"label\"]).merge(sub4,how=\"left\",on=[\"id\",\"label\"]).merge(sub5,how=\"left\",on=[\"id\",\"label\"])\n","display(stacking_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":540},"id":"BMWBavWMv-0x","executionInfo":{"status":"ok","timestamp":1661351851067,"user_tz":-540,"elapsed":39,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"4ee6444c-7a66-4eeb-8313-0c5f14b8bdef"},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":["        id  label  Data scientist 1  Machine learning engineer 1  \\\n","0     1516      1          6.685815                    -0.781564   \n","1     1517      1         -0.630478                    -3.923366   \n","2     1518      1         -3.591125                    -2.077838   \n","3     1519      1         -1.075718                    -4.926772   \n","4     1520      1          1.750711                    -0.921016   \n","...    ...    ...               ...                          ...   \n","1512  3028      1         -1.058913                    -1.431018   \n","1513  3029      1          7.246647                    -2.578345   \n","1514  3030      1         -3.504260                    -1.852924   \n","1515  3031      1          4.794982                    -4.459991   \n","1516  3032      1          1.645523                    -2.826577   \n","\n","      Software engineer 1  Consultant 1     std 1    mean 1  Data scientist 2  \\\n","0               -4.555237     -1.050914  4.730869  0.074525          5.762257   \n","1               -2.001289      6.555913  4.574402  0.000195         -1.254337   \n","2                6.774759     -1.719068  4.689425 -0.153318         -2.873216   \n","3               -2.082120      8.101068  5.638934  0.004115         -1.014173   \n","4                1.564643     -2.328322  1.981697  0.016504         -0.809194   \n","...                   ...           ...       ...       ...               ...   \n","1512             3.122421     -1.188190  2.179696 -0.138925         -0.914356   \n","1513            -4.135920     -0.358376  5.046070  0.043501          5.881723   \n","1514             6.179841     -1.525572  4.324636 -0.175729         -2.950127   \n","1515            -3.940049      3.310294  4.807761 -0.073691          1.947549   \n","1516             0.076269      0.811613  1.944251 -0.073293         -0.580502   \n","\n","      Machine learning engineer 2  ...  Software engineer 4  Consultant 4  \\\n","0                       -1.072270  ...            -3.930109     -0.041512   \n","1                       -2.323590  ...            -1.120204      6.155100   \n","2                       -2.258667  ...             5.858779     -1.070024   \n","3                       -2.861278  ...            -1.704444      7.262183   \n","4                       -1.135850  ...             5.061175     -1.871674   \n","...                           ...  ...                  ...           ...   \n","1512                    -1.310320  ...             3.450119     -0.677963   \n","1513                    -1.386537  ...            -3.893260     -1.689687   \n","1514                    -1.574746  ...             6.133006     -1.369423   \n","1515                    -3.362355  ...            -2.105423      5.109935   \n","1516                    -1.763637  ...             2.878745     -1.036000   \n","\n","         std 4    mean 4  Data scientist 5  Machine learning engineer 5  \\\n","0     4.361177  0.038390          6.211955                    -1.987111   \n","1     4.111474  0.126236         -1.507465                    -3.639722   \n","2     4.053061 -0.106556         -2.610141                    -2.877807   \n","3     4.804017  0.172397         -0.695383                    -4.301244   \n","4     3.439162 -0.054509          0.221690                    -1.864811   \n","...        ...       ...               ...                          ...   \n","1512  2.363190 -0.047301         -1.434959                    -2.221851   \n","1513  4.732307  0.007856          7.104337                    -1.588706   \n","1514  4.207847 -0.054343         -2.780249                    -2.071175   \n","1515  3.857034  0.145179          2.977597                    -2.965709   \n","1516  1.940062  0.024371          0.380797                    -2.859520   \n","\n","      Software engineer 5  Consultant 5     std 5    mean 5  \n","0               -4.183251      0.073621  4.473577  0.028804  \n","1               -1.153705      6.226192  4.305622 -0.018675  \n","2                6.343557     -1.112021  4.341869 -0.064103  \n","3               -2.004891      7.349094  5.065663  0.086894  \n","4                2.857144     -1.610435  2.179003 -0.099103  \n","...                   ...           ...       ...       ...  \n","1512             3.937849     -0.632115  2.761107 -0.087769  \n","1513            -4.403844     -0.971667  4.943975  0.035030  \n","1514             5.696069     -1.301909  3.920351 -0.114316  \n","1515            -2.729434      3.217475  3.435161  0.124982  \n","1516             1.626632      0.941396  1.987630  0.022326  \n","\n","[1517 rows x 32 columns]"],"text/html":["\n","  <div id=\"df-b9e0811d-619d-4098-af05-b9ff19d055fc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>Data scientist 1</th>\n","      <th>Machine learning engineer 1</th>\n","      <th>Software engineer 1</th>\n","      <th>Consultant 1</th>\n","      <th>std 1</th>\n","      <th>mean 1</th>\n","      <th>Data scientist 2</th>\n","      <th>Machine learning engineer 2</th>\n","      <th>...</th>\n","      <th>Software engineer 4</th>\n","      <th>Consultant 4</th>\n","      <th>std 4</th>\n","      <th>mean 4</th>\n","      <th>Data scientist 5</th>\n","      <th>Machine learning engineer 5</th>\n","      <th>Software engineer 5</th>\n","      <th>Consultant 5</th>\n","      <th>std 5</th>\n","      <th>mean 5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1516</td>\n","      <td>1</td>\n","      <td>6.685815</td>\n","      <td>-0.781564</td>\n","      <td>-4.555237</td>\n","      <td>-1.050914</td>\n","      <td>4.730869</td>\n","      <td>0.074525</td>\n","      <td>5.762257</td>\n","      <td>-1.072270</td>\n","      <td>...</td>\n","      <td>-3.930109</td>\n","      <td>-0.041512</td>\n","      <td>4.361177</td>\n","      <td>0.038390</td>\n","      <td>6.211955</td>\n","      <td>-1.987111</td>\n","      <td>-4.183251</td>\n","      <td>0.073621</td>\n","      <td>4.473577</td>\n","      <td>0.028804</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1517</td>\n","      <td>1</td>\n","      <td>-0.630478</td>\n","      <td>-3.923366</td>\n","      <td>-2.001289</td>\n","      <td>6.555913</td>\n","      <td>4.574402</td>\n","      <td>0.000195</td>\n","      <td>-1.254337</td>\n","      <td>-2.323590</td>\n","      <td>...</td>\n","      <td>-1.120204</td>\n","      <td>6.155100</td>\n","      <td>4.111474</td>\n","      <td>0.126236</td>\n","      <td>-1.507465</td>\n","      <td>-3.639722</td>\n","      <td>-1.153705</td>\n","      <td>6.226192</td>\n","      <td>4.305622</td>\n","      <td>-0.018675</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1518</td>\n","      <td>1</td>\n","      <td>-3.591125</td>\n","      <td>-2.077838</td>\n","      <td>6.774759</td>\n","      <td>-1.719068</td>\n","      <td>4.689425</td>\n","      <td>-0.153318</td>\n","      <td>-2.873216</td>\n","      <td>-2.258667</td>\n","      <td>...</td>\n","      <td>5.858779</td>\n","      <td>-1.070024</td>\n","      <td>4.053061</td>\n","      <td>-0.106556</td>\n","      <td>-2.610141</td>\n","      <td>-2.877807</td>\n","      <td>6.343557</td>\n","      <td>-1.112021</td>\n","      <td>4.341869</td>\n","      <td>-0.064103</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1519</td>\n","      <td>1</td>\n","      <td>-1.075718</td>\n","      <td>-4.926772</td>\n","      <td>-2.082120</td>\n","      <td>8.101068</td>\n","      <td>5.638934</td>\n","      <td>0.004115</td>\n","      <td>-1.014173</td>\n","      <td>-2.861278</td>\n","      <td>...</td>\n","      <td>-1.704444</td>\n","      <td>7.262183</td>\n","      <td>4.804017</td>\n","      <td>0.172397</td>\n","      <td>-0.695383</td>\n","      <td>-4.301244</td>\n","      <td>-2.004891</td>\n","      <td>7.349094</td>\n","      <td>5.065663</td>\n","      <td>0.086894</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1520</td>\n","      <td>1</td>\n","      <td>1.750711</td>\n","      <td>-0.921016</td>\n","      <td>1.564643</td>\n","      <td>-2.328322</td>\n","      <td>1.981697</td>\n","      <td>0.016504</td>\n","      <td>-0.809194</td>\n","      <td>-1.135850</td>\n","      <td>...</td>\n","      <td>5.061175</td>\n","      <td>-1.871674</td>\n","      <td>3.439162</td>\n","      <td>-0.054509</td>\n","      <td>0.221690</td>\n","      <td>-1.864811</td>\n","      <td>2.857144</td>\n","      <td>-1.610435</td>\n","      <td>2.179003</td>\n","      <td>-0.099103</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1512</th>\n","      <td>3028</td>\n","      <td>1</td>\n","      <td>-1.058913</td>\n","      <td>-1.431018</td>\n","      <td>3.122421</td>\n","      <td>-1.188190</td>\n","      <td>2.179696</td>\n","      <td>-0.138925</td>\n","      <td>-0.914356</td>\n","      <td>-1.310320</td>\n","      <td>...</td>\n","      <td>3.450119</td>\n","      <td>-0.677963</td>\n","      <td>2.363190</td>\n","      <td>-0.047301</td>\n","      <td>-1.434959</td>\n","      <td>-2.221851</td>\n","      <td>3.937849</td>\n","      <td>-0.632115</td>\n","      <td>2.761107</td>\n","      <td>-0.087769</td>\n","    </tr>\n","    <tr>\n","      <th>1513</th>\n","      <td>3029</td>\n","      <td>1</td>\n","      <td>7.246647</td>\n","      <td>-2.578345</td>\n","      <td>-4.135920</td>\n","      <td>-0.358376</td>\n","      <td>5.046070</td>\n","      <td>0.043501</td>\n","      <td>5.881723</td>\n","      <td>-1.386537</td>\n","      <td>...</td>\n","      <td>-3.893260</td>\n","      <td>-1.689687</td>\n","      <td>4.732307</td>\n","      <td>0.007856</td>\n","      <td>7.104337</td>\n","      <td>-1.588706</td>\n","      <td>-4.403844</td>\n","      <td>-0.971667</td>\n","      <td>4.943975</td>\n","      <td>0.035030</td>\n","    </tr>\n","    <tr>\n","      <th>1514</th>\n","      <td>3030</td>\n","      <td>1</td>\n","      <td>-3.504260</td>\n","      <td>-1.852924</td>\n","      <td>6.179841</td>\n","      <td>-1.525572</td>\n","      <td>4.324636</td>\n","      <td>-0.175729</td>\n","      <td>-2.950127</td>\n","      <td>-1.574746</td>\n","      <td>...</td>\n","      <td>6.133006</td>\n","      <td>-1.369423</td>\n","      <td>4.207847</td>\n","      <td>-0.054343</td>\n","      <td>-2.780249</td>\n","      <td>-2.071175</td>\n","      <td>5.696069</td>\n","      <td>-1.301909</td>\n","      <td>3.920351</td>\n","      <td>-0.114316</td>\n","    </tr>\n","    <tr>\n","      <th>1515</th>\n","      <td>3031</td>\n","      <td>1</td>\n","      <td>4.794982</td>\n","      <td>-4.459991</td>\n","      <td>-3.940049</td>\n","      <td>3.310294</td>\n","      <td>4.807761</td>\n","      <td>-0.073691</td>\n","      <td>1.947549</td>\n","      <td>-3.362355</td>\n","      <td>...</td>\n","      <td>-2.105423</td>\n","      <td>5.109935</td>\n","      <td>3.857034</td>\n","      <td>0.145179</td>\n","      <td>2.977597</td>\n","      <td>-2.965709</td>\n","      <td>-2.729434</td>\n","      <td>3.217475</td>\n","      <td>3.435161</td>\n","      <td>0.124982</td>\n","    </tr>\n","    <tr>\n","      <th>1516</th>\n","      <td>3032</td>\n","      <td>1</td>\n","      <td>1.645523</td>\n","      <td>-2.826577</td>\n","      <td>0.076269</td>\n","      <td>0.811613</td>\n","      <td>1.944251</td>\n","      <td>-0.073293</td>\n","      <td>-0.580502</td>\n","      <td>-1.763637</td>\n","      <td>...</td>\n","      <td>2.878745</td>\n","      <td>-1.036000</td>\n","      <td>1.940062</td>\n","      <td>0.024371</td>\n","      <td>0.380797</td>\n","      <td>-2.859520</td>\n","      <td>1.626632</td>\n","      <td>0.941396</td>\n","      <td>1.987630</td>\n","      <td>0.022326</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1517 rows × 32 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9e0811d-619d-4098-af05-b9ff19d055fc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b9e0811d-619d-4098-af05-b9ff19d055fc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b9e0811d-619d-4098-af05-b9ff19d055fc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["features = stacking_test.columns.to_list()\n","features.remove('id')\n","features.remove('label')"],"metadata":{"id":"XXR04BJ35b6n","executionInfo":{"status":"ok","timestamp":1661351851068,"user_tz":-540,"elapsed":38,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["def get_lgbm_cv_score(oof_df, lr=0.1, n_est=100, n_leave=31):\n","    f1_score_ = []\n","    clf_ = []\n","    for fold in range(5):\n","        print(\"Fold :\", fold)\n","        X_train = oof_df[oof_df.kfold!=fold][features].values\n","        y_train = oof_df[oof_df.kfold!=fold].label.values\n","\n","        X_test = oof_df[oof_df.kfold==fold][features].values\n","        y_test = oof_df[oof_df.kfold==fold].label.values\n","\n","        clf = lgb.LGBMClassifier(learning_rate=lr,\n","                                n_estimators=n_est,\n","                                num_leaves=n_leave,\n","                                boosting_type='gbdt',\n","                                random_state=42)\n","        clf.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=100,\n","               verbose=500)\n","        \n","        y_pred = clf.predict(X_test)\n","        score = f1_score(y_pred,y_test ,average='macro')\n","        print(f\"F1 Score : {score}\")\n","        f1_score_.append(score)\n","        clf_.append(clf)\n","    return f1_score_, clf_\n","\n","lr=0.05\n","lgbm_f1_score_, lgbm_clf_ = get_lgbm_cv_score(stacking_train, lr=lr, n_est=1000, n_leave=31)\n","print(np.array(lgbm_f1_score_).mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4aC-KhQT5cm-","executionInfo":{"status":"ok","timestamp":1661351865315,"user_tz":-540,"elapsed":14284,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"49854c64-19dd-45ae-c206-4d2cf5cf1e81"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold : 0\n","Training until validation scores don't improve for 100 rounds.\n","Early stopping, best iteration is:\n","[58]\tvalid_0's multi_logloss: 0.549269\n","F1 Score : 0.7903658823855448\n","Fold : 1\n","Training until validation scores don't improve for 100 rounds.\n","Early stopping, best iteration is:\n","[96]\tvalid_0's multi_logloss: 0.580805\n","F1 Score : 0.7493826473859844\n","Fold : 2\n","Training until validation scores don't improve for 100 rounds.\n","Early stopping, best iteration is:\n","[62]\tvalid_0's multi_logloss: 0.621708\n","F1 Score : 0.6964788493267811\n","Fold : 3\n","Training until validation scores don't improve for 100 rounds.\n","Early stopping, best iteration is:\n","[63]\tvalid_0's multi_logloss: 0.573549\n","F1 Score : 0.7021752613857877\n","Fold : 4\n","Training until validation scores don't improve for 100 rounds.\n","Early stopping, best iteration is:\n","[75]\tvalid_0's multi_logloss: 0.556865\n","F1 Score : 0.7009728997914864\n","0.7278751080551169\n"]}]},{"cell_type":"code","source":["def get_ctb_cv_score(oof_df):\n","    params = {\n","          \"loss_function\":\"Logloss\",\n","          \"n_estimators\":1000,\n","          \"random_seed\":42,\n","          \"learning_rate\":0.05,\n","          'task_type' : 'GPU'\n","    }\n","    f1_score_ = []\n","    clf_ = []\n","    for fold in range(5):\n","        print(\"Fold :\", fold)\n","        X_train = oof_df[oof_df.kfold!=fold][features].values\n","        y_train = oof_df[oof_df.kfold!=fold].label.values\n","\n","        X_test = oof_df[oof_df.kfold==fold][features].values\n","        y_test = oof_df[oof_df.kfold==fold].label.values\n","\n","        clf = ctb.CatBoostClassifier(**params)\n","        clf.fit(X_train, y_train,\n","            eval_set=[(X_train,y_train),(X_test, y_test)],\n","            verbose = 500,\n","            early_stopping_rounds = 100)\n","        \n","        y_pred = clf.predict(X_test)\n","        score = f1_score(y_pred,y_test ,average='macro')\n","        print(f\"F1 Score : {score}\")\n","        f1_score_.append(score)\n","        clf_.append(clf)\n","    return f1_score_, clf_\n","\n","\n","ctb_f1_score_, ctb_clf_ = get_lgbm_cv_score(stacking_train)\n","print(np.array(ctb_f1_score_).mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yne2Chvi5cv2","executionInfo":{"status":"ok","timestamp":1661351873677,"user_tz":-540,"elapsed":8407,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"7344c1e2-4e08-4d3c-f85b-2065ee8353f7"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold : 0\n","Training until validation scores don't improve for 100 rounds.\n","Did not meet early stopping. Best iteration is:\n","[29]\tvalid_0's multi_logloss: 0.549462\n","F1 Score : 0.8030796805665916\n","Fold : 1\n","Training until validation scores don't improve for 100 rounds.\n","Did not meet early stopping. Best iteration is:\n","[43]\tvalid_0's multi_logloss: 0.588313\n","F1 Score : 0.7256165164946239\n","Fold : 2\n","Training until validation scores don't improve for 100 rounds.\n","Did not meet early stopping. Best iteration is:\n","[29]\tvalid_0's multi_logloss: 0.632381\n","F1 Score : 0.6797060282493853\n","Fold : 3\n","Training until validation scores don't improve for 100 rounds.\n","Did not meet early stopping. Best iteration is:\n","[34]\tvalid_0's multi_logloss: 0.570637\n","F1 Score : 0.71499552483861\n","Fold : 4\n","Training until validation scores don't improve for 100 rounds.\n","Did not meet early stopping. Best iteration is:\n","[31]\tvalid_0's multi_logloss: 0.561672\n","F1 Score : 0.720012439667612\n","0.7286820379633646\n"]}]},{"cell_type":"code","source":["def get_logit_cv_score(oof_df):\n","    f1_score_ = []\n","    clf_ = []\n","    for fold in range(5):\n","        print(\"Fold :\", fold)\n","        X_train = oof_df[oof_df.kfold!=fold][features].values\n","        y_train = oof_df[oof_df.kfold!=fold].label.values\n","\n","        X_test = oof_df[oof_df.kfold==fold][features].values\n","        y_test = oof_df[oof_df.kfold==fold].label.values\n","\n","        clf = LogisticRegression(random_state=0)\n","        clf.fit(X_train, y_train)\n","        \n","        y_pred = clf.predict(X_test)\n","        score = f1_score(y_pred,y_test ,average='macro')\n","        print(f\"F1 Score : {score}\")\n","        f1_score_.append(score)\n","        clf_.append(clf)\n","    return f1_score_, clf_\n","\n","\n","logit_f1_score_, logit_clf_ = get_logit_cv_score(stacking_train)\n","print(np.array(logit_f1_score_).mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZYOrZ0OO5c52","executionInfo":{"status":"ok","timestamp":1661351874568,"user_tz":-540,"elapsed":935,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"c3d7577a-5814-4cc6-8a11-4fceee2ee4d6"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold : 0\n","F1 Score : 0.7284419034419035\n","Fold : 1\n","F1 Score : 0.7133859050357818\n","Fold : 2\n","F1 Score : 0.6839008487754872\n","Fold : 3\n","F1 Score : 0.684930860015057\n","Fold : 4\n","F1 Score : 0.7610791860968366\n","0.7143477406730132\n"]}]},{"cell_type":"code","source":["def get_predicts(df_,lgb_clfs,ctb_clfs,logit_clfs):\n","  lgb_predict,ctb_predict,logit_predict = [],[],[]\n","  test_X = df_[features].values\n","  for fold in range(5):\n","    lgb_predict.append(lgb_clfs[fold].predict(test_X))\n","    ctb_predict.append(ctb_clfs[fold].predict(test_X))\n","    logit_predict.append(logit_clfs[fold].predict(test_X))\n","\n","  return lgb_predict,ctb_predict,logit_predict\n","\n","lgb_pred,ctb_pred,logit_pred = get_predicts(stacking_test,lgbm_clf_,ctb_clf_,logit_clf_)"],"metadata":{"id":"QbiFuYVt5dCH","executionInfo":{"status":"ok","timestamp":1661351874884,"user_tz":-540,"elapsed":320,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["sub = submission_df.copy()\n","sub.columns = [\"id\",\"label\"]\n","\n","for fold in range(5):\n","  sub[f\"lgb_{fold}\"] = lgb_pred[fold]\n","  sub[f\"ctb_{fold}\"] = ctb_pred[fold]\n","  sub[f\"logit_{fold}\"] = logit_pred[fold]\n","\n","sub[\"label\"] = sub.loc[:,\"lgb_0\":\"logit_4\"].mode(axis=1)[0]\n","sub[\"label\"] = sub[\"label\"].astype(\"int\")\n","sub[\"label\"] = sub[\"label\"] + 1\n","sub[[\"id\",\"label\"]].to_csv(os.path.join(OUTPUT_SUB_DIR,\"submission32_Stacking.csv\"),index=False,header=False)\n","display(sub)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"LV0V1EnKHTY1","executionInfo":{"status":"ok","timestamp":1661351875736,"user_tz":-540,"elapsed":856,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"44e6c2dd-a95d-4d2b-b568-63dc6687e279"},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":["        id  label  lgb_0  ctb_0  logit_0  lgb_1  ctb_1  logit_1  lgb_2  ctb_2  \\\n","0     1516      1      0      0        0      0      0        0      0      0   \n","1     1517      4      3      3        3      3      3        3      3      3   \n","2     1518      3      2      2        2      2      2        2      2      2   \n","3     1519      4      3      3        3      3      3        3      3      3   \n","4     1520      3      2      2        2      2      2        2      2      2   \n","...    ...    ...    ...    ...      ...    ...    ...      ...    ...    ...   \n","1512  3028      3      2      2        2      2      2        2      2      2   \n","1513  3029      1      0      0        0      0      0        0      0      0   \n","1514  3030      3      2      2        2      2      2        2      2      2   \n","1515  3031      4      3      3        3      3      3        3      3      3   \n","1516  3032      3      2      2        3      2      2        3      2      2   \n","\n","      logit_2  lgb_3  ctb_3  logit_3  lgb_4  ctb_4  logit_4  \n","0           0      0      0        0      0      0        0  \n","1           3      3      3        3      3      3        3  \n","2           2      2      2        2      2      2        2  \n","3           3      3      3        3      3      3        3  \n","4           2      2      2        2      2      2        2  \n","...       ...    ...    ...      ...    ...    ...      ...  \n","1512        2      2      2        2      2      2        2  \n","1513        0      0      0        0      0      0        0  \n","1514        2      2      2        2      2      2        2  \n","1515        3      0      0        3      3      3        3  \n","1516        0      2      2        2      2      2        2  \n","\n","[1517 rows x 17 columns]"],"text/html":["\n","  <div id=\"df-811aebc2-fc0e-4499-8fe0-9babeea31464\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>lgb_0</th>\n","      <th>ctb_0</th>\n","      <th>logit_0</th>\n","      <th>lgb_1</th>\n","      <th>ctb_1</th>\n","      <th>logit_1</th>\n","      <th>lgb_2</th>\n","      <th>ctb_2</th>\n","      <th>logit_2</th>\n","      <th>lgb_3</th>\n","      <th>ctb_3</th>\n","      <th>logit_3</th>\n","      <th>lgb_4</th>\n","      <th>ctb_4</th>\n","      <th>logit_4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1516</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1517</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1518</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1519</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1520</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1512</th>\n","      <td>3028</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1513</th>\n","      <td>3029</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1514</th>\n","      <td>3030</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1515</th>\n","      <td>3031</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1516</th>\n","      <td>3032</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1517 rows × 17 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-811aebc2-fc0e-4499-8fe0-9babeea31464')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-811aebc2-fc0e-4499-8fe0-9babeea31464 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-811aebc2-fc0e-4499-8fe0-9babeea31464');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["#train,testでダブっているデータを参照\n","dup_test_ids = [1707,2122,2291,2775,2191,1700,2304,2149,2676,2844,2144,2764,1774,2446,2736,2301,1822,1852,2070,1609,2423,2695,\n","                2077,2409,2233,2076,1568,3001,1662,1997, 2896,2352,2842,2321,1630,2259,2968,1551, 1673, 2168]\n","sub[sub[\"id\"].isin(dup_test_ids)]  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"OzJaBXbWbyeT","executionInfo":{"status":"ok","timestamp":1661351875738,"user_tz":-540,"elapsed":32,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"05e20388-3af5-43b1-d01a-c1de299d9b00"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id  label  lgb_0  ctb_0  logit_0  lgb_1  ctb_1  logit_1  lgb_2  ctb_2  \\\n","35    1551      4      3      3        3      3      3        3      3      3   \n","52    1568      1      0      0        0      0      0        0      0      0   \n","93    1609      4      3      3        3      3      3        3      3      3   \n","114   1630      4      3      3        3      3      3        3      3      3   \n","146   1662      1      0      0        0      0      0        0      0      0   \n","157   1673      4      3      3        3      3      3        3      3      3   \n","184   1700      1      0      0        0      0      0        0      0      0   \n","191   1707      3      2      2        2      2      2        2      2      2   \n","258   1774      4      3      3        3      3      3        3      3      3   \n","306   1822      4      3      3        3      3      3        3      3      3   \n","336   1852      4      3      3        3      3      3        3      3      3   \n","481   1997      3      2      2        2      2      2        2      2      2   \n","554   2070      3      2      2        2      2      2        2      2      2   \n","560   2076      1      0      0        0      0      0        0      0      0   \n","561   2077      3      2      2        2      2      2        2      2      2   \n","606   2122      4      3      3        3      3      3        3      3      3   \n","628   2144      3      2      2        2      2      2        2      2      2   \n","633   2149      1      0      0        0      0      0        0      0      0   \n","652   2168      4      3      3        3      3      3        3      3      3   \n","675   2191      1      0      0        0      0      0        0      0      0   \n","717   2233      4      3      3        3      3      3        3      3      3   \n","743   2259      1      0      0        0      0      0        0      0      0   \n","775   2291      1      0      0        0      0      0        0      0      0   \n","785   2301      1      0      0        0      0      0        0      0      0   \n","788   2304      1      0      0        0      0      0        0      0      0   \n","805   2321      4      3      3        3      3      3        3      3      3   \n","836   2352      1      0      0        0      0      0        0      0      0   \n","893   2409      4      3      3        3      3      3        3      3      3   \n","907   2423      4      3      3        3      3      3        3      3      3   \n","930   2446      1      0      0        0      0      0        0      0      0   \n","1160  2676      3      2      2        2      2      2        2      2      2   \n","1179  2695      4      3      3        3      3      3        3      3      3   \n","1220  2736      1      0      0        0      0      0        0      0      0   \n","1248  2764      4      3      3        3      3      3        3      3      3   \n","1259  2775      4      3      3        3      3      3        3      3      3   \n","1326  2842      4      3      3        3      3      3        3      3      0   \n","1328  2844      1      0      0        0      0      0        0      0      0   \n","1380  2896      3      2      2        2      2      2        2      2      2   \n","1452  2968      4      3      3        3      3      3        3      3      3   \n","1485  3001      1      0      0        0      0      0        0      0      0   \n","\n","      logit_2  lgb_3  ctb_3  logit_3  lgb_4  ctb_4  logit_4  \n","35          3      3      3        3      3      3        3  \n","52          0      0      0        0      0      0        0  \n","93          3      3      3        3      3      3        3  \n","114         3      3      3        3      3      3        3  \n","146         0      0      0        0      0      0        0  \n","157         3      3      3        3      3      3        3  \n","184         0      0      0        0      0      0        0  \n","191         2      2      2        2      2      2        2  \n","258         3      3      3        3      3      3        3  \n","306         3      3      3        3      3      3        3  \n","336         3      3      3        3      3      3        3  \n","481         2      2      2        2      2      2        2  \n","554         2      2      2        2      2      2        2  \n","560         0      0      0        0      0      0        0  \n","561         2      2      2        2      2      2        2  \n","606         3      3      3        3      3      3        3  \n","628         2      2      2        2      2      2        2  \n","633         0      0      0        0      0      0        0  \n","652         3      3      3        3      3      3        3  \n","675         0      0      0        0      0      0        0  \n","717         3      3      3        3      3      3        3  \n","743         0      0      0        0      0      0        0  \n","775         0      0      0        0      0      0        0  \n","785         0      0      0        0      0      0        0  \n","788         0      0      0        0      0      0        0  \n","805         3      3      3        3      3      3        3  \n","836         0      0      0        0      0      0        0  \n","893         3      3      3        3      3      3        3  \n","907         3      3      3        3      3      3        3  \n","930         0      0      0        0      0      0        0  \n","1160        2      2      2        2      2      2        2  \n","1179        3      3      3        3      3      3        3  \n","1220        0      0      0        0      0      0        0  \n","1248        3      3      3        3      3      3        3  \n","1259        3      3      3        3      3      3        3  \n","1326        3      3      3        3      3      3        3  \n","1328        0      0      0        0      0      0        0  \n","1380        2      2      2        2      2      2        2  \n","1452        3      3      3        3      3      3        3  \n","1485        0      0      0        0      0      0        0  "],"text/html":["\n","  <div id=\"df-ab0473b8-a17e-4abd-8e34-7960ba2c864d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>lgb_0</th>\n","      <th>ctb_0</th>\n","      <th>logit_0</th>\n","      <th>lgb_1</th>\n","      <th>ctb_1</th>\n","      <th>logit_1</th>\n","      <th>lgb_2</th>\n","      <th>ctb_2</th>\n","      <th>logit_2</th>\n","      <th>lgb_3</th>\n","      <th>ctb_3</th>\n","      <th>logit_3</th>\n","      <th>lgb_4</th>\n","      <th>ctb_4</th>\n","      <th>logit_4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>35</th>\n","      <td>1551</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>1568</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>1609</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>1630</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>1662</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>1673</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>184</th>\n","      <td>1700</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>191</th>\n","      <td>1707</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>258</th>\n","      <td>1774</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>306</th>\n","      <td>1822</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>336</th>\n","      <td>1852</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>481</th>\n","      <td>1997</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>554</th>\n","      <td>2070</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>560</th>\n","      <td>2076</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>561</th>\n","      <td>2077</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>606</th>\n","      <td>2122</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>628</th>\n","      <td>2144</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>633</th>\n","      <td>2149</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>652</th>\n","      <td>2168</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>675</th>\n","      <td>2191</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>717</th>\n","      <td>2233</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>743</th>\n","      <td>2259</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>775</th>\n","      <td>2291</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>785</th>\n","      <td>2301</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>788</th>\n","      <td>2304</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>805</th>\n","      <td>2321</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>836</th>\n","      <td>2352</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>893</th>\n","      <td>2409</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>907</th>\n","      <td>2423</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>930</th>\n","      <td>2446</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1160</th>\n","      <td>2676</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1179</th>\n","      <td>2695</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1220</th>\n","      <td>2736</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1248</th>\n","      <td>2764</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1259</th>\n","      <td>2775</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1326</th>\n","      <td>2842</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1328</th>\n","      <td>2844</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1380</th>\n","      <td>2896</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1452</th>\n","      <td>2968</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1485</th>\n","      <td>3001</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab0473b8-a17e-4abd-8e34-7960ba2c864d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ab0473b8-a17e-4abd-8e34-7960ba2c864d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ab0473b8-a17e-4abd-8e34-7960ba2c864d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["T = pd.DataFrame([[1707,2122,2291,2775,2191,1700,2304,2149,2676,2844,2144,2764,1774,2446,2736,2301,1822,1852,2070,1609,2423,2695,\n","                2077,2409,2233,2076,1568,3001,1662,1997, 2896,2352,2842,2321,1630,2259,2968,1551, 1673, 2168],\n","                [3,4,1,4,1,1,1,1,3,1,3,4,4,1,1,1,4,4,3,4,4,4,3,4,4,1,1,1,1,3,3,1,4,4,4,1,4,4,4,4]]).T\n","T.columns =[\"id\",\"label\"]\n","T = T.sort_values(by=\"id\")\n","T"],"metadata":{"id":"xARRZESNv3uc","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1661351875739,"user_tz":-540,"elapsed":29,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"a9c39cb5-40b6-4186-b9ff-5cad182471cc"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      id  label\n","37  1551      4\n","26  1568      1\n","19  1609      4\n","34  1630      4\n","28  1662      1\n","38  1673      4\n","5   1700      1\n","0   1707      3\n","12  1774      4\n","16  1822      4\n","17  1852      4\n","29  1997      3\n","18  2070      3\n","25  2076      1\n","22  2077      3\n","1   2122      4\n","10  2144      3\n","7   2149      1\n","39  2168      4\n","4   2191      1\n","24  2233      4\n","35  2259      1\n","2   2291      1\n","15  2301      1\n","6   2304      1\n","33  2321      4\n","31  2352      1\n","23  2409      4\n","20  2423      4\n","13  2446      1\n","8   2676      3\n","21  2695      4\n","14  2736      1\n","11  2764      4\n","3   2775      4\n","32  2842      4\n","9   2844      1\n","30  2896      3\n","36  2968      4\n","27  3001      1"],"text/html":["\n","  <div id=\"df-22c98f70-9ad1-41a9-b938-01fc17e2e765\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>37</th>\n","      <td>1551</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>1568</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>1609</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>1630</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>1662</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>1673</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1700</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>1707</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>1774</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>1822</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>1852</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>1997</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>2070</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>2076</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>2077</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2122</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2144</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2149</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>2168</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2191</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>2233</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>2259</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2291</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>2301</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2304</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>2321</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>2352</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>2409</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>2423</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>2446</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2676</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>2695</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2736</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2764</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2775</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>2842</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2844</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>2896</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>2968</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>3001</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22c98f70-9ad1-41a9-b938-01fc17e2e765')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-22c98f70-9ad1-41a9-b938-01fc17e2e765 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-22c98f70-9ad1-41a9-b938-01fc17e2e765');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["sub.to_csv(os.path.join(OUTPUT_DIR,\"Stacking_df.csv\"),index=False)"],"metadata":{"id":"5gQKgLImJ-Mk","executionInfo":{"status":"ok","timestamp":1661352324671,"user_tz":-540,"elapsed":283,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"UGuy-jJrUEQS"},"execution_count":null,"outputs":[]}]}